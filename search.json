[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Handbuch IT in Bibliotheken",
    "section": "",
    "text": "Einleitung"
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Handbuch IT in Bibliotheken",
    "section": "Motivation",
    "text": "Motivation\n\nBecause the library has become software, it is no longer viable for our services to exist separately from our software. [...] Most importantly, all library staff must understand that our software is our library, and is everyone’s responsibility.\n— (Hanson, Cody 2015)\n\nMit der wachsenden Bedeutung der Informationstechnologie (IT) im Allgemeinen und für Bibliotheken im Besonderen bleibt kaum ein Aspekt bibliothekarischer Aufgaben, der nicht durch IT unterstützt wird. Deutlich wird dies z.B. durch das stetig zunehmende Angebot an elektronischen Informationsmitteln, die Digitalisierung historischer Bestände, interoperable Metadaten oder auch die digitale Langzeitarchivierung. Die alltägliche Handhabung von IT (Smartphones, Automatisierung, Vernetzung, …) wird häufig einfacher, die zugrunde liegenden Systeme werden jedoch immer komplexer und erfordern entsprechend mehr Wissen zu ihrem Aufbau und Betrieb. Während sich einige Teile der IT in Bibliotheken nicht wesentlich von IT in anderen Bereichen unterscheiden, gibt es doch zahlreiche Aspekte von Bibliotheks-IT, die nicht oder nicht speziell genug an anderer Stelle behandelt werden. Das vorliegende Handbuch möchte diese Lücke schließen."
  },
  {
    "objectID": "index.html#zielgruppe",
    "href": "index.html#zielgruppe",
    "title": "Handbuch IT in Bibliotheken",
    "section": "Zielgruppe",
    "text": "Zielgruppe\nAls Einführung und Nachschlagewerk wendet sich dieses Handbuch vor allem an Personen, die sich einen ersten Überblick über die verschiedenen IT-Dienste an Bibliotheken verschaffen wollen. Dies können z. B. Personen sein, die sich im Rahmen ihrer bibliothekarischen Ausbildung mit IT-Diensten in Bibliotheken beschäftigen oder die sich im Rahmen der Einarbeitung in eine neue Position mit IT-Diensten in Bibliotheken beschäftigen. Zur Veranschaulichung der Zielgruppen dienen mehrere sogenannte Personas."
  },
  {
    "objectID": "index.html#inhalt",
    "href": "index.html#inhalt",
    "title": "Handbuch IT in Bibliotheken",
    "section": "Inhalt",
    "text": "Inhalt\nDieses Handbuch soll einen knappen und gleichzeitig umfassenden Überblick über die wichtigsten IT-bezogenen Themen in Bibliotheken geben. Die einzelnen Themenkapitel sind weitgehend unabhängig voneinander lesbar und mit Querverweisen verbunden. Die Kapitel bilden grob zwei Blöcke:\n\nAllgemeine technische Grundlagen\n\nTechnische Infrastruktur beschreibt grundlegende technischen Einrichtungen einer Bibliothek für den Betrieb von Prozessen und Dienstleistungen\nManagement von IT-Systemen beinhaltet die Einführung und den Betrieb von IT-Systemen allgemein\nAnforderungsanalyse umfasst die Ermittlung und Erfüllung von Bedarfen und Anforderungen an IT-Systeme\nSicherheit & Datenschutz: dieses Kapitel ist noch nicht fertig gestellt\nDaten & Metadaten stellt wichtige Begriffe, Standards und Prozesse der Datenverarbeitung in Bibliotheken vor\n\n\n\nBibliothekspezifische Dienste\n\nBibliotheksmanagementsysteme sind spezialisierte Informationssysteme für Arbeitsprozesse rund um Erwerbung, Erschließung, Ausleihe, Zugriff und Auffindbarmachung von Bibliotheksbeständen\nDiscovery & Retrieval stellt Arten, Bestandteile und Funktionen von Rechercheplattformen vor und liefert Hinweise zu Auswahl und Betrieb von Discovery-Systemen\nDigitalisierung umfasst Prozesse und Werkzeuge zur Digitalisierung, Erschließung und Präsentation von Kulturgütern\nForschungsnahe Dienste beschreibt Dienste wie Repositorien und Forschungsdatenmanagement zur Unterstützung von Forschungsprozessen\nKommunikation beinhaltet Werkzeuge und Methoden interner und externer Kommunikation von Wissensmanagement bis Öffentlichkeitsarbeit"
  },
  {
    "objectID": "index.html#zur-entstehung-dieses-handbuchs",
    "href": "index.html#zur-entstehung-dieses-handbuchs",
    "title": "Handbuch IT in Bibliotheken",
    "section": "Zur Entstehung dieses Handbuchs",
    "text": "Zur Entstehung dieses Handbuchs\nDieses Handbuch wurde im Rahmen von drei Book Sprints zwischen April 2022 und Oktober 2023 an der Bibliothek der Technischen Hochschule Wildau erstellt. Dazu trafen sich IT-affine Expert*innen aus dem Bibliotheksbereich, um innerhalb von wenigen Tagen eine umfassende Übersicht zu den wichtigsten Themen rund im IT in Bibliotheken zu verfassen. Die Veranstaltung wurde mit Mitteln des Publikationsfonds für Open-Access-Monografien des Landes Brandenburg gefördert.\nDas Handbuch ist ein „lebendiges Buch“, das stetig ergänzt und aktualisiert werden kann. Bei der Bearbeitung sollten folgende Grundsätze beachtet werden:\n\nWir verzichten auf individuelle Autor*innenschaft an einzelnen Textteilen. Alle können an allen Teilen mitarbeiten.\nDas Handbuch ist keine wissenschaftliche Arbeit, sondern soll einen Überblick geben. Für Details kann auf weiterführende Quellen verwiesen werden.\n\nKontaktinformationen und Neuigkeiten zum Projekt finden sich auf der Seite https://www.th-wildau.de/book-sprint/ und in den Artikeln von Bach (2022) und Christensen und Seeliger (2022).\n\n\n\n\n\n\nInfo\n\n\n\nWeitere Hinweise zur Mitarbeit und Details zur technischen Umsetzung des Handbuchs finden sich im Anhang."
  },
  {
    "objectID": "index.html#autorinnen",
    "href": "index.html#autorinnen",
    "title": "Handbuch IT in Bibliotheken",
    "section": "Beteiligte Autor*innen",
    "text": "Beteiligte Autor*innen\n\n\nNicolas Bach, Student an der HdM Stuttgart\nnicolas.bach at posteo dot de\nPascal-Nicolas Becker, Gründer und Geschäftsführer der The Library Code GmbH\nhttps://orcid.org/0000-0003-2169-1261 pascal at the-library-code dot de\nJanna Brechmacher, Stabstelle IT in der Benutzungsabteilung der Staatsbibliothek zu Berlin\nhttps://orcid.org/0000-0001-7233-7153 janna.brechmacher at sbb dot spk-berlin dot de\nSascha A. Carlin, Agile Coach für Führungskräfte in der Softwareentwicklung\nrqst at nvsbl dot cm\nAnne Christensen, Bibliothekarin und Projektmanagerin bei effective WEBWORK sowie Lehrbeauftragte an verschiedenen Hochschulen\nhttps://orcid.org/0000-0001-7753-1078 christensen at effective-webwork dot de\nJana Eger, Stadtbibliothek Chemnitz\njana.eger at stadtbibliothek-chemnitz dot de\nUlrike Golas, IT-Leitung der Universitätsbibliothek der TU Berlin\nhttps://orcid.org/0000-0002-6567-0000 ulrike.golas at tu-berlin dot de\nGerrit Gragert, Leitung IT-Services für die Digitale Bibliothek in der Staatsbibliothek Berlin\nhttps://orcid.org/0000-0002-0542-1555 gerrit.gragert at sbb dot spk-berlin dot de\nLambert Heller, Leitung Open Science Lab an der TIB - Leibniz‐Informationszentrum Technik und Naturwissenschaften\nhttps://orcid.org/0000-0003-0232-7085 lambert.heller at tib dot eu\nSina Hurnik, Studio für Kommunikationsdesign\nhttps://sinahurnik.com/\nClemens Kynast, Discoverysysteme & Bibliotheksautomatisierung an der ThULB Jena\nclemens.kynast at uni-jena dot de\nLukas Lerche, UB Dortmund\nhttps://orcid.org/0000-0002-4027-6840 lukas.lerche at tu-dortmund dot de\nLuis Moßburger\nhttps://orcid.org/0000-0002-5326-219X lmossburger at t-online dot de\nStefanie Nagel, Abteilungsleiterin Open Science an der Universitätsbibliothek TU Bergakademie Freiberg\nhttps://orcid.org/0000-0001-8020-1440 stefanie.nagel at ub dot tu-freiberg dot de\nSilvia Polla, Forschungsdatenmanagement, Bibliothek\nhttps://orcid.org/0000-0002-2395-2448 polla at wias-berlin dot de\nMichael Schaarwächter, Bibliotheks-IT an der UB Dortmund\nhttps://orcid.org/0000-0002-0180-5930 michael.schaarwaechter at tu-dortmund dot de\nFrank Seeliger, Bibliotheksleiter TH Wildau\nhttps://orcid.org/0000-0003-0602-8082 fseeliger at th-wildau dot de\nBritta Steinke, Referentin für Forschungsdatenmanagement\nhttps://orcid.org/0000-0001-6816-5168 b.steinke at tu-berlin dot de\nFlorian Strauß, Abteilungsleiter forschungsunterstützende Dienste Universitätsbibliothek Clausthal\nhttps://orcid.org/0000-0003-0168-0450 florian.strauss at tu-clausthal dot de\nJakob Voß, Forschung und Entwicklung an der VZG Göttingen\nhttps://orcid.org/0000-0002-7613-4123 jakob.voss at gbv dot de\nMichael Voss, Consultant; IT-Expert-Voss\nhttps://orcid.org/0000-0002-7402-1598 info at it-expert-voss dot de\nDavid Zellhöfer, Professor für Digitale Innovation in der öffentlichen Verwaltung an der HWR Berlin\nhttps://orcid.org/0000-0002-0403-457X david.zellhoefer at hwr-berlin dot de"
  },
  {
    "objectID": "index.html#rechte-an-den-inhalten-des-buchs",
    "href": "index.html#rechte-an-den-inhalten-des-buchs",
    "title": "Handbuch IT in Bibliotheken",
    "section": "Rechte an den Inhalten des Buchs",
    "text": "Rechte an den Inhalten des Buchs\nSoweit nicht anders in Quellenangaben ausgewiesen, stehen alle Inhalte dieses Buches unter der Lizenz Creative Commons Namensnennung 4.0 Deutschland (CC-BY 4.0 DE).\nDas heißt: Sie dürfen das Material in jedwedem Format oder Medium vervielfältigen und weiterverbreiten (Teilen) und das Material remixen, verändern und darauf aufbauen (Bearbeiten) und zwar für beliebige Zwecke, inklusive kommerzielle Zwecke, unter der Bedingung, dass Sie angemessene Urheber*innen- und Rechteangaben machen, einen Link zur Lizenz beifügen und angeben, ob Änderungen vorgenommen wurden (Namensnennung).\n\n\n\n\nBach, Nicolas. 2022. „Das Handbuch IT in Bibliotheken: Einblicke in den ersten bibliothekarischen Book Sprint Deutschlands“. Informationspraxis 8 (1). https://doi.org/10.11588/ip.2022.1.94475.\n\n\nChristensen, Anne, und Frank Seeliger. 2022. „„Wie schreiben wir gemeinsam ein nützliches Buch?”“. b.i.t.online 25 (6): 509–10. https://www.b-i-t-online.de/heft/2022-06-nachrichtenbeitrag-christensen.pdf.\n\n\nHanson, Cody. 2015. „Opinion: Libraries are Software“. 2015. https://www.codyh.com/writing/software.html."
  },
  {
    "objectID": "infrastruktur.html#einleitung",
    "href": "infrastruktur.html#einleitung",
    "title": "Technische Infrastruktur",
    "section": "Einleitung",
    "text": "Einleitung\nDie technische Infrastruktur einer Bibliothek umfasst alle IT-Systeme, die die Prozesse und Dienstleistungen einer Bibliothek abbilden, unterstützen oder ergänzen. Neben dem zentralen Bibliotheksmanagementsystem zur Verwaltung und Bereitstellung von Bibliotheksbeständen und Discovery-Systemen zur Recherche gibt es zahlreiche weitere etablierte Anwendungen von IT in Bibliotheken. Die in diesem Kapitel vorgestellte Infrastruktur ist grob nach Hauptanwendungsfall gegliedert in\n\nAllgemeine Infrastruktur für den grundlegenden Betrieb von Prozessen und Dienstleistungen in Bibliotheken wie Verbuchung und RFID\nDienste primär für Nutzer*innen wie Webseite, Internetzugang und Arbeitsplätze\nDienste primär für Mitarbeiter*innen wie Intranet und mobiles Arbeiten\n\nWeitgehend ausgeklammert, weil an anderer Stelle behandelt, bleiben forschungsnahe Dienste wie Repositories und Open Data, Infrastruktur zur Digitalisierung sowie Anwendungen für Kommunikation und Wissensmanagement.\n\n\n\n\n\n\nInfo\n\n\n\nZu Einführung und Betrieb und zur Entwicklung samt Anforderungsanalyse von IT-Systemen gibt es eigene Kapitel."
  },
  {
    "objectID": "infrastruktur.html#allgemeine-infrastruktur-für-bibliotheksprozesse-und--dienste",
    "href": "infrastruktur.html#allgemeine-infrastruktur-für-bibliotheksprozesse-und--dienste",
    "title": "Technische Infrastruktur",
    "section": "Allgemeine Infrastruktur für Bibliotheksprozesse und -dienste",
    "text": "Allgemeine Infrastruktur für Bibliotheksprozesse und -dienste\n\nVerbuchung\nZur Verbuchung zählen die Ausleihe und Rückgabe sowie die Verlängerung von Leihfristen. Für automatische Verbuchung müssen entsprechende Geräte vorhanden sein, um die für Medien eingesetzten Identifikationsmerkmale (Barcodes oder RFID-Tags) zu lesen und ggf. auch zu schreiben. Außerdem muss eine Kommunikation mit dem BMS stattfinden, um darin den entsprechenden Ausleih-, Rückbuchungs-, oder Verlängerungsvorgang durchzuführen. Hierzu muss außerdem eine Identifikation der Nutzer*innen erfolgen, also das Einlesen eines Ausweises oder das Anmelden mit gewissen Zugangsdaten und schließlich das Eintragen einer Ausleihe. Da es Nutzer*innen möglich sein sollte, die Rückgabe von Medien nachweisen zu können, wird bei der Rückgabe mit Verbuchung immer eine Quittung erzeugt. Dies erfolgt sowohl an den Ausleihtheken als auch bei Rückgabeautomaten. Eine weitere Möglichkeit ist das Bezahlen und Begleichen von Gebühren an gleicher Stelle.\n\n\nAutomaten\nZur Gestaltung eines Angebots, das über die Servicezeiten hinausgeht, ist der Einsatz von Automaten für Standarddienstleistungen sinnvoll. Vorgänge wie Ausleihe, Verlängerung und Rückgabe von Medien, Bezahlung von Gebühren oder auch die Abholung von Bestellungen können mit Automaten weitgehend ohne Personal realisiert werden.\nAusleihautomaten bestehen aus Lesegeräten für Ausweise, Lesegeräten für Medien und Entsicherungsgeräten für Buchsicherungen. Der Verbuchungsprozess beinhaltet eine Anmeldung (Ausweisnummer und ggf. Passwort), den eigentlichen Verbuchungsprozess inklusive Entsicherung der Medien, Ausgabe einer Quittung auf Papier oder als E-Mail sowie eine manuelle oder automatisierte Abmeldung.\nRückgabeautomaten sind in zwei Gruppen zu unterteilen. Im einfacheren Fall ist der Ausleihautomat auch gleichzeitig ein Rückgabeautomat. Der Anmeldeprozess kann hier entfallen, denn es ist grundsätzlich nicht relevant, wer das Medium zurückgibt. Die zurückgebrachten Medien werden dann durch die Nutzer*innen selbst auf einen Bücherwagen oder ein separates Regal gestellt und müssen anschließend durch das Bibliothekspersonal sortiert und eingestellt werden. Der zweite und komplexere Fall eines Rückgabeautomaten ist ein Eingabeschacht, der die Medien weiter transportiert, verbucht und sichert. Im einfachen Fall werden die Medien in einem Behälter gesammelt oder es ist ein automatisches Sortiersystem angebunden. Medien, die nicht zum Bestand der Bibliothek gehören und andere Gegenstände müssen bei der Rückgabe erkannt und zurückgewiesen werden.\nFernleihautomaten dienen der personalfreien Abholung von bestellten Fernleihmedien oder anderen bestellten Dingen, die nicht durch die Ausleihautomaten verbucht werden können, etwa weil sie keinen RFID-Tag besitzen. Nach dem Einlegen des abzuholenden Mediums durch Mitarbeiter*innen der Bibliothek werden Bestellende informiert (z.B. durch eine E-Mail), dass in einem Fach x etwas abzuholen sei. In diesem Vorgang kann man den Bestellenden auch ein PIN mitteilen, alternativ ist das Fach durch einen Bibliotheksausweis elektronisch zu öffnen. Wird das Fach geöffnet, wird zeitgleich das Medium im Nutzerkonto verbucht.\nKassenautomaten erlauben die Bezahlung von offenen Gebühren oder auch den Kauf von Gutscheinen/Tickets für Dienstleistungen, die im Anschluss in Anspruch genommen werden.\n\n\nMediensicherung\nMit dem Begriff wird die Methode beschrieben, am Ausgang der Bibliothek mittels einer Art von Schleusen Medien, ggf. auch Dinge des Interieurs, zu detektieren, die gesichert und insofern unverbucht sind. Eine absolute Absicherung gegen Verluste ist mit dieser Methode nicht zu erreichen. Der vornehmliche Einsatzzweck ist daher auch weniger die Verhinderung von vorsätzlichem Diebstahl, sondern vielmehr das Entdecken des versehentlichen Vergessens der Ausleihverbuchung.\nIm Fall von EM-Sicherung oder HF-RFID (siehe RFID) werden zur Erkennung ungesicherter Medien sogenannte Gates aufgestellt, durch die Menschen beim Verlassen der Bibliothek geleitet werden. In diesen Gates sind die entsprechende Detektionstechnologie sowie sowie Alarmsysteme (Ton und/oder Licht) verbaut. Im Fall von UHF-RFID kann man auf Gates verzichten, hier genügen wegen der großen Reichweite auch Antennen, die an der Decke montiert sind. Für die Anzeige der detektierten Medien kann auch ein Monitor verwendet werden, auf dem dann etwa gleich das entsprechende Buchcover angezeigt wird.\nDie Sicherungsanlagen können je nach Konfiguration auch als Besuchszähler genutzt werden. Die Aussagekraft der Zahlen ist zwar nicht exakt, aber hilfreich genug für eine Ermittlung der Auslastung.\n\n\nBezahlung\nIn Bibliotheken fallen an verschiedenen Stellen Gebühren oder andere zu zahlende Beträge an. Diese werden einerseits elektronisch erzeugt und z.B. im Bibliothekssystem gespeichert (z.B. Überziehungsgebühren) oder fallen andererseits direkt an (z.B. Verkaufspreise für Dubletten, Tragetaschen, …). Benötigt werden dafür Geräte, die bei Bezahlung den Betrag direkt dem System verbuchen können, in dem die Beträge erfasst sind, z.B. Kassenautomaten mit Anbindung an das Bibliothekssystem. An diesen Automaten können sich Nutzer*innen anmelden, erhalten eine Anzeige von offenen Posten und können sie direkt begleichen. Manche Bibliotheken erlauben lediglich die bargeldlose Zahlung, manche ermöglichen (auch) die Zahlung mit Bargeld. Unterschiedlich gehandhabt wird auch, ob die gesamte geschuldete Summe zu bezahlen ist oder ob einzelne Posten beglichen werden können. Mit dem Einsatz von Kassenautomaten können Bezahlvorgänge unabhängig von anwesendem Personal ermöglicht werden.\nAuch die Verbindung eines Bezahlterminals mit einem Ausleihautomaten ist möglich. Hier sind dann alle Prozesse für die Nutzer*innen an einem Gerät abwickelbar. Es sind Ausleihautomaten am Markt, die bargeldlose Bezahlung mit verschiedenen Bezahlssystmene (spezielle Debit-Karten, ec-Karten...) und/oder Bargeldzahlungen ermöglichen.\nDie Systeme für Bezahlung und Gebühren sind meist an die jeweiligen Finanzstellen einer Universität oder einer Stadt(verwaltung) angebunden.\n\n\nZugangskontrolle\nEine Zugangskontrolle zur Bibliothek ist relevant, wenn Nutzer*innen die Bibliothek oder Teile davon auch ohne Anwesenheit von Bibliothekspersonal vor Ort nutzen können sollen (Open Library). Im Regelfall sieht eine technische Umsetzung der Zugangskontrolle so aus, dass das Schließsystem des Gebäudes an das Identifikationssystem für die Nutzer*innen angebunden ist. Dies lässt sich beispielsweise mit Kartenlesegeräten am Eingang oder mit einem RFID-Terminal lösen, welches die Bibliotheksausweise einlesen und dem Schließsystem nach festgelegten Regeln mitteilen kann, ob die betreffende Person zur Nutzung der Ressource berechtigt ist. Die Nutzung sollte außerdem kurzzeitig im Rahmen des Datenschutz protokolliert werden.\n\n\nAuslastungszählung\nDie Ermittlung der Auslastung einer Einrichtung ist aus verschiedenen Gründen interessant: für statistische Zwecke, für eine Anzeige auf der Webseite als Service für Nutzer*innen oder wenn für einen Notfall wichtig ist die ungefähre Anzahl der im Gebäude Anwesenden zu erfahren.\nBei der Auswahl einer geeigneten Lösung muss zuerst festgelegt werden, ob eine exakte Zählung nötig ist, oder eine Approximation der Anwesenheitszahlen ausreichend ist.\nFolgende Umsetzungsmöglichkeiten sind für eine exakte Zählung in Erwägung zu ziehen: Auswertung der Zugangskontrollsysteme; Einsatz einer Drehschranke bzw. Vereinzelungsanlage, die nur Einzelpersonen durchlässt; Zählung durch Personal und Zählung durch CV (computer vision). Andere, relativ exakte, aber doch mit kleinen Ungenauigkeiten bei der Zählung behaftete Systeme sind die Zählung durch eine Lichtschranke, durch ein Radar etwa von einem Sicherungsgate (siehe Zugangskontrolle) und IR-Durchgangszähler mit Gruppenerkennung an der Decke montiert (bspw. Produkte der Firma Irisys).\nBei allen exakten Zählsystemen ist insbesondere die Frage des Datenschutzes zu beachten, da aus der Zählung die Nachverfolgung der Nutzer*innen nicht abgeleitet werden darf. Aus Datenschutzgründen ist auch der Einsatz von aufzeichnenden (Kamera-)Systemen im öffentlichen Raum immer sorgfältig abzuwägen.\nFür die approximative Auslastungszählung eignen sich neben anonymisierten Varianten der o.g. Möglichkeiten insbesondere auch die Auslastungsmessung von anderen Infrastruktursystemen, etwa dem öffentlich WLAN. Wenn davon ausgegangen werden kann, dass ein*e Nutzer*in (im Durchschnitt) ein Gerät im öffentlichen WLAN anmeldet, dann kann dies als guter Indikator dienen. Sollen die Zahlen der im WLAN angemeldeten Geräte zur Messung der Auslastung eines Gebäudes dienen, sind allerdings umfangreiche Justierungen notwendig. So zeigte sich z.B. an der UB Dortmund, dass zu Prüfungszeiten die Studierenden in der UB pro Person jeweils mehrere Endgeräte im WLAN nutzten – vermutlich mehrheitlich Smartphone und Notebook. Eine andere Möglichkeit ist die Auswertung der Nutzung von Arbeitsplätzen, etwa der Anteil gerade aktiv genutzter öffentlicher PCs, die Messung von Temperaturabweichungen von Innenräumen, oder die Messung der Lautstärke. In Luzern wurde erfolgreich mit Sensoren in Sitzen bzw. unter Tischplatten experimentiert.\n\n\nVor-Ort-Verlängerung\nDie Vor-Ort-Verlängerung ist ein Angebot der Bibliothek für Mitarbeiter*innen der zugehörigen Institution, also z.B. der Hochschule oder der Verwaltung. Hierbei wird der ausgeliehene Bestand nicht in der Bibliothek, sondern bei Nutzer*innen vor Ort, also im Büro, im Labor etc. erfasst und die entsprechenden Leihfristen verlängert. Technische Hilfsmittel wie RFID und an das BMS angebundene Schnittstellen erleichtern diesen Prozess.\n\n\nOpen Library\nUnter Open Library werden zwei verschiedene Phänomene zusammengefasst: einerseits ist die Open Library ein offenes Projekt zum Aufbau einer digitalen Bibliothek von frei verfügbaren digitalen Büchern oder Digitalisaten. Andererseits bezeichnet der Begriff den Zugang zu einer Bibliothek durch technische Infrastruktur, ganz ohne oder mit wenigen personellen Ressourcen. Einige Bibliotheken bieten auf diese Weise einen durchgehenden Zugang, andere Bibliotheken nutzen die Möglichkeiten, um ihre Öffnungszeiten zu erweitern.\nZugang erhalten in diesen Fällen ausschließlich autorisierte Benutzer*innen innerhalb und außerhalb der Öffnungszeiten der Bibliothek. In den Eingangsbereichen wird über Lesegeräte die Zugangsberechtigung geprüft. Hier kann es Altersbeschränkungen geben und auch ein gesperrter Bibliotheksausweis gewährt keinen Einlass.\nBuchsicherungsanlagen dienen dem Diebstahlschutz von gesicherten Medien und speichern Vorfälle per Video oder verständigen einen Wachdienst. Vorgemerkte Medien liegen in Vormerkregalen, teilweise auch sogenannten intelligenten Abholregalen oder Automaten bereit. Da das Medium auf ein*e Nutzer*in vorgemerkt ist, kann es nur von diesen ausgeliehen werden.\nEine Ausleihe erfolgt durch die Benutzung der Ausleihautomaten. Ausleihregeln sind im Bibliotheksmanagementsystem hinterlegt, werden bei der Verbuchung über den Automaten geprüft und das Medium entsprechend entsichert.\nDie Open Library ermöglicht zwar grundsätzlich den Zugang zu allen Medien, aber es gibt auch immer Teile des Bestands, die von der Selbstausleihe ausgeschlossen sind, z.B. Brettspiele, Tageszeitungen und ausleihbare Geräte.\n\n\nNavigation und Lokalisierung\nDamit Nutzer*innen die im OPAC bzw. Discovery-System gefundenen (physischen) Medien auch nutzen können, müssen sie den entsprechenden Regalstandort aufsuchen. Zur Orientierung wird häufig die Aufstellungssystematik der Medien genutzt und im Rechercheergebnis steht, unter welcher Signatur, in welchem Regal, in welcher Etage ein Buch zu finden ist.\nIn kleineren Bibliotheken kann eine solche Standortangabe zusammen mit der Beschilderung des Gebäudes vor Ort ausreichen, um die Medien zu lokalisieren. Je größer jedoch der Bestand und die Räume einer Bibliothek sind, desto schwieriger ist diese Aufgabe.\nFür das einfachere Auffinden von Regalstandorten gibt es verschiedene Visualisierungsmöglichkeiten. Im einfachsten Fall kann der genaue oder ungefähre Standort eines Mediums auf einer statischen oder sogar interaktiven Karte angezeigt werden. Eine solche Karte könnte hierbei direkt beim Suchtreffer im Katalog angezeigt werden, oder als dediziertes Terminal vor Ort vorhanden sein. Anhand der Karte können sich Nutzer*innen dann zum Buch bewegen.\nTechnisch komplexer ist es nun, wenn eine solche Karte nicht nur den Standort des Buches, sondern gleichzeitig auch den aktuellen Live-Standort des/der Nutzer*in visualisieren soll. In einem solchen Fall, der etwa einer Google-Maps Karte gleicht, muss zusätzlich technischer Aufwand betrieben werden, um den aktuellen Nutzerstandort zu ermitteln. Im Gegensatz zu Karten und Navigationslösungen in Automobilen oder unterwegs mit dem Smartphone, kann allerdings innerhalb von Gebäuden nicht auf GPS-Satelliten zur Positionsbestimmung zurückgegriffen werden, sondern es müssen andere Signale oder Ortungspunkte genutzt werden, um den Standort der Person im Raum zu ermitteln.\nMögliche Ansätze sind hierbei etwa sog. Beacons, die mit Funklösungen wie Bluetooth und Triangulation die Position eines Mobiltelefons ermitteln, oder bildbasierte Lösungen, die über die Smartphonekamera bestimmte Objekte oder Marker im Raum erkennen.\nDie Standorte von physischen Medien sind über eine Zuordnung von Signaturen zu Regalen, teilweise sogar auch zu einzelnen Regalbrettern, einfach möglich. Dies bedingt allerdings eine systematische Aufstellung, die in Zeiten von mehrheitlich elektronischen Medien und immer weniger Printmedien nicht mehr hilfreich ist. So sollte ursprünglich eine Systematik am Regal den Bestand zu einem bestimmten Thema abbilden, man sollte über die benachbarten Bücher einen Überblick zu einem Thema bekommen können. Da aber bspw. E-Books nicht im Regal auftauchen, stellt sich die Frage nach der Aufstellung von gedruckten Medien in den Lesesälen neu. Eine Alternative zur systematischen Aufstellung kann die dynamische Aufstellung sein. So kann man z.B. ohne Umsignierungen temporäre Sammlungen bilden. Man kann darüber nachdenken, ob die Nutzer*innen ausgeliehene Bücher selbst zurückgeben können, indem sie sie einfach an einen freien Platz im Regal stellen. Man kann die Nutzer*innen die früher so ungeliebten „Nester“, also die Konzentration von Büchern an einer beliebigen nicht systematischen Stelle, bilden lassen, so dass vielleicht auch andere von dieser „eigenen“ Systematik profitieren. Dies bedingt natürlich eine technische Lösung, mittels der die Bücher anschließend auch wiedergefunden werden, also irgendwie geortet werden können (siehe auch der Abschnitt Revision).\n\n\nSortiersysteme\nMedien-Sortieranlagen sind in der Regel direkt an den Rückgabeautomaten angeschlossen. Nutzer*innen legen Medien in einen Schacht, in dem die Medien erfasst, zurückgebucht und gleichzeitig gesichert werden. Fließbänder oder Rollen transportieren das Medium entsprechend vorher definierte Ziele, z.B. bestimmte Signaturbereiche, andere Zweigstellen oder vorgemerkte Medien.\nDie Anschaffung einer Sortieranlage ist mit hohen Kosten verbunden, sowohl für die eigentliche Anschaffung und Installation als auch für die Wartung. Eine Kosten-Nutzen-Analyse (Anzahl Ausleihen/Rückgaben, Personaleinsatz, Platzbedarf) sollte daher vor der Entscheidungsfindung unbedingt durchgeführt werden. Insbesondere in öffentlichen Bibliotheken sollte außerdem immer bedacht werden, dass nicht alle Medien über das Sortiersystem zurückgenommen werden können (siehe Medienarten). Auch sehr kleine, leichte oder besonders große, schwere Medienarten müssen i.d.R. gesondert zurückgebucht werden.\n\n\nRevision\nDie Aufstellung der Medien in einer Systematik ist die Grundlage des Auffindens dieser Medien. Durch die übliche Zirkulation (Ausleihe, Rückgabe, Wiedereinstellen) und selbst schon beim Stöbern vor Ort ist die korrekte Aufstellung latent gefährdet – es entsteht Unordnung.\nTechnische Mittel zur Unterstützung bzw. Vereinfachung von Inventur und Revision sind daher gern verwendete Hilfen bei der Kontrolle oder Wiederherstellung der korrekten Aufstellung.\nFür die Auswahl von geeigneten Werkzeugen können zwei Fragestellungen herangezogen werden:\n\nIst das (nicht ausgeliehene) Medium im Haus?\nIst das (nicht ausgeliehene) Medium am richtigen Platz?\n\nDie zweite Frage ist eine Konkretisierung der ersten und bereits ein Hinweis auf die unterschiedliche Leistungsfähigkeit der Hilfsmittel bzw. auf das geeignete Vorgehen bei Inventur und Revision.\nDas klassische Vorgehen ist das genaue Auffinden und Prüfen der Medien mit Hilfe einer Liste. Dies ermöglicht im besten Fall die Wiederherstellung der korrekten Aufstellung. Durch Digitalisierung der Liste und, sofern vorhanden, eine Anreicherung mit Cover-Bildern, kann eine Beschleunigung dieses Prozesses erreicht werden. Mobile Geräte wie Tablets mit geeigneten Apps oder Laptops auf Rollwagen beschleunigen den Prozess nochmals.\nRFID kann bei der Beantwortung der ersten Frage, ob Medien generell im Haus sind, sehr gut eingesetzt werden. Für die zweite Frage, ob Medien am richtigen Platz und auch noch in der richtigen Reihenfolge stehen, ist der Einsatz von RFID aufgrund der räumlichen Auflösung jedoch nur bis zu einem gewissen Grad geeignet. Hierbei ist die verwendete RFID Frequenz ein entscheidender Faktor. Durch die Lesereichweite von 0 bis ca. 35 cm bei der HF-Frequenz ist HF zwar gut geeignet, um ein konkretes Medium in einem kleinen Suchfeld zu finden. Durch Grenzen beim gleichzeitigen Lesen von vielen HF-Transpondern, die sich – wie in Regalen üblicherweise der Fall – nah beieinander befinden, ist es jedoch praktisch nicht besonders hilfreich.\nEine elektronisch unterstützte Inventur in HF-Bibliotheken kann auf zwei Arten durchgeführt werden. Die erste Möglichkeit ist das „Entlangwandern“ an den Regalen mit einem Tischtennisschläger-artigen Gerät, welches an den Buchrücken entlanggeführt wird. Die Genauigkeit dieser Art der Inventur ist bei weitem nicht absolut, da die Lesegenauigkeit stark vom Abstand/Winkel von Transponder zu Lesegerät abhängt (idealerweise sind Antenne und Transponder parallel ausgerichtet). Zudem stören Metallgegenstände (z.B. Metallregale) den Empfang.\nDie zweite Möglichkeit ist der Einsatz sogenannter Smart-Shelves. In diesen sind aktive RFID-Komponenten verbaut, die die Detektion der auf ihnen befindlichen Medien erlauben. Nachteilig sind hier die Kosten der Regale, die umgerechnet bei mehreren Euro pro detektiertem Medium liegen. Ein großes Manko bei den oben genannten Inventursystemen ist zudem die mangelnde Integration mit dem BMS bzw. eine ausgereifte Benutzungsoberfläche.\nAnders sieht es im UHF-Frequenzbereich aus. Durch die potentielle große Lesereichweite von bis zu ca. 12 Metern bei praktisch keiner Beschränkung der Anzahl der Transponder im Erfassungsfeld ist die Frage der prinzipiellen Präsenz eines Mediums gut zu beantworten. Gleichzeitig ist durch die große Lesereichweite die korrekte Aufstellung an einer konkreten Stelle nur durch einen hohen technischen Aufwand automatisiert zu prüfen.\nScan-Roboter, die regelmäßig den Bestand überprüfen (beispielsweise an der TU Dortmund), können derzeit mit einer Genauigkeit von ca. 1 Kubikmeter den Standort eines Transponders bestimmen. Die zur Zeit im Einsatz befindlichen Roboter der Firma Metralabs aus Ilmenau scannen den Bestand in sogenannten „Runs“, die etwa 30.000 Tags pro Stunde finden. Nach einem abgeschlossenen Run werden die Ergebnisse in einer CSV-Datei über einen Fileshare oder einfach per E-Mail geliefert. Enthalten sind darin u.a. Taginhalt und x,y,z-Koordinaten ausgehend von einem einmal festgelegten Nullpunkt. Diese Informationen können (und müssen) dann weiterverarbeitet werden. Denkbar ist eine Integration in den Katalog, so dass in einem Lageplan der Standort des Mediums angezeigt wird, sobald man darauf klickt. Eine Inventur über alle Daten ist möglich, wenn man die Daten abgleicht mit dem ausgeliehenen Bestand und die Fehlmenge ausweist. Eine Stellrevision ist etwas aufwändiger, da der Bestand dazu über längere Zeit überwacht werden und Abweichungen bestimmt werden müssen – wenn der genaue Soll-Standort jedes Mediums nicht in einer Tabelle erfasst ist, mit der der aktuelle Roboterdaten verglichen werden kann.\nFestzuhalten ist, dass auch die von den Robotern erhobenen Daten keine absolute Genauigkeit haben, sondern immer etwas „Schwund“ enthalten. Die Gründe für die Ungenauigkeit sind vielfältig: Reflexionen durch Metall-Anhäufungen im Suchfeld, verstellte Gänge zwischen den Regalen, die die Roboter am Durchfahren und Scannen hindern, sehr eng zusammenstehende Bücher, die verhindern, dass beide Tags gescannt werden usw. Mit einer Fehlerrate von ca. 1% ist beim Robotereinsatz zu rechnen.\n\n\nSmart Library\nAngelehnt an neologistische Komposita wie „smart home“, „smart industries“ (zu Deutsch ‚Industrie 4.0‘) oder „smart cities“ hielt ebenfalls die Kombination „smart“ und „library“ Einzug in die Welt der Informationseinrichtungen. Einzelne Produkte wie „smart shelves“ warben mit dem Label für neue Dienstleistungen über den Einsatz von RFID-Technologie. Insgesamt bezieht man das Konzept der „smart library“ auf Bibliotheken, die Informationstechnologien im Rahmen der Digitalisierung und Automatisierung auch in neuen Bereichen wie physischen Räumen, Nachaltigkeit und Vernetzung einsetzen (Freyberg und Wolf 2019; Seeliger 2019).\n\n\nRFID\nDer folgende Abschnitt gibt einen tieferen Einblick in die Thematik „RFID“, die für viele Teile der allgemeinen Infrastruktur (Verbuchung, Mediensicherung, Sortiersysteme…) relevant ist. Insbesondere im Hinblick auf Fragestellungen einer Migration oder Einführung von RFID-basierten Technologien für einen Bibliotheksbestand werden Grundlagen und Hintergründe erläutert, Speicherung und Datenmodelle diskutiert und Unterschiede zwischen Verschiedenen RFID-Technologien aufgezeigt. Weitere Informationen zum Einsatz von RFID in Bibliotheken siehe Seeliger (2014) und Kern (2011).\n\nRFID-Grundlagen\nRFID (radio frequency identification) ist eine Technologie, um Objekte mittels Funksignalen zu erfassen und zu orten. Die Objekte werden hierbei durch RFID-Tags (auch Etiketten oder Transponder genannt) markiert. Ein RFID-Tag enthält zumeist einen Schaltkreis (Speicher + Prozessor) und eine Antenne. Um mit einem RFID-Tag zu kommunizieren, wird ein Sende-/Empfangsgerät benötigt („RFID-Reader“), welches die Antenne über Funkwellen mit Strom versorgt („Induktion“) und danach mit dem Schaltkreis kommuniziert. Die meisten RFID-Tags sind „passiv“, da sie über die Antenne aus der Ferne mit Strom versorgt werden. Es existieren aber auch „aktive“ Tags, die eine Batterie enthalten. Aufgrund der dafür notwendigen Größe sowie der Kosten sind aktive Tags in Bibliotheken nicht im Einsatz. Die Kosten für passive Tags bewegen sich im Bereich von wenigen Cent pro Stück, natürlich stark abhängig von der Bestellmenge.\n„RFID“ ist nicht gleich „RFID“! Die Identifikation mittels Radiofrequenzen wird in verschiedenen Frequenzbereichen betrieben. Die Frequenzbereiche sind untereinander inkompatibel, Tags sind nur in einem Frequenzbereich betreibbar, die Schreib-/Lesegeräte sind ebenfalls dediziert auf den Frequenzbereich. Selten gibt es Geräte, die mehrere Frequenzbereiche lesen können, diese enthalten beide notwendigen Technologien. In europäischen Bibliotheken ist meistens ein sogenanntes RFID-HF im Einsatz, welches im Frequenzbereich von 3-30 MHz arbeitet. In der Industrie, in Bibliotheken in China und USA sowie in einzelnen Bibliotheken in Europa kommt RFID-UHF mit einer Frequenz von 868 MHz in Europa (andere Frequenzbereiche in anderen Gebieten) zum Einsatz. Der Hauptunterschied in der Anwendung zwischen den beiden Frequenzbereichen ist die Schreib-/Lesereichweite (siehe UHF oder HF?).\nNeben dem Beschreiben und Auslesen des Speicherchips aus der Ferne ist auch eine mehr oder minder präzise Ortung der Tags möglich. Die Ortung ist mit Ungenauigkeiten versehen, da in dem Frequenzbereich von RFID-UHF Reflexionen der Normalfall sind. Eine Lokalisierung ist also nur über die Kombination verschiedener Verfahren in sehr vielen Messungen und einiger Statistiken möglich und dennoch mit einer Unsicherheit versehen.\nNeben Bibliotheken finden sich RFID im Alltag auch oft im Einzelhandel, hier meist als Diebstahlsicherung, zur Inventur oder auch zum Erkennen der Artikel an der Kasse. Auch hier kommt bei neueren Installationen häufig RFID-UHF zum Einsatz. Kontaktlose Zahlungsmöglichkeiten auf Bankkarten (NFC) sind ebenfalls eine Anwendungsform von RFID.\n\n\nUHF oder HF, was sind Tags?\nIm deutschsprachigen Raum ist zur Zeit (2022) der Einsatz von RFID-HF verbreitet. Einzelne Bibliotheken setzen auch schon RFID-UHF ein (Beispiele: Bibliothek der Wirtschaftsuniversität Wien oder auch die Universitätsbibliothek Dortmund sowie die Bibliothek der Burg Giebichenstein Kunsthochschule Halle). In der Industrie ist RFID-HF praktisch nicht im Einsatz, was vermuten lässt, dass diese Technologie in einigen Jahren aussterben könnte. Die größere Reichweite von RFID-UHF ermöglicht zum Beispiel eine automatisierte Inventur / Stellrevision (siehe auch Abschnitt Revision). Auf der anderen Seite muss man die großen Reichweiten auch einschränken, um etwa bei Ausleihautomaten nicht das zu verbuchen, was sich in einem größeren Abstand befindet. Dies erfordert Kenntnisse in der Justage der Leistung und Signalstärke der eingesetzten Antennen (Dortmund) oder Abschirmung derselben (Wien).\nEin sichtbarer Unterschied der Transponder ist bedingt durch die beiden Funkfrequenzen HF (High Frequency: 13,56 MHz) und UHF (Ultra High Frequency: 860 bis 960 MHz). Höhere Frequenzen erfordern eine andere Bauform der Empfangsantennen in den Transpondern. HF Transponder haben durchschnittlich die Ausmaße einer Chipkarte, damit auf einer Fläche von ca. 10 bis 20 Quadratzentimetern eine spiralförmige Antenne in einem quadratischen oder rechteckigen Layout untergebracht werden kann. In der Mitte der Spirale ist der Mikrochip platziert. Je größer die Antennen sowohl in den Transpondern als auch in den Antennen der Geräte sind, desto besser funktioniert der Kommunikationsprozess.\nUHF Transponder hingegen haben üblicherweise Antennen in einer eher länglichen Bauform, bei der zwei symmetrische Antennenteile von einem Zentrum, in dem der Mikrochip platziert ist, in gegenüberliegende Richtungen zeigen. Hier ist weniger die Größe, sondern das für den jeweiligen Anwendungsfall am besten geeignete, konkrete Layout der Antennen für eine zuverlässige Kommunikation wichtig. Die Ausmaße eines typischerweise in Bibliotheken eingesetzten UHF RFID Tags sind ca 15 mm × 94 mm, es gibt aber auch kleinere Ausführungen.\nEs existieren ebenfalls Transponder, die sowohl mit UHF, als auch mit HF ansprechbar sind, was die Kosten pro Transponder deutlich erhöht, da zwei verschiedene Antennen vorhanden sein müssen. Beide Frequenzen gleichzeitig in einer Bibliothek zu verwenden, bringt keinen Vorteil, der diesen Aufwand rechtfertigen würde.\n\n\n\n\n\n\n\n\n\n\nAbbildung 1.1: HF Transponder und UHF Transponder\n\n\nDas unterschiedliche Layout der Transponder ist für das Einkleben in Büchern wenig relevant. Beide Arten werden bei der Herstellung auf Folie aufgebracht. Man unterscheidet verschiedene Ausprägungen der Weiterverarbeitung: „dry naked“ bezeichnet einen fortlaufenden Folienstreifen. auf den Chips und Antennen in gewissen Abständen aufgebracht sind. Hier gibt es keine Stanzung und keine Klebefläche. „wet inlay“ hingegen bezeichnet eine Weiterverarbeitung, die Klebemasse auf Trägerfolie enthält und gestanzt ist. Weitere Verarbeitung sorgt auf Wunsch für Papieroberfläche, so dass die Transponder auch bedruckt werden können. Hersteller von RFID-Transpondern (in der klebenden Version auch „Tags“ genannt) liefern oft nur „dry naked“, weiter verarbeitete Tags beschafft man von sogenannten „Konvertierern“ (nicht zu verwechseln mit dem manchmal so genannten Prozess der „Konvertierung“ des Medienidentifikators von Barcode zu RFID). Der verwendete Klebstoff genügt keiner hohen Anforderung, die in Bibliotheken mit seltenen Werken denkbar wäre. Langzeithaftung oder garantierte Unschädlichkeit des Klebstoffes für das Papiermaterial sind kein Thema für die Hersteller und nur für sehr viel Geld bei speziellen Konvertierern zu bekommen.\nRelevant für die Sichtbarkeit der technischen Komponenten in einer Bibliothek ist jedoch die Gegenseite der Transponder: die Schreib-/Lese- Geräte bzw. genauer gesagt deren Antennen. Die maximale Lesereichweite wird bei HF maßgeblich durch die Größe der Antennen, bei UHF hingegen hauptsächlich durch die Feldstärke bestimmt. Dementsprechend haben HF Antennen, die für die Buchsicherung beispielsweise an Ausgängen verwendet werden, die ungefähre Größe einer mittelgroßen Person und es werden üblicherweise zwei sich gegenüberstehende Antennen zu einem „Gate“ kombiniert, nicht zuletzt um die Leseentfernung auf ca. 80-100 cm zu verdoppeln und der Kontrolle der Transponder beim passieren einer Person durch das Gate zu ermöglichen. Ein solches Gate ist sichtbar, muss in die Architektur des Eingangsbereiches einer Bibliothek integriert werden und kann ggf. auch ein Hindernis darstellen (Rollstuhlfahrer, Fluchtwege). Für andere Anwendungen ist der Größenunterschied der Antennen der beiden Frequenzbereiche weniger relevant, wenn auch nicht komplett zu vernachlässigen: Eine Inventur mit HF bedingt eine gewisse Nähe der Sende/Empfangsantenne zu den Medien, ansonsten müssten die Antennen Ausmaße von mehreren Metern haben. Bei UHF hingegen werden auch Medien in größerer Entfernung erkannt (siehe auch im Abschnitt Revision). Typische Bibliotheks-Vorgänge wie die Ausleihe oder Rückgabe, egal ob an einer Theke oder an einer Selbstbedienungsstation, erfordern eine Lesereichweite von 0 bis maximal ca. 30 cm. Da sich bei beiden Frequenzen für diese Entfernung eine in etwa ähnliche Größe der Antennen ergibt, ist bei diesen Anwendungen der optische Unterschied der Geräte nicht sehr offensichtlich. Bedeutsam für diese Anwendungen ist allerdings die Anzahl der gleichzeitig im Stapel gut lesbaren Medien: bei HF sind es unter optimalen Voraussetzungen ca. 3 bis 8 Medien (je nach Größe bzw. Dicke) bei UHF ist diese Zahl nicht wirklich beschränkt. Beispielsweise werden im Extremfall problemlos 20 bis 30 Medien in einem Stapel gleichzeitig erkannt.\nUHF und HF unterscheiden sich außerdem durch den Speicherplatz, der auf dem Chip des Tags vorhanden ist. Faustformel ist: Je weiter gefunkt werden muss, desto energieintensiver ist der Prozess und desto weniger kann übertragen/gespeichert werden. Demzufolge ist auf einem UHF Tag im Regelfall weniger Platz als auf einem HF Tag. So wenig sogar, dass bei vielen üblichen Tags nicht beliebig lange Informationen auf einen Tag geschrieben werden können, sondern sich explizit darüber Gedanken machen muss, welche Daten gespeichert werden sollen. Es existieren allerdings auch spezielle Tags mit großem Speicher, auf denen man etwa das Dänische Datenmodell finden kann.\nRFID-Tags können in verschiedenen Dingen eingebracht werden, so gibt es Tags in Büchern, Schlüsselanhängern sowie auch mobile devices (NFC, Smartphones). Nicht alle Arten sind untereinander kompatibel, so kann man mit NFC in Smartphones zwar RFID-HF-Tags in Bibliotheken auslesen, nicht aber RFID-UHF-Tags.\nZu der Lebensdauer der Tags lässt sich bisher recht wenig sagen – was auch eine gute Nachricht ist, da sich im Zeitraum des Praxiseinsatzes von ca. 20 Jahren bisher keine nennenswerte Abnutzung der elektronischen Eigenschaften der Tags gezeigt hat. Den Klebstoff betreffend, mit dem die Tags in die Medien eingeklebt werden, gilt in Bibliotheken Altbekanntes. Schädigung von Papier und Langzeithaltbarkeit dieser Klebstoffe ist im Zusammenhang mit Barcodeetiketten gut erforscht (Kern 2011).\n\n\nRoboter und RFID\nRoboter können im Zusammenhang mit RFID genutzt werden, um Inventuren durchzuführen oder Stellrevisionen, also das Erkennen von verstellten Medien. Wegen der geringen Reichweite ist das mit RFID-HF nur unter großen Einschränkungen möglich. So wird in der Kunstbibliothek Sitterwerk in St. Gallen eine nächtliche Inventur und Lokalisierung der Bücher vorgenommen, um eine dynamische Aufstellung zu realisieren. Dazu wird eine aktive RFID-Komponente nachts sehr dicht am Regal entlanggeführt, um die RFID-Tags auszulesen. Das funktioniert aus (mechanischen) Sicherheitsgründen nur in der Schließungszeit, die Lokalisierungsinformation der Medien ist also tagsüber bei viel Betrieb nicht sehr wertvoll, da veraltet. Weil in der dortigen Bibliothek nicht sehr viel Betrieb ist, ist das aber dort kein großer Schaden.\nFür eine Bibliothek mit großem Bestand und viel Betrieb ist der Einsatz von RFID-UHF für Inventur und Lokalisierung sinnvoller. Roboter etwa der Firma Metralabs (Illmenau) sind seit einigen Jahren in Betrieben wie Adler und Conrad, aber auch in hunderten australischen Supermärkten, unterwegs, um laufende Inventuren auch in Umgebung mit Menschen durchzuführen. Seit 2020 gibt es an der UB Dortmund solche Roboter, die in einem RFID-UHF-getaggten Bestand nicht nur Lokalisierung, sondern auch Stellrevisionen durchführen. Auch werden vermisste Medien (also Medien, die nicht am erwarteten Standort auffindbar sind) damit wiedergefunden. Aufgrund der physikalischen Eigenschaften von RFID (Reflexionen der Funkwellen im Raum an vielen Materialien) ist trotz hundertfacher Sichtung eines Tags durch den Roboter in einem „Run“ (ein kompletter Scan) bisher die Genauigkeit auf ca 50 cm in jeder Raumachse beschränkt. In der Praxis bedeutet dies, dass die vom Roboter gelieferte Koordinate für den Aufenthaltsort eines RFID-UHF-Tags in einem kugelförmigen Wahrscheinlichkeitsraum mit einem Meter Durchmesser zu betrachten ist – sprich, man muss das Buch im Umkreis von einem Meter von der Ortsangabe suchen. Das ist für eine Stellrevision zwar besser als gar keine Angabe, genügt aber noch nicht, um Nutzer*innen mit diesen Informationen genau zum Buch zu leiten. Auf diesem Gebiet wird weiterentwickelt, unter Laborbedingungen wurde bereits eine Ortungsgenauigkeit von unter 10 cm erreicht.\n\n\nMigration RFID\nDie Migration von einer Technologie zur anderen führt unweigerlich zu drei Fragen:\n\nAuf welche Technologie soll ich migrieren?\nWas genau muss migriert werden?\nWie führe ich den Prozess der Migration durch?\n\nIn den letzten Abschnitten schon angeklungen ist der Unterschied von HF und UHF, wodurch sich in den meisten Fällen die Frage der Technologiewahl als erste stellt. Als Faustregel kann hier festgestellt werden, dass die schon langjährige Verbreitung von HF im DACH-Raum dazu geführt hat, dass einige Anbieter mit Standardlösungen am Markt sind und für die meisten Anwendungsfälle abgedeckt sind, inkl. dem Migrationspfad von Barcodes.\nBei der Migration an sich geht es dann zumeist darum, das Identifikationsmerkmal eines Mediums auf ein RFID-Tag abzubilden. Hier existieren mehrere Ansätze: Es kann ein RFID-Tag „von der Stange“ ohne Beschreiben in ein Buch eingebracht werden, dessen eindeutiger Identifikator ausgelesen und – zumeist im BMS – mit dem jeweiligen Medium verknüpft werden. Eine andere Möglichkeit wäre das Beschreiben des RFID-Tags mit einem Identifikator, etwa der Mediennummer, einer eindeutigen Signatur oder einer komplexeren Datentstruktur wie dem Dänischen Datenmodell (siehe folgender Abschnitt).\nSchließlich muss der Prozess der Migration gewählt und durchgeführt werden. Das Einkleben und zumindest Auslesen, ggf. aber auch Beschreiben eines RFID-Tags ist eine Aufgabe, die entweder von der Belegschaft einer Bibliothek oder als eingekaufte Dienstleistung durchgeführt werden kann. Erfahrungen zeigen, dass die eingekaufte Dienstleistung in drastisch kürzerer Zeit mit der Aufgabe fertig wird, als wenn dafür nur eigenes Personal eingesetzt wird. Eine typische Zeit für das Taggen eines Buches mit außen angebrachtem Barcode (also Einkleben eines leeren RFID-Tags, Auslesen des Barcodes, Schreiben der Infos des Barcodes auf das RFID-Tag) sind 20 Sekunden inklusive Verbringungsarbeiten (Erfahrungswert der UB Dortmund, Mittelwert beim Taggen von 860.000 Medien an vier Standorten durch einen externen Dienstleister). Es bietet sich an, im gleichen Atemzug auch eine Inventur des Bestands durchzuführen.\nDer Wechsel von RFID-HF auf RFID-UHF ist noch nicht erprobt, sollte aber keine größeren Probleme darstellen als der Wechsel von Barcode zu RFID. Ein RFID-HF-Tag und ein RFID-UHF-Tag können nebeneinander in einem Buch geklebt und sicher ausgelesen werden. Einige Hersteller von RFID-Hardware bieten auch hybride Geräte an, die beide Arten von Tags auslesen können.\nEin Wechsel von RFID-UHF zu RFID-HF erscheint nicht sinnvoll und wird daher hier nicht betrachtet. Grundsätzlich gilt dabei aber das gleiche wie im vorherigen Absatz.\n\n\nDatenmodelle\nFür die Inhalte von HF-Tags in Bibliotheken wurde das sogenannte „Dänische Datenmodell“ spezifiziert, welches später in der ISO-Norm ISO 28560 Teil 3 aufgegangen ist. Generell wird das Datenmodell in der ISO 28560 spezifiziert. Sie enthält heute drei Teile mit folgendem Inhalt: ISO 28560-1 enthält eine Beschreibung vielfältiger, für Bibliotheken denkbarer Datenfelder. Dies sind neben der Mediennummer auch der Titel von Büchern und weitere Daten, welche eventuell offline verfügbar auf dem Chip sein sollten. Aus den Elementen kann für jedes Land ein „Profil“« zusammengestellt werden. ISO 28560 Teil 2 basiert wiederum auf ISO 15962 und den oben genannten OIDs. Er wird in den angelsächsischen Ländern stark propagiert. In diesen Ländern sind bisher vorwiegend proprietäre Datenmodelle im Einsatz, das Dänische Modell kaum verbreitet. ISO 28560 Teil 3 entspricht zu fast hundert Prozent dem Dänischen Datenmodell. Es ist im Vergleich zum Teil 2 zwar fest kodiert, aber deutlich einfacher strukturiert (Kern2014).\nAls Referenz für das Datenmodell auf einem Tag dient die Norm ISO 28560 in drei Teilen:\n\nTeil 1 beschreibt die erforderlichen und optionalen Datenfelder, die länderspezifisch in Profilen zusammengestellt werden können. Die Felder werden hierbei als OID bezeichnet.\nTeil 2 beschreibt die Anordnung dieser Felder (OIDs) in einem flexiblen bzw. fließenden Speicherlayout und wird primär in angelsächsischen Ländern angewandt.\nTeil 3 der ISO 28560 entspricht dem immer noch häufig im Sprachgebrauch genutzten Begriff des Dänischen Datenmodells und beschreibt die feste Struktur der Daten in verschiedenen anwendungsspezifischen Blöcken.\n\nDiese Norm sollte ursprünglich einerseits die Interoperabilität zwischen Bibliotheken ermöglichen. Es sollte also möglich sein, ein Buch einer fremden Bibliothek mit dem eigenen System zu verbuchen. In Deutschland oder in Österreich wird dies nicht flächendeckend (vorsichtig ausgedrückt) angewendet. In der Schweiz ist das hingegen üblich und wegen der zentralen Magazinbibliothek auch notwendig. Andererseits sollte eine Interoperabilität zwischen BMS und RFID-Infrastruktur ermöglicht werden, damit einzelne Komponenten des Systems problemlos ausgetauscht werden können, ohne die Funktionalität zu gefährden.\nDie Informationen, die im Dänischen Datenmodell in einem RFID-Tag gehalten werden, sind teilweise Daten, die auch schon im BMS über ein Medium vorgehalten werden. Das Dänische Datenmodell ist von seinem Format so komplex bzw umfangreich, dass es wegen des geringeren zur Verfügung stehenden Speichers nicht auf beliebige UHF-Tags geschrieben werden kann, sondern explizit UHF-Tags mit großen Speicher genutzt werden müssen. Der geringere Speicher von den meisten UHF-Tags erlaubt lediglich die Speicherung einer Bibliotheks-ID, einer ID des Mediums (auch „Mediennummer“ oder „Strichcode“ genannt) und natürlich eines Bits, welches den Sicherungsstatus speichert.\n\n\nExkurs: Speicherung von Informationen auf Strichcodes und RFID-Tags\nUm Informationen, wie etwa eine Mediennummer, eine Signatur oder eine komplexere Datenstruktur – wie das Dänische Datenmodell – auf einem Identifikationsmerkmal, wie einem Barcode, einem QR-Code oder einem RFID-Tag in maschinenlesbarer Form abzuspeichern, muss die Information entsprechend dem jeweiligen Zielformat encodiert werden. Im Folgenden wird beispielhaft für Barcodes und RFID-Tags erläutert, wie so etwas funktioniert.\nBarcodes sind weit verbreitet, beispielsweise auf Produkten im Supermarkt. Meistens steht unter einem Barcode im Klartext, welche Nummern- oder Buchstabenfolge sich hinter einem Barcode verbirgt. Allerdings ist nicht jeder Barcode wie ein anderer. Es existieren verschiedene Formate, die sich darin unterscheiden, durch welche Strich- und Leerplatzfolge jeweils einzelne Zeichen dargestellt werden. Je weniger Zeichen von einem Barcodeformat unterstützt werden sollen, desto weniger Striche werden pro Zeichen benötigt und desto kompakter wird der Barcode (siehe Strichcode in Wikipedia).\nFolgendes Beispiel stellt einen Barcode im Code39-Format dar, welches in Bibliotheken verbreitet ist und Zahlen, Großbuchstaben und ein paar wenige Sonderzeichen darstellen kann.\n\n\n\nBeispiel für einen Code39 Barcode\n\n\nQR-Codes funktionieren analog, erweitern allerdings die Darstellung um eine zweite Dimension, sodass auf weniger Platz mehr Informationen dargestellt werden können. Gleichzeitig enthalten QR-Codes eine Prüfsumme, die Fehler bei der Erkennung, etwa bei Beschädigungen am Code, ausgleichen können.\nEin RFID-Tag enthält einen Speicherchip und hält daher seine Informationen in Bits und Bytes, genau so, wie Daten und Dateien auch auf einem Computer gespeichert werden. Wie sich jeweils eine Information aus Bits und Bytes interpretieren lässt (ganz so, wie man aus den Balken eines Barcodes Buchstaben und Zahlen interpretiert), hängt von der jeweiligen Encodierung ab, wobei der Speicher eines Tags auch in unterschiedliche Encodierungsformate aufgeteilt werden kann, um Platz zu sparen.\nFolgendes Beispiel zeigt einen Speicherbereich, wie er auf dem Chip eines Tags vorkommen könnte:\n\n\n\nBeispiel für einen Speicherbereich auf einem RFID-Tag\n\n\nHierbei ist der Speicher 32 Bit klein, was (geteilt durch 8) genau 4 Byte entspricht. Die einzelnen Bits können entweder 0 oder 1 sein und eine zweistellige Darstellung von jeweils 8 Bit als Byte nutzt die Werte von 00 bis FF im Hexadezimalsystem. Der Speicher, auf dem nun 19E9B6EA steht, wird in diesem Beispiel wie folgt encodiert: Die ersten beiden Byte sollen nach URN Code 40 gelesen werden, ein Verfahren mit dem man Text kompakt darstellen kann ähnlich der Idee hinter Code39 (IPC RFID STANDARD FOR INDENTIFYING POSTAL ITEMS BASED ON THE UPU S10 CODE, USING THE ISO/IEC 18000-63 PROTOCOL, Version 1.0, Februar 2017, Seite 33ff). Damit ergibt sich der Text „DE2“. Die letzten beiden Byte sollen hier einfach als Zahl gelesen werden. Die hexadezimale Zahl B6EA wird im Dezimalraum zu 46826. Das Beispielhafte RFID-Tag würde hier also etwa eine Präfixkennung DE2 für die Bibliothek enthalten, sowie eine fortlaufende Mediennummer. Würden wir vereinbaren, auch URN40 für die letzten zwei Byte des Speichers zu nutzen, so hätten wir nur die Möglichkeit, Zahlen von 000 bis 999 (bzw. dann auch dreistelligen Text) zu encodieren. Daher die wechselnde Encodierung.\nKomplexere Datenmodelle, wie das Dänische Datenmodell, brauchen demzufolge deutlich mehr Speicherplatz, um auf ein Tag zu passen.\n\n\nSteuerkommandos, Arten des Zugriffs\nRFID-Geräte kommunizieren mit RFID-Tags über verschiedene sog. Steuerkommandos. Analog zur Barcodes, die von einem Drucker gedruckt werden (WRITE) und von einer Lesepistole eingelesen werden (READ), so gibt es ähnliche Steuerkommandos auch für RFID-Tags, wobei diese entsprechende Kommunikation zwischen RFID-Gerät und Tag auslösen. Je nach Technologie (HF, UHF bzw. sogar nach technischer Spezifikation der Tags, SLI, SLI-S, SLI-X) existieren verschiedene Kommandos, die verschiedene Aktionen mit einem Tag auslösen. Ohne in technische Details zu gehen lassen sich diese Kommandos grob wie folgt abstrahieren: READ, WRITE, SECURE, UNSECURE, KILL, PROTECT. Dies entspricht der natürlichen Interaktion mit den Tags, etwa beim Inventarisieren neuer Bücher (WRITE), dem Verbuchen (READ, dann UNSECURE) oder dem Durchschreiten eines Gates (prüfen auf SECURED).\nBei der Nutzung von Bibliotheksgeräten, die RFID einsetzen, kommt man im Normalfall nicht mit den Steuerkommandos von RFID-Hardware in Berührung. Sollte man aber mit der Hardware selber experimentieren oder testen, wird man manchmal auch roh auf die Tags schreiben müssen.\n\n\nSicherheit und Datenschutz\nRFID-Tags können auf zwei Arten manipuliert werden: Einerseits kann man mittels geeigneter Hardware (im Falle von RFID-HF genügt ein Smartphone) den Inhalt eines nicht schreibgeschützten Tags verändern. Dies betrifft sowohl das Sicherungsbit (das Gate schlägt also nicht mehr an, wenn ein so manipuliertes Medium herausgetragen wird) als auch den gesamten Tag Inhalt, so dass das Medium von der Infrastruktur der Bibliothek nicht mehr verarbeitet werden kann. Andererseits kann man die meisten UHF-Tags und manche HF-Tags mit einem einfachen Befehl zerstören, also dauerhaft und endgültig stummschalten. Beide Arten der Manipulation kann man mit einem Passwortschutz wirkungsvoll verhindern (fun-fact: die meisten in Deutschland eingesetzten HF-Systeme enthalten diesen Passwortschutz nicht, sind also nicht vor einfachsten Manipulationen geschützt).\nBei der Einführung von RFID werden häufig Diskussionen zum Thema Datenschutz geführt. Wenn allerdings die Tags lediglich mit einer nur intern bekannten ID beschrieben werden, also einer ID, die nicht öffentlich im Katalog des BMS einsehbar ist, besteht diese Gefahr nicht. Selbst wenn jemand Medien im Rucksack eine*r Nutzer*in scannen würde (was technisch nicht unaufwändig ist), könnte man daraus keine Rückschlüsse auf das betreffende Medium schließen.\n\n\nAnbindung von RFID-Infrastruktur an BMS\nDamit ein Gerät einer RFID-Infrastruktur mit dem Rest der Systeme einer Bibliothek, insbesondere dem BMS, kommunizieren kann, muss es über entsprechende Schnittstellen angebunden werden. Bei der Anschaffung sollte daher darauf geachtet werden, dass die Anlage etwa die standardisierten Schnittstellen wie SIP2 oder NCIP nutzt, um Dienstleistungen wie Rückgabe, Sortierung und Ausleihe mit dem Bibliothekssystem abwickeln zu können (Michaelis 2014).\nDie Anbindung von lokalen RFID-Readern an Computerarbeitsplätzen von Mitarbeiter*innen erfolgt im Regelfall durch das Anschließen eines solchen Gerätes direkt am Arbeitsplatz, zumeist über USB. Es existieren allerdings auch Reader, die über einen Netzwerkanschluss direkt mit dem Netz der Einrichtung verbunden werden können und dadurch weitere Flexibilität ermöglichen, da kein Gerät an einen lokalen Computer angesteckt werden muss.\nIm Vergleich zu Barcode-Lesern, die den Inhalt eines gelesenen Barcodes meist einfach als Tastatureingaben an die Position des Cursors am Bildschirm ausgeben, können RFID-Geräte aufgrund der auch komplexen Inhalte von RFID-Tags (siehe Datenmodelle) auch mittels Programmierschnittstellen aus dem BMS oder anderen Systemen angesprochen werden. Die Logik der Interpretation des des Taginhalts liegt hierbei dann beim BMS, oder bei einer Zwischensoftware („Proxy“) die zwischen Reader und BMS vermittelt.\n\n\nMedienarten\nRFID-Transponder sind nicht für alle Medienarten geeignet. Aufgrund der Tatsache, dass RFID-Tags über Funkwellen mit Strom versorgt werden und kommunizieren, gilt, dass die Tags durch das Vorhandensein von Metall, Wasser, o.ä. beeinflusst oder abgeschirmt werden können. Selten vorkommende metallisch beschichtete Einbände von Bücher zum Beispiel verhindern effizient die Nutzung von RFID. Konkret bedeutet das, dass die Antenne eines RFID-Tags im Regelfall nicht mehr funktioniert, wenn sie in direkter Nähe zu metallischen Oberflächen ist: Eine CD, ein Laptop im Rucksack, oder sogar ein anderen RFID-Tag in einem dünnen Buchstapel können die Reichweite und Lesbarkeit einschränken. Beim Einbringen von Tags ist daher darauf zu achten, dass sie nicht auf solche Materialien aufgebracht werden. Ebenfalls hilft es nicht, ein Tag auf die Außenseite eines metallischen Gegenstands aufzubringen.\nGenerell sollte der Gegenstand, auf den ein Tag aufgebracht wird, von Funkwellen durchdrungen werden können, zumindest aber von der Seite, an der das Tag aufgebracht wurde.\nGleichzeitig bedeutet das auch, dass RFID-Tags durch das Vorhandensein von Wasser, also Menschen, ebenfalls abgeschirmt werden können. Eine hunderprozentige Erkennungsrate in einem Sicherheitsgate ist somit unrealistisch.\nRFID-Transpoder sind natürlich nicht geeignet für Medien, bei denen eine Unwucht störend ist (Schallplatten, CDs), sie sollten dabei auf der Außenhülle angebracht weren. Bei CDs ist zusätzlich der Metallanteil der CD störend.\nDazu kommt, dass RFID-Tags unterschiedlicher Hersteller und Arten unterschiedlich auf verschiedene Umgebungen reagieren. Für UHF wird vom Unternehmen EECC eine Studie herausgegeben die die physikalischen Eigenschaften von verschiedenen Tags untersucht („UHF RFID Almanach 2022“ 2022). Um diese Studie nutzen zu können, sind allerdings fundierte physikalische Kenntnisse notwendig, alternativ kann die Firma um mit einer Empfehlung beauftragt werden, wie 2019 in der UB Dortmund geschehen.\nNach Einführung von RFID ist das Weiterführen von Barcodes zur Identifikation zwar nicht mehr zwangsläufig erforderlich, es ergeben sich aber zwei Vorteile, insofern weiterhin der Barcode mit am oder im Medium angebracht wird. Durch den Barcode kann das Medium weiterhin maschinenlesbar identifiziert werden. Falls RFID Komponenten mal ausfallen sollten, kann mit dem Barcode traditionell weiter gearbeitet werden. Wenn außerdem (wie meist üblich) unter dem Barcode auch die im Barcode codierten Zeichen mit zu sehen sind, können auch Menschen das Medium bzw. den Band problemlos eindeutig identifizieren. Barcodes können dabei auch auf ein mit Papier beschichtetes RFID-Tag aufgebracht werden.\nAuf die Barcodes kann beim Einsatz von RFID auch verzichtet werden, wenn in Kauf genommen wird, dass man für die Identifikation eines Buches eine Recherche im BMS durchführen muss, wenn das Tag unlesbar oder falsch beschrieben ist.\n\n\nAlternativen zu RFID in Bibliotheken\nFortgeschrittene Entwicklungen im Bereich OCR und generell CV (computer vision) können es ermöglichen, ganz ohne technisch lesbare Identifikationsmerkmale ein Buch zu erkennen und zu verarbeiten. Bei einer solchen Lösung wird mittels einer Kamera das Äußere eines Mediums aufgenommen und erkannt und kann somit weiterverarbeitet werden. Um das Medium einer Bibliothek zuzuordnen kann weiterhin etwa ein Aufkleber auf dem Buchen, z.B. ein Signaturetikett auf dem Rücken, erkannt werden, um das Buch der Bibliothek zuordnen zu können und ggf. mehrere Exemplare auseinander halten zu können.\nBisher ist kein solches System aktiv im Einsatz; die Erkennung von Objekten ist jedoch ein aktives Forschungsthema.\nVollständige Automatisierung ist in Bibliotheken auch möglich mit Barcodeverbuchung und EM-Sicherung. Wenn die Barcodes vorn außen am Buch angebracht sind, können sie auch von Ausleihautomaten und Rückgabeautomaten gelesen und verarbeitet werden. EM-Sicherung wird realisiert mittels magnetisierbaren Streifen, die mit doppelt klebendem Film in den Falz der Bücher geklebt wird. Diese Streifen sind über separate Geräte magnetisierbar bzw. entmagnetisierbar. Der Status ist detektierbar über spezielle Gates, so dass darüber die Buchsicherung realisierbar ist. Auch diese Sicherung ist natürlich fehleranfällig und nicht 100%ig. Schon metallene Gegenstände in derselben Tasche wie gesicherte Bücher verhindern die Erkennung. Es gibt bei dieser Methode also keinen Vorteil gegenüber eines RFID-Betriebs – im Gegenteil, diese Technologie ist veraltet, wird immer seltener genutzt und insofern immer teurer."
  },
  {
    "objectID": "infrastruktur.html#dienste-für-nutzerinnen",
    "href": "infrastruktur.html#dienste-für-nutzerinnen",
    "title": "Technische Infrastruktur",
    "section": "Dienste für Nutzer*innen",
    "text": "Dienste für Nutzer*innen\n\nWebsite, Landingpages und Newsletter\nEine Internetpräsenz ist für eine öffentliche Einrichtung mittlerweile unabdingbar und dient vielen Nutzer*innen als Erstkontaktmöglichkeit, Arbeitsmittel und Informtionsplattform gleichermaßen.\nEine technische Basis für eine Onlinepräsenz wird manchmal von hiesigen Verwaltungen oder Rechenzentren gestellt, allerdings sollte auch hier darauf geachtet werden, dass die Grundfragen und -dienste mit einer solch vorgefertigten Variante umgesetzt werden können. Alternativ kann es auch sein, dass allein die technische Basis – ein (Web-)server – bereitgestellt wird und sich die jeweilige Einrichtung selbst um die Umsetzung einer Webseite kümmern muss.\nFolgende Basisinformationen für Bibliotheksbesucher*innen und Interessierte sollten zu finden sein\n\nÖffnungszeiten, Anmeldemodalitäten, Gebühreninformationen\nVeranstaltungshinweise\nDigitale Angebote\nFachspezifische Angebote wie medienpädagogische Inhalte\nVerlinkung zu Bibliotheks-OPAC oder anderen Online-Katalogen\n\nSchließlich muss darauf geachtet werden, dass nicht nur die eigentliche Webseite der Einrichtung die Basisinformationen enthält, sondern auch, dass diese in einschlägigen Suchmaschinen indexiert sind, etwa die Adresse und Öffnungszeiten in einer Google Suche und auf Google Maps. Hierzu müssen entsprechende SEO (Search Engine Optimization) Parameter eingestellt bzw. an die jeweiligen Plattformen übermittelt werden.\n\n\nInternetzugang\nDer kostenlose Zugang zum Internet ist für viele Nutzer*innen ein Grund die Bibliothek als Lern- und Arbeitsort zu nutzen. PC-Arbeitsplätze und freies WLAN gehören deshalb in den meisten Bibliotheken mittlerweile zum Standard. Letzteres ist Voraussetzung, um mit eigenen Geräten wie Notebook, Handy und Tablet arbeiten zu können. Damit in allen relevanten Bereichen WLAN mit angemessener Bandbreite verfügbar ist, sollten Bibliotheken Anforderungen an die Ausstattung des Gebäudes mit einer ausreichenden Anzahl an WLAN-Access-Points bestimmen. Das öffentliche Netz sollte vom internen Netz für Mitarbeiter*innen der Bibliothek getrennt sein, um das Risiko eines Angriffs auf die Infrastruktur zu minimieren. Bei öffentlichen PCs sind zusätzlich Datenschutz-Maßnahmen zu treffen.\nGrundsätzlich sind für die Bereitstellung von Internet zwei Fragen zu klären:\n\nIst der Zugang offen oder sind ein Passwort und ggf. Registrierung notwendig?\nErfolgt der Zugang direkt durch die Bibliothek oder per Roaming über Dritte?\n\nIn Hochschulen und Forschungseinrichtungen bietet sich die WLAN-Roaming-Infrastruktur eduroam, die in Deutschland vom DFN koordiniert wird und auch international an vielen Bildungseinrichtungen verfügbar ist. Der Betrieb von eduroam wird in der Regel durch das universitäre Rechenzentrum verantwortet. Nutzer*innen müssen allerdings an einer Einrichtung registriert sein und ihre Zugangsdaten kennen, um eduroam zu verwenden.\nFür den offenen Zugang kann im Idealfall mit der Trägereinrichtung z.B. der eigenen Kommune zusammengearbeitet werden. Eine weitere Möglichkeit ist das ehrenamtliche Freifunk-Projekt. Je nach Rahmenbedingung gibt es verschiedene Leitfäden und Fördermöglichkeiten zur Einrichtung offenen Internetzugangs.\n\n\n\nInternet-Nutzungshinweise in den Städtischen Bibliotheken Leipzig\n\n\nAls Anbieter von öffentlichem WLAN sollten Bibliotheken auf Gefahren und mögliche Sicherheitsvorkehrungen hinweisen. Bei der Nutzung von öffentlichem WLAN muss beachtet werden, dass die Verbindungen in der Regel nicht verschlüsselt sind und somit alle, die sich im gleichen Netzwerk befinden, potenziell die übertragenen Daten mitlesen können. Zur Minimierung des Risikos sollten Webseiten möglichst nur verschlüsselt per HTTPS aufgerufen werden und Datei- und Verzeichnisfreigaben deaktiviert sein, um zu verhindern, dass andere Teilnehmer im Netzwerk auf eigene Dateien zugreifen können.\n\n\nGruppen- und Einzelarbeitsplätze\nZur Ausstattung von Gruppen- und Einzelarbeitsplätzen gehört auch angemessene Informationstechnik. Wesentlich sind zunächst ein stabiler Internetzugang und Steckdosen. Ausstattung, Verwaltung und Unterhalt von Räumen mit Technik ist insbesondere für öffentliche Bibliotheken ressourcen- und kostenintensiv. Entsprechend sollten sich Bibliotheken an der tatsächlichen Nachfrage ihrer Nutzer*innen orientieren und nur die Technik anschaffen, die sie selbst verwalten können.\nEs gibt auch einige Bibliotheken, die in ihren öffentlichen Arbeitsbereichen sogenannte Smartboards zur Verfügung stellen. Damit sind große Monitore gemeint, die Computer enthalten. Die gewohnten Funktionen wie Webbrowsing, Textverarbeitung und andere Programme sind über Bildschirmtastatur/Touchscreen erreichbar, man kann aber auch eine Art digitales Whiteboard nutzen und die darauf erarbeiteten Ergebnisse digital weiternutzen.\nIn der Praxis zeigt sich jedoch bisher, dass Smartboards meistens nur als großer Monitor mit extern angeschlossenem Notebook oder integriertem Computer genutzt wird. Ein Angebot von derartigen Projektionsflächen lässt sich auch kostengünstiger realisieren.\nIn einigen Bibliotheken werden auch komplette Workspaces für große Gruppen angeboten. Für die gezielte Nutzung von speziell ausgestatteten Arbeitsplätzen kann das Angebot einer Platz- bzw. Raumbuchungslösung nützlich sein. Das Buchungssystem lässt sich auf der Homepage oder in einer Service-App einbinden und kann auf diesem Weg ebenso wie andere Dienstleistungen genutzt werden.\n\n\nÖffentliche PC-Arbeitsplätze\nSowohl wissenschaftliche als auch öffentliche Bibliotheken bieten PC-Arbeitsplätze für ihre Nutzer*innen an. Auch wenn der Trend zu eigenen Geräten geht, bleiben die Nutzungszahlen bei den PC-Arbeitsplätzen besonders in öffentlichen Bibliotheken stabil.\nDienste wie die Nutzung des Internets und Textverarbeitung mit oder ohne Gebühren sind die häufigsten Einsatzzwecke für PC-Arbeitsplätze und sollten weiterhin niedrigschwellig angeboten werden. Die Gebührenabrechnung für angemeldete Nutzer*innen erfolgt über Bezahlsysteme, die an das Bibliotheksmanagementsystem angegliedert sind. Geräte mit Münz- oder Kartenzahlung bieten außerdem die Möglichkeit, diese auch ohne Bibliotheksmitgliedschaft zu nutzen.\nIn der Regel stehen PC-Arbeitsplätze angemeldeten Nutzer*innen zur Verfügung. Anhand der Benutzergruppe können altersbedingte Einschränkungen vorgenommen werden. So müssen Eltern z.B. der Internetnutzung von minderjährigen Kindern zustimmen.\nBei kostenfreier und nicht reglementierter Nutzung muss der Jugendschutz besonders beachtet werden. Denkbar ist dabei das Whitelisting von Internetseiten, d.h. eine Freischaltung von Seiten, die aus Jugendschutz-Sicht als unbedenklich eingestuft wurden. Ein Blacklisting hingegen ist nicht empfohlen, da keinesfalls alle bedenklichen Seiten bekannt sein können.\nAuch der Datenschutz spielt im öffentlichen Bereich eine große Rolle. PCs müssen so konfiguriert werden, dass Nutzer*innen ausschließlich ihre eigenen Dateien sehen und keinen Zugriff auf Dateien von anderen Personen erhalten. Dies wird z.B. durch persönliche Nutzerprofile (gebunden an das Benutzerkonto) oder systemseitige Rücksetzung aller Einstellungen (Gastzugänge) erreicht. Zum Betrieb solcher „Kiosksysteme“ gibt es entsprechende Software. Auch der Einsatz von Thin-Clients ist in diesem Bereich sinnvoll.\nAuch bei der Freigabe der Nutzung von Speichermedien sollten Sicherheitsvorkehrungen getroffen werden, beispielsweise vorgeschaltete automatische Virenprüfungen. Eine Sperre von externen Speichermedien wäre auch denkbar, jedoch spricht die aktuelle Nachfrage dagegen.\nHinweise zur Einrichtung eines öffentlichen WLAN in Bibliotheken gibt der Abschnitt zum Internetzugang.\n\n\nDigitalisieren/Scannen, Digitalisierung on demand\nScannen, Kopieren und Drucken sind weitere häufig genutzte Angebote in Bibliotheken. Zur Unterstützung von Nachhaltigkeit und Digitalisierung von Studium und Lehre könnte das Ausdrucken auf Papier reduziert oder gar nicht angeboten werden und stattdessen das Einscannen auf Datenträger oder Speichersysteme befördert werden.\nUm Nutzer*innen das Digitalisieren von Medien zu ermöglichen, kann eine Bibliothek Scanner zur Verfügung stellen. Im einfachsten Fall sind das Multifunktionsgeräte (MFGs), die sowohl Kopier- als auch Scan- und Druckfunktionen anbieten. Meistens sind Druck- und Kopierfunktionen kostenpflichtig, Scannen oft kostenfrei. Höherwertige Scans von größeren Vorlagen und ergonomisches Scannen sind mit sogenannten Kopfscannern möglich. Bei diesen Scannern liegt das Medium offen, mit dem Druckbild nach oben auf der Vorlagefläche. Mit Fingerdruck oder Fußschalter wird der Scanvorgang ausgelöst, anschließend kann ohne Umdrehen der Vorlage, wie es bei einem herkömmlichen Kopierer notwendig wäre, umgeblättert werden.\nEin weiterer Anwendungsfall ist das Einscannen von Einzelblattvorlagen. z.B. Vorlesungsmitschriften. Hier sind Scanner mit automatischem Papiereinzug ideal, die Vorder- und Rückseite gleichzeitig einscannen können.\nDas Digitalisat kann in der Regel auf einem USB-Stick gespeichert werden. Komfortabler sind eine Netzwerkverbindung und eine Anmeldemöglichkeit für Nutzer*innen. Alternativ kann auch die Eingabe einer Mailadresse mit anschließendem Versand eines Links auf das Dokument angeboten werden. Das Digitalisat selbst per E-Mail zu verschicken ist i.d.R. aufgrund der Dateigröße nicht möglich.\n\n\nAusleihbare Geräte\nAls „Bibliothek der Dinge“ wird die Möglichkeit bezeichnet, in Bibliotheken auch Gegenstände wie Werkzeuge, Sportgeräte und Musikinstrumente ausleihen zu können. Für die Ausleihe von Kunstwerken oder Spielen sind auch die Begriffe „Artothek“ bzw. „Ludothek“ üblich. Für diese Gegenstände ist in der Regel eine besondere Form der Mediensicherung notwendig. Für die Ausgabe von Tablets gibt es beispielsweise spezielle Automaten. Durch Verbindung mit dem Bibliotheksmanagementsystem ist es auch möglich, die Freigabe an ein Mindestalter zu knüpfen und verschiedene Profile auf den Tablets anzulegen.\n\n\nMakerspace\nEin Makerspace ist ein Bereich in einer Bibliothek, in dem Hardware und Software zum Ausprobieren zur Verfügung gestellt wird. Ziel ist das Angebot eines niedrigschwelligen Zugangs zu neuen (technischen) Entwicklungen, die der breiten Öffentlichkeit – in der Regel aus Kostengründen – sonst nicht zur Verfügung stehen. Beispiele für Angebote in Makerspaces sind:\n\n3D Drucker\nGeräte zur Holz/Metallverarbeitung\nStickmaschine/Nähmaschine\nTon- und Videotechnik\nRepaircafé\n\nZusätzlich zur Bereitstellung der Technik bieten viele Bibliotheken Einführungs- und Expertenkurse an, die jedoch auch stark von den vorhandenen Personalressourcen abhängig sind. Makerspaces sind vor allem in größeren öffentlichen Bibliotheken verbreitet. Auch in einigen wissenschaftlichen Bibliotheken gibt es inzwischen entsprechende Angebote, wobei hier der Fokus mehr auf dem Einsatz in Lehre und Lernen liegt, zum Beispiel das Dortmunder Hybrid Learning Center (hylec).\n\n\nBibliotheks-App\nBei Überlegungen zum Einsatz einer App für die Dienstleistungen der Bibliothek sollten verschiedene Aspekte betrachtet werden. Eine App wird um so häufiger installiert, je mehr wichtige und häufig genutzte Funktionalitäten damit nutzbar sind. Eine Integration der Dienstleistungen der Bibliothek in eine bestehende App der übergeordneten Institution ist also der Eigenentwicklung vorzuziehen – sofern das möglich ist.\nIn einer App können grundsätzlich alle Dienstleistungen der Bibliothek angeboten werden. Ein Mehrwert entsteht dann, wenn man den mobilen Charakter des Endgerätes berücksichtigt. Beispiele: Navigation in der Bibliothek mit Wegweisung am Endgerät, Buchung des Gruppenarbeitsraums, vor dem man gerade steht (z.B. über einscannbare QR-Codes).\nEine vollständige Nutzung der Dienstleistungen der Bibliothek ist nur dann möglich, wenn man sich auch digital anmelden kann. Es sollte also eine Form eines digitalen Ausweises geben, Accountname/Passwort im einfachsten Fall, komplett digitaler Ausweis über die App im besten Fall.\nWildau als Beispiel mit UNIDOS hat eine Integration des Bibliothekskontos, mit der Möglichkeit der Anzeige aller entliehenen Medien und der Verlängerung dieser. Bewerkstelligt wird die Funktion via SIP2-Schnittstelle. Zusätzlich können Discovery-Systeme sowie eine Raumbuchung verlinkt bzw direkt via App ermöglicht werden.\n\n\nTechnische Beratung und Schulungen\nTechnische Beratung erfolgt oft in dem Umfang, der für lokale Bibliotheksdienste sinnvoll ist. Bietet eine Bibliothek z.B. die Onleihe als Dienst an, werden sich Nutzer*innen bei Fragen direkt an die Bibliothek wenden und nicht an den Dienstleister.\nSomit müssen sich auch die Mitarbeiter*innen in der Bibliothek stetig fortbilden, um ihren Nutzer*innen einen guten Service zu bieten.\nBeispiele:\n\nErklärung und Dokumentation zu Diensten, z.B. Ebook-Leihe, Streaming-Dienste, E-Learning-Ressourcen\nEbook–Reader Beratung zur Unterstützung der Ebook-Ausleihe\nBeratung zu App-Nutzung, die als digitale Inhalte angeboten werden\n\nWerden neue Dienste eingeführt, bedarf es neben der Werbung auch einer Einführung oder dem Angebot einer Schulung, in erster Linie für Mitarbeiter*innen. Viele Anbieter unterstützen dabei mit eigenem Schulungsmaterial, was unter Umständen je nach Zielgruppe angepasst werden muss."
  },
  {
    "objectID": "infrastruktur.html#dienste-für-mitarbeiterinnen",
    "href": "infrastruktur.html#dienste-für-mitarbeiterinnen",
    "title": "Technische Infrastruktur",
    "section": "Dienste für Mitarbeiter*innen",
    "text": "Dienste für Mitarbeiter*innen\nDie folgenden IT-Dienstleistungen dienen der Unterstützung der täglichen Arbeit, insbesondere im Hinblick auf verteilte Arbeitsumgebungen und mobiles Arbeiten. In vielen Fällen werden sie von der übergeordneten Einrichtung einer Bibliothek bereitgestellt.\nSiehe auch das geplante Kapitel zu Wissensmanagement und Kommunikation.\n\nMobiles Arbeiten\nFür mobiles Arbeiten müssen Endgeräte transportabel sein (Notebook, Tablet…) und zum anderen müssen die Dienste, die für das Arbeiten notwendig sind, vom jeweiligen Standort aus erreichbar sein (siehe VPN). Für dauerhaftes Arbeiten von anderer Stelle als dem Büro (Homeoffice) ist aus Ergonomiegründen ein fester Arbeitsplatz mit Tastatur, Maus, Bildschirm und ggf. Anschlussmöglichkeit für mobile Geräte („Dock“) vorzuziehen oder vorgeschrieben.\nDer Begriff bring your own device (BYOD) bezeichnet die Nutzung von privaten Endgeräten in der Infrastruktur des Arbeitgebers. Dies ist allerdings mit einigen Herausforderungen verbunden. So kann nicht zentral sichergestellt werden, dass das Endgerät frei von Schadsoftware ist. Auch die Sperrung des Gerätes aus der Ferne ist nicht möglich (auf eigenen Geräten des Arbeitgebers kann eine solche Software installiert werden, die im Falle eines Diebstahls aktiviert werden kann). Letztendlich liegt also die Verantwortung dafür, ob dienstliche Daten über das private Gerät in falsche Hände gelangen, beim Arbeitnehmer.\n\n\nVPN\nEin „Virtuelles Privates Netzwerk“ dient dazu, über einen authentifizierten Zugriff das Endgerät der Mitarbeiter*innen bzw. Nutzer*innen virtuell in das interne Netzwerk (Intranet) der Institution einzubinden. Das ermöglicht die Nutzung von Diensten, die auf der Basis der Netzwerkadresse (IP-Adresse) entscheiden, ob der Zugriff ermöglicht wird. Viele Dienste einer Institution werden über eine Firewall aus Sicherheitsgründen dem gesamten Internet verborgen und sind nur über ein VPN auch außerhalb der Institution zum Beispiel aus dem Homeoffice zugreifbar.\n\n\nFileservices\nDienstlich genutzte Dateien sollten an zentraler Stelle abgelegt werden, damit sie in eine Backup-Lösung eingeschlossen werden können und damit die Möglichkeit besteht, sie mit anderen Menschen auszutauschen. Entweder wird dazu einen klassischer Fileserver wie zum Beispiel Windows Server genutzt, oder es kommt eine Cloudlösung wie Nextcloud zum Einsatz. Zusätzlich oder alternativ kann ein Dokumentenmanagementsystem genutzt werden.\n\n\nChat\nChats zwischen Mitarbeiter*innen dienen der niedrigschwelligen Kommunikation, oft als Alternative zu Telefon und E-Mail. Gruppenchats in Abteilungen können für einfache Fragen und Absprachen genutzt werden und Menschen, die mobil arbeiten, können mit einem Chatsystem besser integriert werden. Die Nutzung von kommerziellen Systemen, die noch dazu außerhalb von Europa gehostet werden, ist aus Datenschutzgründen nur in Ausnahmefällen zulässig (WhatsApp u.a., Teams, Slack, …). Sofern die Möglichkeit besteht, ist ein selbst gehostetes, ggf Open Source System vorzuziehen (Beispiel: RocketChat).\n\n\nE-Mail\nE-Mail ist ein Kommunikationsmedium, welches in den meisten Fällen vom Anbieter der IT-Infrastruktur angeboten wird. Ideal ist der Zugang per IMAP/SMTP und nicht nur über proprietäre Protokolle, so dass beliebige Clients genutzt werden können.\n\n\n(Hybride) Konferenzsysteme\nUm Besprechungsräume so auszustatten, dass auch Menschen an Besprechungen teilnehmen können, die nicht anwesend sind, ist technische Infrastruktur erforderlich. Die Anwesenden müssen für die Anwesenden sichtbar und hörbar sein, ohne dass die Anwesenden Headsets tragen müssten. Dies erreicht man mit einer Art überdimensionalen Webcams, die automatisch auf die sprechende Person fokussieren und im Idealfall auch Störgeräusche (Echos, Rauschen, Rascheln) ausblenden. Die gängigen Systeme im knapp vierstelligen Eurobereich genügen für Konferenzen mit bis zu sechs anwesenden Personen um einen Tisch herum. Sind mehr Personen anwesend, steigt der technische Aufwand stark an, wenn man häufig hybrid arbeiten möchte und die anwesenden Personen nicht benachteiligen möchte.\n\n\nDokumentenmanagementsystem (DMS)\nDokumentenmanagementsysteme sind Multi-User Softwaresysteme mit Anbindung an eine hinreichend großen und ausfallsicheren Datenspeicher. Sie lösen in der Regel drei Anforderungen:\n\nlangfristige ggf. auch revisionssichere Ablage digitalisierter oder rein digitaler Dokumente die einer Aufbewahrungsfrist unterliegen (Archivierung, Versionierung)\nUnterstützung der Datenverarbeitung für Prozesse zwischen verschiedenen Akteuren (Workflows)\nStrukturierung und Pflege der Dokumente institutions-relevanter interner und externer Prozesse (Aktenplan)\n\nAb und an erhalten Bibliotheken den Auftrag, die Originale von digitalisierten und in einem DMS abgelegten Dokumenten physisch zu archivieren oder auch den Digitalisierungsprozess zu verantworten. Hierbei ist es empfehlenswert, zwischen Unternehmens- bzw. institutionskritischen Dokumenten, die nicht für die Bibliotheksnutzer verfügbar sein sollen, und Dokumenten mit bibliothekarischem Bezug zu unterscheiden, denn eine Bibliothek ist im Allgemeinen kein Archiv."
  },
  {
    "objectID": "infrastruktur.html#zusammenfassung-und-ausblick",
    "href": "infrastruktur.html#zusammenfassung-und-ausblick",
    "title": "Technische Infrastruktur",
    "section": "Zusammenfassung und Ausblick",
    "text": "Zusammenfassung und Ausblick\nDie technische Infrastruktur bildet die Grundlage für die Dienste einer Bibliothek. Während sich die grundlegenden Dienste für Mitarbeiter*innen nicht wesentlich von anderen Einrichtungen unterscheiden, sind viele Dienste für Nutzer*innen an die Verwaltung physischer Medien gekoppelt.\n\n\n\n\nFreyberg, Linda, und Sabine Wolf, Hrsg. 2019. Smart Libraries: Konzepte, Methoden und Strategien. b.i.t.online Innovativ 76. Wiesbaden: b.i.t. Verlag.\n\n\nKern, Christian. 2011. RFID für Bibliotheken. Springer.\n\n\nMichaelis, Barbara. 2014. In RFID für Bibliothekare: ein Vademecum, herausgegeben von Frank Seeliger, 3. Auflage, 145–50. Verlag News & Media. https://doi.org/10.15771/RFID_2014_13.\n\n\nSeeliger, Frank, Hrsg. 2014. RFID für Bibliothekare: ein Vademecum. 3. Auflage. Verlag News & Media. https://doi.org/10.15771/978-3-936527-32-2.\n\n\n———. 2019. „Smart Services als Marketinginstrument“. In Praxishandbuch Informationsmarketing: Konvergente Strategien, Methoden und Konzepte, herausgegeben von Frauke Schade und Ursula Georgy, 343–57. De Gruyter Saur. https://doi.org/10.1515/9783110539011-023.\n\n\n„UHF RFID Almanach 2022“. 2022. EECC. https://eecc.info/rfidalmanach.html."
  },
  {
    "objectID": "management.html#einleitung",
    "href": "management.html#einleitung",
    "title": "IT-Management",
    "section": "Einleitung",
    "text": "Einleitung\nIT-Systeme sind selten statisch sondern folgen einem Lebenszyklus von der Planung bis zu ihrer Ablösung. Während des Betriebs der Systeme müssen mögliche Risiken beachtet und rechtliche Rahmenbedingungen eingehalten werden. In Bibliotheken sind daher entsprechende IT-Kompetenzen und ein organisatorischer Rahmen notwendig. Um diesen Anforderungen begegnen zu können, gibt es Möglichkeiten zur Aus- und Weiterbildung."
  },
  {
    "objectID": "management.html#it-lebenszyklus",
    "href": "management.html#it-lebenszyklus",
    "title": "IT-Management",
    "section": "Lebenszyklen von IT-Systemen",
    "text": "Lebenszyklen von IT-Systemen\nAlle Software-Systeme folgen einem Lebenszyklus, der mit ihrer Einführung beginnt und irgendwann mit ihrer Abschaltung endet (Abbildung 2.1). Die wesentlichen Phasen im klassischen Lebenszyklus eines IT-Systems werden im Folgenden näher betrachtet.\nDie konkrete Abfolge vor allem der ersten Phasen kann je nach der angewendeten Projektmanagement-Methode (agil vs. klassisch) variieren. Eine Diskussion von agilen und klassischen Methoden liegt außerhalb des Fokus dieses Handbuchs.\n\n\n\nAbbildung 2.1: SDLC-Skizze (Platzhalter)\n\n\n\nPlanung und Analyse\nGrundlage für die Umsetzung eines Softwareprojekts, egal ob es sich um individuell erstellte Software oder die Anpassung eines existierenden IT-Systems handelt, ist ein gemeinsames Verständnis für das Ziel und die Anforderungen des Projektes. Dieses gemeinsame Verständnis, insbesondere der Anforderungen, sollte bei allen Projektmitgliedern und den weiteren Stakeholdern vorhanden sein. Die Anforderungen werden idealerweise vor und während der Entwicklung unter Einbeziehung von Nutzer*innen ermittelt und angepasst.\nZur Planungs- und Analysephase gehört neben einer grundsätzlichen Machbarkeitsanalyse des Projekts die Zusammenstellung eines geeigneten Teams, die Bestimmung der Stakeholder sowie die Klärung finanzieller und rechtlicher Rahmenbedingungen.\n\\(\\Rightarrow\\) Siehe auch ausführlicher zum Entscheidungsprozess bei der Einführung eines Bibliotheksmanagementsystem\n\n\n\n\n\n\nInfo\n\n\n\nZuweilen kommt es vor, dass die Entscheidung für ein IT-System bereits getroffen ist, bevor geklärt wurde, welches Problem damit gelöst werden soll. Auch in diesem Fall ist es sinnvoll, die Einführung mit einer offenen Planung und Anforderungsanalyse zu beginnen, und danach zu prüfen, welche Anforderungen das System tatsächlich abdecken kann.\n\n\n\n\nDesign/Prototyping\nWährend der Design- bzw. Prototyping-Phase entwickeln Designer*innen und Entwickler*innen erste Prototypen. Ziel ist es dabei, Feedback der verschiedenen Stakeholder zu erhalten, um gemeinsam ein besseres Verständnis der Anforderungen zu erhalten bzw. diese zu präzisieren. Das Kapitel Anforderungen an Bibliotheks-IT geht gesondert auf die Bedeutung dieser Einbeziehung und damit verbundener Methoden ein.\n\n\nImplementierung\nAufbauend auf einem gemeinsamen Verständnis der Anforderungen überführen Entwickler*innen Prototypen in lauffähigen Code. Wird im Rahmen des Projekts ein bestehendes System implementiert, werden die Prototypen zunächst in ein Testsystem und in der Folge in das produktive System überführt.\nIn klassischen Projekten sieht man in dieser Phase zuerst ein Produkt mit den gewünschten Features, während nutzer*innenorientierte Vorgehensmodelle (siehe Kapitel Anforderungsanalyse) hier auf einen iterativen Prozess setzen, welcher Produktiterationen häufiger bereitstellt und evaluiert.\nGrundsätzlich unterscheidet sich die Implementierung von Informationssystemen in und für Bibliotheken nicht von der Softwareentwicklung in anderen Bereichen. Unabdingbar ist der Einsatz eines Versionskontrollsystems, ein Issue-Tracker und möglichst automatische Tests und Deployment (kontinuierliche Integration), so dass Änderungen am Quellcode direkt zu einer Aktualisierung der Test- und/oder Produktiv-Instanz der installierten Software führen.\n\n\nTest und Integration\nAls letzte Lebensphase vor der Produktivschaltung werden Abnahmetests und die Integration des entwickelten bzw. erworbenen Systems in die Zielumgebung durchgeführt. Im Falle der Inanspruchnahme eines Dienstleisters wird hier auch dessen Leistung final abgenommen, wenn das System erfolgreich produktiv in Betrieb genommen werden kann.\nWährend der Tests wird korrekte Umsetzen der Anforderungen sowie die Umsetzung der Anforderungen geprüft.\n\nWartung\nDie Wartungsphase folgt auf die Produktivsetzung des IT-Systems. In dieser Lebensphase wird das System nicht mehr grundlegend weiterentwickelt, es werden jedoch Fehler (Bugs) entfernt und Anpassungen der Funktionsweise im Sinne der Parametrisierung oder die Optimierung der Programmabläufe vorgenommen.\nTypischerweise finden sich IT-Systeme, die grundlegende Geschäftsprozesse abbilden oder die nach individuellen Anforderungen erstellt wurden, viele Jahre in dieser Phase. Abbildung 2.2 illustriert die Lebensspanne einiger ausgewählter Nachweissysteme der Staatsbibliothek zu Berlin, die zum Zeitpunkt der Erstellung dieses Textes erst teilweise abgelöst wurden.\n\n\n\nAbbildung 2.2: Lebenszeit (in Jahren) von Bibliothekssystemen in der Wartungsphase am Beispiel der Staatsbibliothek zu Berlin (Stand 2022)\n\n\n\n\n\nAblösung\nDie Ablösung eines Systems kann eine Vielzahl an Gründen haben. So entwickeln sich die technischen Möglichkeiten und die Anforderungen der Nutzer*innen kontinuierlich weiter. Eine Ablösung kann aber auch durch technische Obsoleszenz erzwungen werden, wenn zugrundeliegende Software-Komponenten wie das Betriebssystem oder ein Datenbankmanagementsystem nicht mehr sicher betrieben werden können.\nDie konkrete Ablösungsplanung sollte mit genügend zeitlichem Vorlauf begonnen werden. Dies gewährleistet die Arbeitsfähigkeit in der Ablösungsphase. So können in der Vorphase beispielsweise notwendige Daten migriert werden, die vom Altsystem vorgehalten werden.\nMit dem frühzeitigen Beginn der Ablösungsplanung noch in der Wartungsphase können zudem vermeidbare Risiken minimiert werden. Dies ist insbesondere deshalb wichtig, da man als Betreiber eines IT-Systems nicht alle Faktoren kontrolliert, welche eine kurzfristig notwendig werdende Ablösung des Systems verursachen können. Darunter fallen zum Beispiel:\n\ndie Abschaltung wegen technischer Obsoleszenz (s.o.),\nder Ausfall des Systems durch Hardware-Ausfälle,\ndie Ankündigung von Wartungsarbeiten und Sicherheits-Patches durch den Hersteller oder die Insolvenz des Herstellers (insb. bei proprietärer Software) oder\ndie De-Facto-Unwartbarkeit durch den Wegfall geeigneten Personals mit Spezialkenntnissen (z.B. veralteter Programmiersprachen), siehe dazu auch den Abschnitt Ressourcenplanung\n\nLetztlich führen all diese Punkte zur Abschaltung eines IT-Systems aufgrund von IT-Sicherheitsproblemen, da diese Einbrüche in die Systeme (Hacks) begünstigen. Hinzu kommt das Risiko von Datenverlusten, entweder durch physischen Verlust im Falle eines Hardware-Defekts oder durch den logischen Verlust, da z.B. proprietäre Datenformate nicht mehr gelesen werden können.\nDer Weiterbetrieb eines IT-Systems ohne Ablösungsplanung birgt hohe Risiken in sich und kann eine Organisation folglich in ernsthafte Schwierigkeiten bringen, insbesondere wenn geschäftskritische Prozesse betroffen sind."
  },
  {
    "objectID": "management.html#betriebsmodelle",
    "href": "management.html#betriebsmodelle",
    "title": "IT-Management",
    "section": "Betriebsmodelle",
    "text": "Betriebsmodelle\nInsbesondere serverbasierte Software, wie zum Beispiel das Bibliotheksmanagementsystem, kann auf verschiedene Arten betrieben werden. Die Betriebsarten unterscheiden sich bezüglich Installation, Kosten, Pflege und Wartung sowie Backup und Support.\n\nLokale Installation\nBis etwa 2010 war diese Betriebsart der Normalfall: Eine Einrichtung erwarb die Lizenz für eine (Server-)Software, entweder als Einzelkauf oder im Abo, und installierte diese auf eigenen Servern, z.B. im Serverraum der Bibliothek. Im Fachjargon spricht man auch von einer „on-premise“ Installation.\nIn diesem Modell kümmert sich die Einrichtung selbst um Installation und Updates. Folglich erfordert dieses Modell höheren Personaleinsatz und kann dazu führen, dass bei einem personellen Engpass eine Software länger betrieben bzw. nicht aktualisiert wird, als eigentlich ratsam wäre. Auch muss sich die Einrichtung um grundlegende Dinge, wie Backups und Ausfallsicherheit selbst Gedanken machen.\nAuf der anderen Seite bietet dieses Modell der Einrichtung die meiste Kontrolle über die eingesetzte Software - etwa hinsichtlich nötiger Erweiterung oder Anpassung - und macht sie damit weitgehend unabhängig von äußeren Einflüssen.\n\n\nHosting\nIn diesem Betriebsmodell wird die Ebene der Rechenkapazität bzw. Serverhardware an einen Dienstleister ausgelagert. Der Dienstleister kann hierbei etwa das Rechenzentrum einer Universität oder des angeschlossenen Bibliotheksverbundes sein, oder ganz allgemein jeder kommerzielle Betreiber eines Rechenzentrums, bei dem Kapazitäten erworben werden.\nSämtliche Betriebsfragen, wie Backups und Ausfallsicherheit der eingesetzten Hardware können an diesen Anbieter delegiert werden. Im Falle des Hostings durch einen Bibliotheksverbund entfallen möglicherweise auch Einrichtung, Installation und Upgrades. Die Betriebskosten müssen beim Verbund kalkuliert werden, was jedoch durch das Hosting für mehrere Einrichtung besser skaliert.\n\n\nCloud\nBei diesem Betriebsmodell, das manchmal auch als SaaS (Software as a Service) bezeichnet wird, liegt der fachlich und technische Betrieb beim Anbieter bzw. Dienstleister der Software und die Einrichtung nutzt lediglich eine für sie konfigurierte Installation („Instanz“). Dies ist insbesondere bei webbasierten Anwendungen die bevorzugte Betriebsart, stellt aber erhöhte Anforderungen an die Anbindung lokaler Endgeräte wie z.B. Ausleihautomaten), weil dabei eine sichere und stabile Verbindung zwischen den lokalen Automatisierungsgeräten und dem entfernt gehosteten System hergestellt werden muss.. Die Einrichtung ist weder für die Wartung der eingesetzten Hardware noch für die Pflege der genutzten Software zuständig.\nIn der Praxis kann sich ein solches Betriebsmodell als komfortabel erweisen, da keine Personalressource für allgemeine Tätigkeiten des IT-Betriebs oder spezielle Bibliotheks-IT-Tätigkeiten benötigt werden. Gerade für kleine Einrichtungen kann dies ein guter Weg sein, möglichst personalsparend serverbasierte Software einzusetzen. Eine Kostenersparnis ist bei einer Vollkostenrechnung aber nicht unbedingt zu erwarten. Je nach Größe der Einrichtung oder basierend auf der Anzahl der Endnutzer*innen führt ein solches Betriebsmodell meist zu Abonnementkosten."
  },
  {
    "objectID": "management.html#betriebssicherheit-und-risikomanagement",
    "href": "management.html#betriebssicherheit-und-risikomanagement",
    "title": "IT-Management",
    "section": "Betriebssicherheit und Risikomanagement",
    "text": "Betriebssicherheit und Risikomanagement\nNeben den Problemen der Ablösungplanung gibt es weitere Risiken des Betriebs von IT-Systemen, von denen einige im nachfolgenden Abschnitt vorgestellt werden.\n\nVendor-Lock-In\nEin nicht zu unterschätzendes Risiko, welches sich aus der Einführung eines proprietären IT-Systems ergibt, ist der sogenannte Vendor Lock-In. Dieser beschreibt die Abhängigkeit von Produkten oder Dienstleistungen eines Anbieters durch die der gleichzeitige Einsatz von anderen Produkten oder der Wechsel zu anderen IT-Systemen erschwert wird. Durch den Einsatz von Systemen mit etablierten Standards, offenen Datenformaten und Schnittstellen sowie geeigneter Ablösungsstrategien kann das Risiko eines Vendor Lock-Ins verringert werden.\nDer Begriff des Vendor Lock-ins kann noch auf den Bereich der Fehlerbehebung und die Wartung von Software ausgedehnt werden. Im Fall von proprietärer Software, welche ohne Zugriff auf den Quellcode betrieben wird, ist die Fehlerbehebung ausschließlich Sache des Herstellers. Fällt dieser, wie oben beschrieben, aus, kann ein Betrieb aus IT-Sicherheitsperspektive nicht mehr verantwortet werden. Hinzu kommt, dass das sogenannte Reverse Engineering bzw. das Dekompilieren dieser Software in der Regel verboten ist. Mit einem Grundsatzurteil des EuGH aus dem Jahr 2021 wird dieses Verbot jedoch aufgeweicht. So ist es nun rechtmäßigen Erwerbern erlaubt, Fehler in einem Computerprogramm zu beheben und dafür auch proprietäre Software zu dekompilieren.\nIn der Praxis sollte dieses Notfallszenario aber nicht in die Planung einbezogen werden, da die Fehlerbehebung innerhalb fremder Software unter dem Rückgriff auf Dekompilierung besondere Kenntnisse seitens des zuständigen IT-Personals voraussetzt.\n\n\nSoftware-Abhängigkeiten\nSowohl der Betrieb von proprietärer als auch von Open-Source-Software ist vom Funktionieren einer Vielzahl weiterer Software-Komponenten abhängig. Diese Abhängigkeit lässt sich mit einem vereinfachten Schichtmodells des Betriebs eines IT-Systems illustrieren:\n\n\n\nAbbildung 2.3: Schichtmodell-Bild (Platzhalter)\n\n\nAus Abbildung 2.3 wird deutlich, dass moderne Software-Systeme zum Beispiel auf einem Betriebssystem oder weiteren Subsystemen wie einem Datenbankmanagementsystem basieren. Um das gesamte IT-System betreiben zu können, müssen die Einzelkomponenten zusammen spielen. Fällt eines der Systeme, beispielsweise das Betriebssystem, aufgrund von Obsoleszenz aus, so ist es unter Umständen möglich, die darüber liegenden Schichten auf ein neues Betriebssystem zu migrieren, jedoch ist dies nicht garantiert.\nDas Risiko erhöht sich, wenn im Rahmen eines Wartungsvertrags durch den Hersteller festgelegt wurde, dass zum Beispiel nur bestimmte Kombinationen aus Betriebssystem und weiterer Komponenten zugelassen sind. In diesem Fall kann ein IT-System aus der Wartung fallen, obwohl es vorerst betreibbar bleibt. Mit dem Ausfall der Wartung entfallen auch Software-Updates etc. Damit ist der mittel- bis langfristige Weiterbetrieb des Systems ohne Gefährdung der Betriebssicherheit aller IT-Systeme der Organisation nicht möglich.\n\n\nRechtliche Rahmenbedingungen\nDie meisten Bibliotheken befinden sich in öffentlicher Hand und sind deshalb bestimmten Gesetzen und Verordnungen unterworfen. Von besonderer Bedeutung sind dabei Anforderungen an die Software-Ergonomie und die Barrierefreiheit (Accessibility) von IT-Systemen.\n\n\nSoftware-Ergonomie\nDie gesetzliche Unfallversicherung fordert z.B. die Berücksichtigung ergonomischer Grundsätze bei der Entwicklung von Software. Moderne grafische Anwendungen müssen ebenso wie Internetseiten diese Anforderungen erfüllen:\n\nDie Software muss gebrauchstauglich sein, das heißt, sie sollte gewährleisten, dass Benutzer festgelegte Ziele in einem bestimmten Nutzungskontext effektiv, effizient und zufriedenstellend erreichen können. Dies setzt voraus, dass die Grundsätze der Dialoggestaltung nach DIN EN ISO 9241-110, wie Aufgabenangemessenheit, Selbstbeschreibungsfähigkeit, Steuerbarkeit, Fehlertoleranz, Erwartungskonformität, Individualisierbarkeit, Lernförderlichkeit beachtet und realisiert werden.\n– (Gesetzliche und Unfallversicherung e.V. (DGUV) 2019)\n\nDie Erreichung dieser Ziele wird im Kapitel Anforderungsanalyse thematisiert.\n\n\nBarrierefreiheit\nNeben dem Befolgen der Anforderungen an ergonomisch bedienbare Software, liegt es auf der Hand, dass IT-Systeme für eine Vielzahl von Anwender*innen nutzbar sein sollte. Diese grundlegende Anforderung bezeichnet man als Barrierefreiheit bzw. Accessibility.\nWährend Barrierefreiheit häufig mit einem sehr engen Behinderungsbegriff assoziiert wird, wie z.B. die Rampe für Rollstuhlfahrer*innen, ist dieser Begriff mittlerweile aufgrund der gesetzlichen Grundlagen in Deutschland wesentlich weiter zu fassen (siehe §3 Behindertengleichstellungsgesetz). So leiten sich z.B. auch Anforderungen an Angebote in Leichter Sprache o.ä. aus diesem weiten Behinderungsbegriff ab.\nAufbauend auf der einschlägigen Gesetzgebung regelt die BITV 2.0 (Verordnung zur Schaffung barrierefreier Informationstechnik nach dem Behindertengleichstellungsgesetz) die konkrete Gestaltung barrierefreier IT-Systeme und Webangebot. Hierbei greift sie auf die aktuell gültigen Web Content Accessibilty Guidelines (WCAG) zurück, welche die Anforderungen der Barrierefreiheit anschaulich mit vielfältigen Beispielen illustriert.\nDie gesetzliche Anforderung Barrierefreiheit umsetzen zu müssen trifft dabei nicht nur auf Organisationen der öffentlichen Verwaltung, wie es viele Bibliotheken sind, zu. Vielmehr müssen sich alle Stellen, die europäisches Vergaberecht anwenden müssen (siehe EU Richtlinie 2016/2102), z.B. im Rahmen von Drittmitteln oder Zuwendungen, nach diesen Vorgaben richten.\nWichtig ist hierbei zu beachten, dass die BITV 2.0 nicht zwischen internen und externen Nutzer*innen unterscheidet. Das heißt, dass sowohl rein bibliotheksintern genutzte Systeme als auch nach außen gerichtete Anwendungen, wie z.B. Discovery-Systeme, barrierefrei zu gestalten sind.\nNeben der Ermöglichung der digitalen Teilhabe für den Großteil der Bevölkerung sollen abschließend noch drei weitere positive Aspekte der Beachtung von Barrierefreiheitsanforderungen genannt werden:\n\nViele Umsetzungen der Grundsätze der Barrierefreiheit, erhöhen auch die Usability für Menschen ohne Behinderung,\nebenso wird zumeist die Nachnutzbarkeit auf Mobilgeräten erhöht und\ndie Gestaltung barrierefreier Anwendungen schlägt sich positiv im Suchmaschinenranking nieder, da Suchmaschinen diesen Aspekt zur Bewertung heranziehen."
  },
  {
    "objectID": "management.html#management-der-bibliotheks-it",
    "href": "management.html#management-der-bibliotheks-it",
    "title": "IT-Management",
    "section": "Management der Bibliotheks-IT",
    "text": "Management der Bibliotheks-IT\nDie Auswahl und Implementierung sowie der Betrieb von digitalen Diensten ist ein stetig wachsender Aufgabenbereich für Bibliotheken. Durch den Verlust ihres früheren Monopols auf die Versorgung mit Informationen ist Ende der 1990er Jahre in den Bibliotheken ein starker Innovationsdruck entstanden. In der Folge wurden neue Dienstleistungen wie fachliche Portale, Dokumentenserver etc. im Rahmen von Projekten realisiert. Die notwendigen Kenntnisse haben vielerorts eigens dafür eingestellte Mitarbeiter*innen eingebracht. Eine systematische Ausweitung von Kenntnissen zu IT-Systemen, Metadatenmanagement, Web-Standards, Usability und User Experience bleibt jedoch für die meisten Bibliotheken eine große Herausforderung.\n\nKompetenzen\nDer Einsatz von IT-Systemen erfordert dezidierte Kenntnisse und Fähigkeiten. Veränderungen der Systemlandschaft, z.B. durch einen Systemumstieg oder die Einführung neuer Systeme, erfordern daher eine regelmäßige Analyse der vorhandenen und benötigten IT-bezogenen Kompetenzen.\nBei der Analyse sind folgende Bereiche zu unterscheiden:\n\nBasisinfrastruktur für Hard- und Software: Infrastruktur Netze/Hardware, Netzdienste, Server, Basis-Software, Storage, Backup\nSystemadministration: Installation und Betrieb\nInbetriebnahme und Individualisierung: Metadatenmanagement, Konfiguration und Parametrisierung, Software-Entwicklung\nProjektmanagement\n\nFür die Systemadministration werden Kenntnisse zu grundsätzlichen Architekturen webbasierter Systeme benötigt. In der Regel handelt es sich dabei um die Installation und Administration von Datenbanken, PHP- und Java-Systemen auf Linux-Servern, einschließlich der jeweiligen Wartung durch Minor und Major Updates, Patches etc.\nFür die Inbetriebnahme und Individualisierung von Systemen sind zunächst Kenntnisse bei der Umwandlung von Daten in unterschiedliche Formate notwendig, wenn eine Datenmigrationen aus Altsystemen durchgeführt wird. Die Systeme müssen dann konfiguriert und parametrisiert werden, das heißt auf die konkreten Nutzungsszenarien angepasst. Hier ist zwischen einer so genannten Out-of-the-Box-Verwendung, bei der das System im Rahmen seiner Möglichkeiten genutzt wird, und einer weitergehenden Individualisierung durch eigene Software-Entwicklung zu unterscheiden. In beiden Fällen ist ein Zusammenspiel von bibliotheksfachlichen und Software-technischen Kompetenzen erforderlich, um das Verständnis von bibliothekarischen Geschäftsgängen und den Prozessen und Funktionalitäten des Systems zusammen zu bringen. Daher werden in der Regel Implementierungsteams aus Anwender*innen und Software-Betreuer*innen bzw. Entwickler*innen gebildet\nDie Arbeit dieser Implementierungsteams sollte idealerweise nach Grundlagen des Projektmanagements und des Lebenszyklus von IT-Systemen erfolgen, also unter Berücksichtigung klarer Strukturen für die Planung, die Kommunikation und die Kontrolle. Siehe dazu auch das Kapitel [IT-Entwicklung].\n\n\n\n\n\n\nNiemand kommt als IT-Expert*in auf die Welt und es ist praktisch unmöglich bei allen Entwicklungen auf dem Laufenden zu bleiben. Versuchen Sie ihre Kompetenzen realistisch einzuschätzen und scheuen Sie sich nicht Kolleg*innen um Rat zu fragen!\n\n\n\n\n\nOrganisation\nGrößere Bibliotheken haben in der Regel eigene IT-Abteilungen, die folgende Aufgaben übernehmen:\n\nAnwendungsbetreuung bei Hard- und Software sowie Peripheriegeräten,\nBetreuung von eigenen Servern,\nKonfiguration und Parametrisierung von Systemen,\nggf. Software-Entwicklung.\n\nAlle Punkte außer der Konfiguration und Parametrisierung von Systemen werden in der Regel von informatisch ausgebildetem Personal vorgenommen. Die Konfiguration und Parametrisierung von Systemen ist klassischerweise eine Aufgabe so genannter Systembibliothekar*innen, die teilweise in Ergänzung zu ihrer bibliothekarischen Ausbildung auch über formalisiert erworbene Zusatzqualifikationen verfügen und auf diese Weise eine ideale Schnittstelle zwischen den bibliothekarischen Anwender*innen und den Systemen sind.\nDie Betreuung eigener Server wird häufig von übergeordneten Einrichtungen wie universitären, städtischen oder regionalen Rechenzentren oder externen Dienstleistern übernommen. Bei kleinen Bibliotheken werden oftmals auch andere Tätigkeiten von externen Dienstleistern durchgeführt.\nDer Umgang mit dem Mangel an IT-Fachkräften wird für die Ressourcenplanung des IT-Managements in Bibliotheken zur Herausforderung werden. Dabei wird auch Open-Source-Software die in der Community entwickelt und unterstützt wird, eine größere Rolle spielen, ebenso wie externe Dienstleister und Software as a Service. Eine umfassende Bedarfsanalyse bei IT-Systemen wird daher zukünftig noch stärker berücksichtigen müssen, wie eine längerfristige Betreuung von eingesetzten Systemen ggf. auch ohne eigenes Personal gewährleistet werden kann.\n\nRessourcenplanung\nVeränderungen des Status Quo durch einen Systemwechsel, neue Funktionalitäten oder auch personelle Änderungen durch neue Mitarbeitende, Berentung o.ä. beeinflussen die Personal- und Ressourcenplanung. Eine kontinuierliche Beschäftigung mit diesem Thema ist notwendig, um das Betriebsrisiko von IT-Systemen zu minimieren. Die Benutzung von gut etablierter und weit verbreiteter freier Software verursacht Kosten durch Kompetenzaufbau oder -einkauf, macht unabhängig in Bezug auf Datenhoheit, Datensicherheit und vor allem die Weiterentwicklung. Die Lizenznahme eines kommerziellen Produktes lässt grundsätzlich weniger Individualisierung zu und verlagert die Verantwortung für die Verfügbarkeit und Betriebssicherheit auf den jeweiligen Anbieter.\nFür die Planungen muss entsprechend regelmäßig der Bedarf analysiert werden:\n\nSysteme: Welche Kompetenzen erfordert der Betrieb der Systeme?\nPersonal: Wie viel Personal steht mit welchen Kompetenzen zur Verfügung?\nWie verteilen sich die Kompetenzen auf das vorhandene Personal?\nWie hoch ist die Übereinstimmung bei vorhandenen und benötigten Kompetenzen?\nSind Weiterbildungen sind erforderlich?\n\nDas Thema Aus- und Weiterbildung sowie die Personalgewinnung wird im Folgenden ausführlicher betrachtet.\n\n\n\nAus- und Weiterbildung\nIn der Einleitung wird Cody Hanson (2015) zitiert: „Most importantly, all library staff must understand that our software is our library, and is everyone’s responsibility.“ Bezogen auf Einarbeitung und Weiterbildung bedeutet das, dass sich Mitarbeitende mit der (Weiter-)Entwicklung von Software ebenfalls weiterbilden und weiterentwickeln. Nur so kann die Verantwortung von allen Mitarbeitenden mit Bezug zur Bibliotheks-IT gemeinsam getragen werden.\nNachfolgend werden aktuelle Beispiele zur Aus- und Weiterbildungen mit Bezug bibliothekarischen IT-Bereich aufgeführt. Nicht betrachtet werden Szenarien wie die Einarbeitung von Anwender*innen von IT-Systemen bei der Einführung oder dem Wechsel von Systemen.\n\nAusbildungsmöglichkeiten und Zusatzqualifizierung\nHistorisch gibt es keine formalisierte Ausbildung für die erwähnten Systembibliothekar*innen. Die notwendigen Kenntnisse werden klassischerweise im Rahmen von „Training on the Job“ erworben.\nAllgemeine Ausbildungen und Studiengänge im Bereich IT und Data Science bieten eine gute Grundlage, decken aber bibliotheksspezifische IT-Themen nur unzureichend ab. Stand 2022 gibt es mehrere spezielle Ausbildungsangebote für die Arbeit in der Bibliotheks-IT mit unterschiedlichen Schwerpunkten:\n\nberufsbegleitende Master-Studiengänge:\n\nBibliotheksinformatik an der TH Wildau\n\nVollzeit-Studiengänge:\n\nMasterstudiengang Digitales Datenmanagement an der FH Potsdam und HU Berlin\n\nKurse\n\nZertifikatskurs Data Librarian an der TH Köln\nZertifikatskurs Forschungsdatenmanagement an der TH Köln\n\n\nDiese Zusatzqualifizierungsmöglichkeiten sind eine sehr gute Möglichkeit, um vorhandene Mitarbeiter*innen systematisch weiterzuentwickeln und die IT-Kenntnisse in der Bibliothek zu verbreiten. Der Erwerb dieser Abschlüsse ist jedoch zeitaufwändig und passt nur für wenige Lebenssituationen.\n\n\nWeiterbildung\nBibliothekarische Ausbildungsstätten sowie Verbundzentralen sind wichtige Akteure bei der Weiterbildung von Bibliothekspersonal und machen teilweise entsprechende punktuelle Weiterbildungsangebote. Dabei handelt es sich in der Regel um ein- oder halbtägige Angebote, die durchaus im Einzelnen Hilfestellung bieten. Für Mitarbeitende mit Bezug zur Bibliotheks-IT sollten ausdrücklich zeitliche und ggf. finanzielle Ressourcen für die Nutzung dieser Angebote bereitgestellt werden.\nAuch der Besuch von Konferenzen ist eine wichtige Säule der Weiterbildung. Im Kontext der Bibliotheks-IT hervorzuheben sind hier\n\nJahrestagungen der Verbundzentralen\nBibliothekstage und -konferenzen\nTagung der European Library Automation Group (ELAG)\nCode4Lib-Konferenzen in den USA\nAccess Conference in Kanada\nUKSG Annual Conference in Großbritannien\nJahrestreffen der UXLibs in Großbritannien\n\nDie wichtigste Rolle bei der Qualifizierung für die Aufgaben im Bereich Bibliotheks-IT dürfte die informelle Weiterbildung spielen. Informelle Weiterbildungsformen sind\n\nAnwendungstreffen: z.B. jährlich für DSpace, VuFind, Koha, FOLIO, Kitodo, OPUS, …\nLibrary Carpentries\nMailinglisten, Foren und andere Kommunikationskanäle\npersönliche Kontakte, Gruppen wie UX Roundtable\nFachpublikationen: Code4Lib Journal, Weave Journal\nSoziale Medien: Weblogs, Twitter, Discord\n\n\n\nPersonalgewinnung\nDie Gewinnung von Personal für die Aufgaben im Bereich der digitalen Dienste ist neben der Aus- und Weiterbildung eine zweite Herausforderung. Die Gehaltsstruktur im öffentlichen Dienst ist für informatisch ausgebildetes Personal nicht unbedingt wettbewerbsfähig, so dass viele ausgewiesene IT-Stellen nur schwer besetzt werden können. Eine unmittelbare Reaktion darauf kann sein, die Vorteile der Beschäftigung im öffentlichen Dienst besser herauszuarbeiten (unkommerzielles Umfeld, gesellschaftliche Relevanz der Tätigkeiten).\nDennoch ist es erwartbar, dass Aufgaben im Bereich Bibliotheks-IT künftig stärker an Verbundzentralen oder externe Dienstleister outgesourct werden müssen.\nDie Ausrichtung der bibliothekarischen Studiengänge wird die Bedarfe bei den digitalen Diensten noch stärker berücksichtigen und Studierende mit einem erhöhten Interesse an den Aufgaben in der Bibliotheks-IT rekrutieren müssen."
  },
  {
    "objectID": "management.html#zusammenfassung-und-ausblick",
    "href": "management.html#zusammenfassung-und-ausblick",
    "title": "IT-Management",
    "section": "Zusammenfassung und Ausblick",
    "text": "Zusammenfassung und Ausblick\nAuch nach Auswahl eines Systems ist eine permanente Beobachtung des Lebenszyklus erforderlich. Es empfiehlt sich immer eine frühzeitige Reaktion auf sich ändernde Anforderungen. Das Wissen um das System als auch um seine Anwendung müssen ebenfalls aktuell gehalten werden, z.B. durch entsprechende Fortbildungen oder Schulungen. Sollte sich ein System-Umstieg abzeichnen, sind vor allem die internen Arbeits-Prozesse zu berücksichtigen: das Wissen der Systemanwendenden und -betreuenden ist somit unverzichtbar, denn nur dadurch kann auf eine Ablösung bzw Anpassung des Systems effektiv reagiert werden.\n\n\n\n\nGesetzliche, Deutsche, und Unfallversicherung e.V. (DGUV). 2019. „Bildschirm- und Büroarbeitsplätze: Leitfaden für die Gestaltung“. https://publikationen.dguv.de/widgets/pdf/download/article/409.\n\n\nHanson, Cody. 2015. „Opinion: Libraries are Software“. 2015. https://www.codyh.com/writing/software.html."
  },
  {
    "objectID": "anforderungen.html#einleitung",
    "href": "anforderungen.html#einleitung",
    "title": "Anforderungsanalyse",
    "section": "Einleitung",
    "text": "Einleitung\nIm Kapitel Management von IT-Systemen wurde bereits auf Themen wie Barrierefreiheit und software-ergonomische Anforderungen sowie den permanenten Anpassungsbedarf an Systeme im Laufe ihrer Lebenszeit eingegangen.\nBetrachtet man sein persönliches Nutzungsverhalten im digitalen Bereich wird klar, dass sich auch die eigenen Präferenzen bezüglich der Nutzung von Apps oder Webseiten ändern. Ursachen dafür sind beispielsweise Veränderungen an Lebens- oder Arbeitskontexten, Erwartungen an die Bedienbarkeit von Systemen oder durch die digitale Transformation beziehungsweise technischen Fortschritt möglich gewordene neue Nutzungsformen von Medien.\nIT-Entwicklung sollte sich daher auch an den Bedürfnissen von Nutzer*innen ausrichten. Es gibt verschiedene Methoden, die entsprechenden Bedarfe und Anforderungen zu ermitteln und sie in die Entwicklung einzubeziehen. Dazu gehören unter anderem der Einsatz von Personas, Use Cases oder Storyboards. Weitere Methoden sind zum Beispiel Storyboards, Wireframes oder auch Prototypen."
  },
  {
    "objectID": "anforderungen.html#nutzerinnenorientierten-gestaltung",
    "href": "anforderungen.html#nutzerinnenorientierten-gestaltung",
    "title": "Anforderungsanalyse",
    "section": "Nutzer*innenorientierten Gestaltung",
    "text": "Nutzer*innenorientierten Gestaltung\nNutzer*innenorientierte Gestaltung heißt, die Bedürfnisse von Nutzenden in den gesamten Entwicklungsprozess einzubeziehen. Das bedeutet, dass deren Bedarfe nicht nur als Quelle von initialen Anforderungen dienen, sondern kontinuierlich in den Entwicklungsprozess einbezogen werden. Hierbei ist es besonders wichtig, die Fähigkeiten und Bedürfnisse der Nutzenden sowie ihre Arbeitskontexte und -aufgaben in den Entwurf von IT-Systemen einzubeziehen. Diese Aspekte finden sich auch in den zugrundeliegenden Definitionen, wie der Usability (siehe Abschnitt Was beeinflusst den Nutzungseindruck?) wieder.\nBeim nutzer*innenorientierten Design oder dem User-Centered Design (UCD) handelt es sich nicht im formale Methoden im engeren Sinn, sondern um eine Sammlung i.d.R. empirisch abgesicherter Techniken mit drei Kernideen (Gould und Lewis 1987).\n\nFokussierung auf Nutzer*innen und deren Aufgaben von Beginn der Entwicklung an\nderen kontinuierliche Einbeziehung und Auswertung von Nutzer*innen-Feedback sowie Performance-Messung\nNutzung eines iterativen Design-Prozesses\n\nKling und Leigh Star ergänzen, dass die ganz individuellen Fähigkeiten der Nutzenden in Betracht gezogen werden müssen (Kling und Star 1998), was allein schon aus Gründen der digitalen Teilhabe sinnvoll erscheint.\nGenerell zielt UCD darauf ab, interaktive Systeme zu entwickeln, welche einfach zu nutzen und nützlich sind. Hierbei wird ein Fokus auf Aspekte wie Effektivität, Effizienz, Benutzerzufriedenheit und Zugänglichkeit gelegt (Deutsches Institut für Normung e. V. (DIN) 2020). Diese Aspekte werden in Abschnitt Was beeinflusst den Nutzungseindruck? weiter erläutert.\nDas Central Digital and Data Office des Vereinigten Köngreichs fasst die zentral zu bearbeitenden Arbeitspunkte im nutzer*innenzentrierten Gestaltungsprozess und den Weg dahin prägnant in seinen „Government Design Principles“ zusammen „Government Design Principles. GOV.UK“ (2012):\n\nStart with user needs\nDo less\nDesign with data\nDo the hard work to make it simple\nIterate. Then iterate again\nThis is for everyone\nUnderstand context\nBuild digital services, not websites\nBe consistent, not uniform\nMake things open: it makes things better\n\nUnter der oben genannten Website des Central Digital and Data Office finden sich auch umfangreiche Hinweise, wie sich die einzelnen Punkte praktisch umsetzen lassen.\n\nWas beeinflusst den Nutzungseindruck?\nGut bedienbare, interaktive Systeme sollen Zufriedenheit auslösen und zugänglich sein. Die Erreichung dieser Ziele und zentrale Begriffsdefinitionen sind Teil des Arbeits- und Forschungsgebiets der Software-Ergonomie und finden sich in den einschlägigen Normen wie der DIN EN ISO 9241-11 wieder (Deutsches Institut für Normung e. V. (DIN) 2020).\nVon zentraler Bedeutung sind dabei zwei Kernbegriffe: die Usability (Gebrauchstauglichkeit) und die User Experience (Nutzer*innenerfahrung)\n\n\n\n\n\n\nUsability ist das „Ausmaß, in dem ein System, ein Produkt oder eine Dienstleistung durch bestimmte Benutzer in einem bestimmten Nutzungskontext genutzt werden kann, um festgelegte Ziele effektiv, effizient und zufriedenstellend zu erreichen“ DIN EN ISO 9241-11\nUser Experience bezeichnet die „Wahrnehmungen und Reaktionen einer Person, die aus der tatsächlichen und/oder der erwarteten Benutzung eines Produkts, eines Systems oder einer Dienstleistung resultieren“ DIN ISO 9241-210:2011\n\n\n\nBei Usability handelt es sich um eine Eigenschaft eines Systems, die während der konkreten Interaktion mit diesem relevant wird und beispielsweise angibt, inwiefern Hürden bei der Bedienung auftreten (Abbildung 3.1). Zur Vermeidung von Usability-Problemen existieren ein Vielzahl von Heuristiken, die in den einschlägigen Normen skizziert werden bzw. durch Autoren wie Shneiderman in seinen „8 golden rules“ (Shneiderman und Plaisant 2005) oder Nielsen mit seinen „10 Heuristics“ benannt werden.\nDie User Experience hingen bezieht sich auf die Wahrnehmung der Nutzenden sowohl vor, nach und auch während der Interaktion. Sie bezeichnet sozusagen die Positionierung gegenüber einem System und hat damit Auswirkungen darauf, ob Nutzende ein System erneut benutzen werden oder, z. B. aufgrund von schlechter Bedienbarkeit, d. h. schlechter Usability, vor einer zukünftigen Nutzung zurückschrecken. Es reicht folglich nicht aus, einzelne Aspekte einer Nutzer*innenschnittstelle zu optimieren. Vielmehr muss der gesamte angebotene Service aus Sicht der Nutzenden optimiert werden, damit sich ein positives Nutzungserlebnis einstellt. Diese Optimierung beschränkt sich dabei nicht nur auf die digitalisierten Anteile eines Services sondern bezieht alle Arbeitsschritte, egal ob analog oder digital, mit ein.\n\n\n\nAbbildung 3.1: Zusammenhang zwischen Usability und User Experience"
  },
  {
    "objectID": "anforderungen.html#einbeziehung",
    "href": "anforderungen.html#einbeziehung",
    "title": "Anforderungsanalyse",
    "section": "Wie beziehen wir unsere Nutzer*innen ein?",
    "text": "Wie beziehen wir unsere Nutzer*innen ein?\nMit der Einführung einer neuen IT-Lösung werden bestimmte strategische Ziele verfolgt wie die Ablösung eines veralteten Systems, die Einführung einer neuen Dienstleistung und dergleichen. Die konkrete Ausgestaltung dieser strategischen Ziele sollte unter Einbeziehungen der beabsichtigten Nutzenden erfolgen. Die konsequente Bedarfsorientierung sichert die Qualität der Dienste und verhindert, dass eigene Bedürfnisse und Einschätzungen von Expert*innen die Entwicklung dominieren. Für die Einbeziehung von Nutzer*innen gibt es verschiedene Methoden, die im Folgenden kurz dargestellt werden sollen.\n\nBedarfsermittlung\n\nKlassische Methoden zur Bedarfsermittlung\nZu den in Bibliotheken auch jenseits der Entwicklung von digitalen Diensten häufig genutzten Methoden der Bedarfsermittlung gehören qualitative und quantitative Befragungen sowie Beobachtungen. Diese Methoden sind aus der empirischen Sozialforschung entlehnt. Für viele Software-Projekte sind groß angelegte Befragungen zu aufwändig, allerdings ist es empfehlenswert, sich über Studien aus vergleichbaren Projekten zu informieren und daraus nach Möglichkeiten Ableitungen für eigene Zielsetzungen zu entwickeln.\nBeobachtungen können sehr flexibel angelegt und geplant werden. Dadurch können valide Ergebnisse mit vertretbarem Aufwand produziert werden und die Studie bei Bedarf gut skaliert werden. Der Fokus bei solchen Studien liegt darauf, Nutzer*innen in ihrem Arbeitsalltag zu beobachten, um ihre Herangehensweise bei der Lösung von Aufgaben und Problemen zu ermitteln. Übertragen auf digitale Dienste kann das zum Beispiel im Rahmen eines Usability-Tests passieren, in dem eine oder mehrere Personen ein System nutzen. Typischerweise werden während des Tests nicht nur Notizen oder Aufnahmen gesichert, sondern die Tester*innen nutzen das Think-Aloud-Protokoll. Dabei sollen Nutzende in Echtzeit laut kommentieren, was sie denken, sehen und tun (siehe Abschnitt Methoden).\nFokusgruppen dagegen sind eine qualitative Methode, in der Vertreter*innen verschiedener Zielgruppen gemeinsam an einem bestimmten, vorher formulierten Thema arbeiten. Das können sowohl Diskussionen über Anforderungen und Wünsche an ein bestimmtes System sein, als auch die Planung von Einsatzszenarien oder Workflows. Durch die freie Wahl von Themen und Mitgliedern, z. B. Nutzende ohne Vorerfahrungen und/oder Expert*innen, sind Fokusgruppen ebenfalls eine sehr flexible, breit anwendbare Methode.\n\n\nBedarfsermittlung mit Personas und Use Cases\nPersonas sind fiktive Persönlichkeiten, die stellvertretend für einzelne Zielgruppen eines Dienstes entwickelt werden. Die Beschreibungen enthalten vielfältige Informationen über die Persona und laden damit dazu ein, den zu entwickelnden Dienst aus der Perspektive der jeweiligen Persona zu beurteilen, jenseits von abstrakten Anforderungen. Darüber hinaus helfen Personas dabei, Prioritäten zu setzen und die Zielerreichung zu überprüfen. Es empfiehlt sich, für jedes strategische Ziel eine Persona zu erstellen, mindestens drei bis fünf Personas insgesamt.\nAbgeleitet von solchen Personas fällt es häufig leicht, konkrete Use Cases für die Interaktion mit einem System zu definieren. Ein Use Case beschreibt dabei eine Reihe von Aktionen, die eine Person in bzw. mit einem System durchführen kann. Das kann beispielsweise in einem Fließtext passieren, in dem ein Szenario beschrieben wird.\n\n\n\nAbbildung 3.2: Aus einem Vortrag zum Scenario-based Design\n\n\nAußerdem kann es sich lohnen, solche Use Cases zu visualisieren. Dabei können Start, Ende, mögliche Verzweigungen, alternative Aktionen und mehr mit verschiedenen Formen modelliert werden. Dafür können formalisierte Systeme wie die Unified Modelling Language (UML) zum Einsatz kommen. Sie bietet ein Set verschiedener Formen, um Start, Ende, Verzweigungen, Alternativen und mehr visuell zu beschreiben. Aber auch Skizzen können Nutzungsszenarien bereits verdeutlichen und als Diskussionsgrundlage dienen, z. B. in Form von Storyboards, die in einem eigenen Unterkapitel zu dieser Methode noch beschrieben werden.\nUse Cases können sowohl als Grundlage für den Entwicklungsprozess dienen als auch für die Evaluation eines Systems (siehe Abschnitt Evaluierung). Für die Nutzenden-Personas einer Bibliothek kann eine breite Palette von Use Cases existieren. Manche sind dabei eher allgemein zu verstehen, andere bibliotheksspezifisch und natürlich sind alle je nach Einrichtung bzw. Anforderungen beliebig erweiterbar. Zu beachten ist, dass sowohl Personas als auch Use Cases zwingend auf der Grundlage vertrauenswürdiger Daten wie denen aus der Bedarfsermittlung erstellt werden sollten. Solche Methoden ohne Kenntnisse der Zielgruppen anzuwenden kann nur zur Reproduktion der eigenen Meinung führen.\n\n\n\nMethoden\nTestaufgaben für Usability-Tests werden erstellt, um typische Nutzungsszenarien mit Hinblick auf die Usability des Systems hin zu überprüfen. Die folgenden Methoden können relativ einfach umgesetzt werden, generieren jedoch bereits wertvolle Erkenntnisse.\n\nThink-Aloud-Protokolle\nDie zentrale Idee bei Think-Aloud-Protokollen ist, dass Proband*innen während der Interaktion mit dem zu evaluierenden System ihre Meinungen, Gedanken und Gefühle laut aussprechen.\nDadurch wird es den Beobachter*innen ermöglicht, zuvor unsichtbare, kognitive Prozesse der Proband*innen zu beobachten sowie einen Einblick in typische Nutzungsweisen zu gewinnen. Durch die Verbalisierung und Beschreibung des Systems durch die Nutzenden lernt man zeitgleich die Nutzer*innenterminologie für bestimmte Sachverhalte kennen, die teils erheblich von der Fachsprache abweichen wird. Die Ergebnisse der Methode können z. B. durch Notizen oder Audioaufnahmen festgehalten werden.\n\n\nCo-Discovery Learning\nDie Kernherausforderung bei der Erstellung von Think-Aloud-Protokollen ist es, die Proband*innen kontinuierlich zu motivieren, selbst kleinste Gedanken zu verbalisieren. Beim Co-Discovery Learning arbeiten zwei Testpersonen gleichzeitig an einem System und helfen sich gegenseitig bei der Erfüllung der Aufgaben. Dadurch entstehen Gespräche und gewissermaßen automatisch ein Think-Aloud-Protokoll beider Personen.\nDie Methode bildet einerseits eine realistische Arbeitssituation des gegenseitigen Helfens ab und normalisiert andererseits das laute Aussprechen von Gedanken innerhalb einer Dialogsituation.\n\n\nQuantitative Methoden\nBeobachtungsmethoden generieren primär qualitative Daten, ebenso wie viele Inspektionsmethoden. Aus Managementsicht werden jedoch oft Entscheidungen auf Grundlage von quantitativen Daten bevorzugt, da diese häufiger als Fakten wahrgenommen werden.\nEinfache, relativ leicht zu erhebende quantitative Metriken im Rahmen von Usability-Tests sind z.B.:\n\nNutzungsfehler pro Zeiteinheit,\nAnzahl nicht benötigter Befehle (Menus, Icons, Links)\nBenötigte Zeit für den Abschluss einer Arbeitsaufgabe (insbesondere im Vergleich mit einer vorherigen Iteration)\nBenötigte Anzahl an Klicks/Links, um an ein bestimmtes Ziel zu kommen.\n\nDer „Benutzungsfragebogen ISONORM 9241/10“ bietet einen interessanten Kompromiss zwischen qualitativen und quantitativen Daten, da er qualitative Aussagen bezüglich der Usability eines Systems (z.B. Aufgabenangemessenheit und Selbstbeschreibungsfähigkeit) mithilfe einer siebenstufigen Likert-Skala abbildet. Der Fragebogen ist frei im Internet verfügbar. Beachtet werden muss, dass für belastbare quantitative Daten die Größe der Testgruppe deutlich steigen muss, um Verfälschungen durch Einzelpersonen zu vermeiden.\n\n\n\nEinbeziehung von Nutzenden in die Entwicklung\nAls Grundlage für Personas oder Use Cases und alle weiteren Schritte ist die Einbeziehung von tatsächlichen Nutzenden in die Entwicklung also bereits in einem frühen Stadium möglich und sinnvoll. Diese Einbeziehung sichert ab, dass wesentliche Ziele der Nutzenden erreicht werden und in mitunter komplexen Entwicklungsprozessen die richtigen Schwerpunkte gesetzt werden. Dafür stehen verschiedene Methoden zur Verfügung.\nNachfolgend werden drei Ansätze vorgestellt:\n\nStoryboards - Skizzierung von Interaktionskonzepten\nWireframes und Mock-Ups - Skizzen der Oberflächen\nPrototypen - erste funktionsfähige Iterationen\n\n\nStoryboards als frühe Methode\nEin Storyboard illustriert, wie ein User Interface (UI, Nutzer*innenoberfläche) auf Eingaben reagiert ohne das Interface visuell perfekt darzustellen. Es kann genutzt werden, um in Use Cases bestimmte Aktionen zu illustrieren.\n\n\n\nhier sollte man am besten etwas mit Bib-Bezug kritzeln, das bild ist nur als Platzhalter zu verstehen z.B. https://www.storyboardthat.com/de/storyboards/1c78733f/matilda-library-visit\n\n\nDie Visualisierung von Interaktionsideen kann Beteiligten helfen, mögliche Abläufe nachzuvollziehen. Storyboards sind dabei oft leichter verständlich als z. B. technische Diagramme mit der oben genannten UML. Trotzdem ist darauf zu achten, dass Ideen und Konzepte für Stakeholder und Nutzende klar beschrieben werden, um Missverständnisse zu vermeiden. IN dieser Form lassen sich Storyboards nutzen, um z.B. verbale Beschreibungen oder Nutzungsszenarien zu ergänzen.\nDurch die noch vage Darstellung der Idee können dann Diskussionen angeregt werden. Beispielsweise können Storyboards in Fokusgruppen vorgestellt und diskutiert oder auch in Einzelgesprächen mit verschiedenen Stakeholdern analysiert werden. Möglichst alle Fragen und Ideen sollten dabei ohne Limitierungen behandelt werden können und die Ergebnisse festgehalten werden.\nVor- und Nachteile von Storyboards im Überblick:\n\n\n\n\n\n\n\nVorteile\nNachteile\n\n\n\n\nleicht verständlich, für alle Stakeholder geeignet\nnicht jeder Use Case oder jede Interaktionsmöglichkeit ist darstellbar\n\n\nbereits im frühen Entwurfsprozess einsetzbar\ndigitale, nichtlineare Produkte (z.B. Websites) sind schwer darstellbar\n\n\nschnelle Erstellung ohne Vorkenntnisse möglich\nggf. Unklarheiten bei der Nutzung (z.B. durch unklare Symbole)\n\n\n\n\n\nWireframes und Mock-Ups\nWireframes und Mock-Ups werden vor allem dazu genutzt, erste Skizzen für Struktur, Layout und Funktionalitäten eines Interface vorzustellen. Ähnlich wie Storyboards dienen sie als einfach zu erstellende Diskussionsgrundlage, mit deren Hilfe ein Abgleich der Vorstellungen von einem System und der Gestaltungsmöglichkeiten durchgeführt werden kann.\n\n\n\nAbbildung 3.3: https://www.mockplus.com/blog/post/basic-uiux-design-concept-difference-between-wireframe-prototype (Platzhalter)\n\n\nEin Wireframe („Drahtmodell“) ist eine noch undetaillierte („low-level“) Ausarbeitung eines Interfaces, v. a. darauf ausgerichtet, die Positionierung der einzelnen Elemente zu planen. Daher sind z.B. Bilder oder Buttons als Kästchen dargestellt, Text als Striche und ähnliches (siehe Abbildung 3.3). Ein Mock-Up ist, im Kontext Design, eine ausgereifte („high-level“) Version des Interfaces mit realistischen Farben, Schriftarten und Elementen. Sowohl Wireframes als auch Mock-Ups sind also rein statische Entwürfe des zukünftigen Produkts im Gegensatz zu Prototypen, die interaktiv sind und damit echte Funktionalitäten enthalten.\n\n\n(Interaktive) Prototypen\nDie nächsthöhere Form eines geplanten Produkts, (interaktive) Prototypen, besitzen bereits erste Funktionen des geplanten Interfaces. Auch hier gibt es eine Spanne von rudimentären, low-level bis hin zu ausgereiften, high-level Prototypen, die durch Iterationen schrittweise erreicht werden. Üblich ist außerdem die Unterteilung in „vertical slice“, die qualitativ hochwertige Umsetzung nur eines bestimmten Teils des Produkts, und „horizontal slice“, die prototypische Umsetzung einer möglichst großen Bandbreite des späteren Systems.\nErste Prototypen müssen dabei noch nicht zwingend programmiert werden, sondern können durch entsprechende Prototyping Software, wie Figma oder Axure, umgesetzt werden. Diese besitzen eine Art Bausystem für Interfaces mit mehreren Ansichten, die über Aktionen wie den Klick auf einen Button verbunden werden können. So kann Nutzenden gewissermaßen ein Produkt vorgetäuscht werden, das dann mit rudimentären Funktionen bereits getestet werden kann.\nWährend des eigentlichen Softwareentwicklungsprozesses wird der anfängliche Prototyp mit jeder Iteration hochwertiger und nimmt mehr den Charakter eines vollen Systems an. Es empfiehlt sich, nach Iterationen regelmäßig zu evaluieren, ob neue Funktionen oder Änderungen noch für die Zielgruppen geeignet sind.\n\n\n\nEvaluierung\nDie vorangegangenen Abschnitte haben herausgestellt, wie wichtig es ist, regelmäßig Feedback der Nutzenden zu erhalten. Eine zentrale Datenquelle dafür ist die Begleitung eines Projekts durch Evaluierungen. Ein Beispiel für eine lebendige Evaluierungskultur ist das “User Research Center” der Harvard Library, das regelmäßig verschiedene Methoden anwendet, um Angebote gemeinsam mit Nutzenden zu evaluieren und diese öffentlich in einem Wiki teilt.\nIm Rahmen der Usability-Evaluierung entscheidet man dabei grob zwei Methoden: Beobachtungs- und Inspektionstests (Abbildung 3.4). Während erstgenannte unter Einbeziehung von Nutzer*innen durchgeführt werden, werden Inspektionstests häufig durch Usability-Expert*innen realisiert.\n\n\n\nAbbildung 3.4:  \n\n\nAls Vorteil der Beobachtungstests erweist sich aus der Praxissicht, dass diese auch ohne eine formale Usability-Ausbildung durch engagierte Mitarbeiter*innen durchgeführt werden können. Im Folgenden soll deshalb das prinzipielle Vorgehen bei einem Beobachtungstest skizziert werden.\n\nTestgruppen\nDie Testgruppe muss die potentielle Nutzungsgruppe bestmöglich repräsentieren, jedoch nicht sehr groß sein. Die Erfahrung zeigt, dass ca. fünf Testpersonen ausreichen, um die wichtigsten Usabilityprobleme eines Systems zu identifizieren Jakob Nielsen (2000). Statt eines einzigen Tests mit vielen Teilnehmenden bieten sich daher schnell durchzuführende Tests mit wenigen Teilnehmenden an, um ein Produkt iterativ zu verbessern. Möchte man jedoch verschiedene Typen von Nutzer*innen analysieren oder quantitative Ergebnisse sammeln, muss die Gruppengröße entsprechend wachsen.\nNeben den typischen Streuungsmerkmalen wie demographischen und kulturellen Faktoren (z.B. Bildungshintergrund) bietet es sich an, Nutzer*innen auszuwählen, die über ein unterschiedliches Maß an Vorwissen über das zu entwickelnde oder verwandte Produkte verfügen. Außerdem sollten Personen integriert werden, welche von Einschränkungen betroffen sind, die in Abschnitt Accessibility thematisiert wurden.\n\n\nTestablauf und Vorbereitungen\nNach der Rekrutierung repräsentativer Nutzer*innen und der Vorbereitung der benötigten Materialien und der Testumgebung bietet sich ein Pilottest mit Proband*innen an. Dieser dient der Validierung der eigenen Annahmen über die Testaufgaben (s.u.) und die Machbarkeit des Ablaufs.\nDie Testumgebung sollte eine entspannte und natürliche Arbeitsumgebung vermitteln. Diese ist in jedem Fall einer künstlichen Laborumgebung vorzuziehen. Während der Beobachtungstests ist sicherzustellen, dass keine Unterbrechungen, z.B. in Form von Telefonanrufen erfolgen, damit die Proband*innen das zu evaluierende System konzentriert testen können.\nNach dem Beobachtungstest sollte es den Proband*innen ermöglicht werden, die Testergebnisse zu erhalten. Außerdem ist es neben dem obligatorischen Dank für die Teilnahme üblich, eine Aufmerksamkeit - je nach Dauer z. B. Kaffee, Süßes, Gutscheine - auszuhändigen, um die eigene Wertschätzung für das zeitliche Investment der Proband*innen auszudrücken. In einer Erklärung zum Datenschutz ist die anonyme Datennutzung zuzusichern.\n\n\nTestaufgaben\nWie die Testgruppen müssen auch die Testaufgaben repräsentativ für den späteren Einsatzzweck des Systems sein. Die von den Proband*innen zu bearbeitenden Testaufgaben müssen realistische Aufgaben in bzw. mit dem System sein und in der gegebenen Zeit absolvierbar sein. Dabei ist zu beachten, dass sich die Arbeitsaufgaben an tatsächlichen Use Cases orientieren und nicht trivial sind.\nDie Formulierung der Arbeitsaufgaben muss unmissverständlich für die Proband*innen sein und auf deren (mitunter variierendes) Vorwissen eingehen. Ein Pilottest hilft, dies zu überprüfen.\nDie Gestaltung der einzelnen Aufgaben sollte einer Dramaturgie folgen, um die Proband*innen während des gesamten Tests zu motivieren. Das heißt konkret, dass die ersten Teilaufgaben leicht zu lösen sein sollten und deren Schwierigkeit dann kontinuierlich zunimmt, um durch komplexere Aufgaben belastbare Aussagen zu erhalten."
  },
  {
    "objectID": "anforderungen.html#zusammenfassung-und-ausblick",
    "href": "anforderungen.html#zusammenfassung-und-ausblick",
    "title": "Anforderungsanalyse",
    "section": "Zusammenfassung und Ausblick",
    "text": "Zusammenfassung und Ausblick\nEs gibt verschiedenste Methoden mit denen Bedarfe ermittelt und Nutzende in die Entwicklung von Software einbezogen werden können - je nach Umfang des Produkts und des Anwender*innenkreises. Usertests erfordern ein anderes Zeitmanagement als die Entwicklung von Personas. Auch der Anwendungsfall nimmt Einfluss auf die Methodenauswahl. So kann für die Entwicklung eines neuen Designs die Verwendung von Wireframes und Mockups bei der Bedarfsermittlung hilfreich sein. Wird ein Portal mit neuen Interaktionsmöglichkeiten entwickelt, empfehlen sich Prototypen, mit denen auch die Interaktionen getestet werden können.\n\n\n\n\nDeutsches Institut für Normung e. V. (DIN). 2020. „DIN EN ISO 9241-110 Ergonomie der Mensch-System-Interaktion - Teil 110: Interaktionsprinzipien (ISO 9241-110:2020)“. https://www.din.de/de/mitwirken/normenausschuesse/naerg/veroeffentlichungen/wdc-beuth:din21:320862700.\n\n\nGould, J. D., und C. Lewis. 1987. „Designing for usability: Key principles and what designers think“. In Human-computer interaction: a multidisciplinary approach, 528–39. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.\n\n\n„Government Design Principles. GOV.UK“. 2012. 2012. https://www.gov.uk/guidance/government-design-principles.\n\n\nJakob Nielsen. 2000. „Why You Only Need to Test with 5 Users. Nielsen Norman Group“. 2000. https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/.\n\n\nKling, Rob, und Susan Leigh Star. 1998. „Human centered systems in the perspective of organizational and social informatics“. ACM SIGCAS Computers and Society 28 (1): 22–29. https://doi.org/10.1145/277351.277356.\n\n\nShneiderman, Ben, und Catherine Plaisant. 2005. Designing the user interface. Strategies for effective human-computer interaction. 4th Aufl. Pearson."
  },
  {
    "objectID": "sicherheit.html",
    "href": "sicherheit.html",
    "title": "Sicherheit & Datenschutz",
    "section": "",
    "text": "Dieses Kapitel ist noch nicht umgesetzt (siehe Issue Datensicherheit und Issue Datenschutz)."
  },
  {
    "objectID": "metadaten.html#einleitung",
    "href": "metadaten.html#einleitung",
    "title": "Daten & Metadaten",
    "section": "Einleitung",
    "text": "Einleitung\nZur Sammlung und Bereitstellung von Informationen werden von Bibliotheken Ressourcen unterschiedlichster Form (Bücher, Filme, Forschungsdaten, …) nachgewiesen. Zur Verwaltung dieser Ressourcen werden diese mit Metadaten beschrieben. Neben diesen Metadaten beinhalten bibliothekarische Informationssysteme zunehmend auch Dokumente selbst als digitale Inhalte wie sogenannte Volltexte, Digitalisate und Forschungsdaten (siehe Kapitel Digitalisierung und Forschungsnahe Dienste). Viele der im Folgenden beschriebenen Grundlagen zu Eigenschaften, Arten und Verarbeitung von Daten gelten sowohl für Metadaten als auch für digitale Inhalte."
  },
  {
    "objectID": "metadaten.html#grundlegende-begrifflichkeiten",
    "href": "metadaten.html#grundlegende-begrifflichkeiten",
    "title": "Daten & Metadaten",
    "section": "Grundlegende Begrifflichkeiten",
    "text": "Grundlegende Begrifflichkeiten\n\nDaten\nIm Wesentlichen bestehen Daten im Sinne dieses Buchs aus einer Folge von Bits. Abgesehen von ihrer Anzahl in Bytes lässt sich auf dieser Ebene allerdings nichts weiter über Daten sagen. Uns interessiert daher mehr, für was die Daten stehen – beispielsweise für eine Jahreszahl, ein Bild oder für den Titel eines Dokumentes. Dabei besteht ein Unterschied zwischen\n\nder Struktur von Daten (Syntax)\nund der Bedeutung von Daten (Semantik).\n\nZur Interpretation von Daten dienen Kodierungen in Form von Datenformaten und Identifikatoren. Wo genau jeweils die Grenze zwischen Syntax und Semantik liegt, hängt davon ab, auf welcher Ebene und mit welcher Kodierung Daten betrachtet und verarbeitet werden (siehe Tabelle 5.1):\n\n\nTabelle 5.1: Beispiele für Syntax und Semantik von Daten auf verschiedenen Ebenen\n\n\nDatenebene\nBedeutung\nKodierung\n\n\n\n\n1100001\nDie Zahl 97 (64+32+1)\nByte als Zahl\n\n\n97\nDer Buchstabe „a“\nASCII oder Unicode\n\n\na\nUnterfeld für Haupttitel\nFeld 021A im PICA+ K10plus-Format\n\n\na\nUnterfeld für Umfangsangabe\nFeld 300 im MARC21 Format\n\n\n\n\nEin Großteil der Datenverarbeitung besteht darin, Daten, zum Beispiel im Rahmen von ETL-Prozessen, von einer Kodierung in eine andere Kodierung zu überführen, um sie anschließend leichter interpretieren zu können. Bei der Konvertierung von Daten von einem in ein anderes Datenformat reduziert sich das implizite Datenmodell der Konvertierung auf den kleinsten gemeinsamen Nenner beider Formate.\nZur Beschreibung von Daten dienen\n\nformale Schemata auf Ebene der Syntax\nund Datenmodelle auf Ebene der Semantik.\n\nLeider liegen beide oft nicht explizit vor, sondern müssen anhand von Beispielen, Anwendungen und Dokumentation mühsam ermittelt werden. Im Idealfall entsprechen Daten einem klar definierten Datenformat.\n\n\nDatenformate\nDatenformate definieren eine Struktur, die sich in einer oder in mehreren austauschbaren Syntax-Varianten ausdrücken lässt und deren Bedeutung durch ein Datenmodell festgelegt ist. Beispielsweise definiert der Unicode-Standard eine Menge von Schriftzeichen (Buchstaben, Sonderzeichen, Emojis, …) und verschiedene Verfahren, um Zeichenketten in Bytes zu kodieren (UTF-8, UTF-16, …). Syntax-Varianten werden auch als Serialisierung bezeichnet. Die meisten Datenformate haben nur eine Serialisierung, so dass Format und Syntax meist synonym verwendet werden. Einzelne Syntax-Elemente entsprechen Bestandteilen im Datenmodell (siehe Tabelle 5.2), daher werden in der Beschreibung von Daten auch diese beiden Ebenen meist nicht sauber getrennt.\n\n\nTabelle 5.2: Einige Bestandteile des XML-Formats\n\n\nXML-Syntax\nXML-Modell\n\n\n\n\n&lt;name /&gt; oder &lt;name&gt;...&lt;/name&gt;\nXML-Element\n\n\nname=\"Inhalt\"\nXML-Attribut\n\n\n&lt;!-- ... --&gt;\nKommentar\n\n\n\n\nAls Faustregel kann gelten, dass bei statischer Betrachtung von Daten der Bezug auf ihre Syntax sinnvoll ist, während zur Verarbeitung von Daten eher auf die Bestandteile ihrer Modelle Bezug genommen werden sollte.\nDatenformate lassen sich grob in zwei Kategorien unterteilen:\n\nStrukturierungssprachen wie CSV, XML, JSON und RDF ermöglichen es, Daten in kleinere Einheiten zu unterteilen und miteinander in Beziehung zu setzen. Die Sprachen basieren auf allgemeinen Ordnungsprinzipien (Felder, Tabellen, Hierarchien, Netzwerke, …) und ihre Modelle haben darüber hinaus keine eigene Semantik. Die einfachste Strukturierungssprache ist das Prinzip der Zeichenkette.\nAnwendungsformate legen die Struktur von Daten für konkrete Arten von Inhalten fest (Metadatenformate zur Beschreibung von Dokumenten, Bildformate für Bilder…). Ihre Modelle verweisen letztendlich auf reale Objekte und Eigenschaften. Viele Anwendungsformate sind ihrerseits mittels einer Strukturierungssprache kodiert, zum Beispiel basiert das DataCite-Format zur Beschreibung von Forschungsdaten auf dem XML-Modell.\n\nDarüber hinaus gibt es besondere Formate, deren Anwendung in der Verarbeitung von Daten liegt. Neben Programmiersprachen, die selbst nicht als Datenformate betrachtet werden, sind dies folgende Sprachen:\n\nSchemasprachen wie XML Schema, JSON Schema und nicht zuletzt reguläre Ausdrücke dienen der formalen Beschreibung der Syntax von Datenformaten. Dabei bezieht sich jede Schemasprache auf eine Strukturierungssprache (XML Schema für XML-Formate, Avram für feldbasierte Formate, …).\nAbfragesprachen dienen dem Verweis auf einzelne Teile von Datensätzen. Sie beziehen sich ebenfalls immer auf eine Strukturierungssprache (zum Beispiel XPath für XML, JSON Path für JSON, …) und sind für die Verarbeitung von Daten notwendig.\nModellierungssprachen helfen bei der Beschreibung von Datenmodellen. Die häufigsten Modellierungssprachen basieren auf dem Entity-Relationship-Modell. Da zwischen Syntax und Semantik irgendwann die reine Datenebene verlassen werden muss, sind die wichtigsten Mittel zur Datenmodellierung allerdings Diagramme und Beschreibungen in natürlicher Sprache.\n\nDie Verwendung von Schema-, Abfrage- und Modellierungssprachen hilft, viele häufige Fehler bei der (Meta-)Datenverarbeitung zu vermeiden. Ein Beispiel hierfür ist das Resource Description Framework (RDF) mit dazugehörigen Schemasprachen (SHACL/ShEx), Abfragesprachen (SPARQL) und Modellierungssprachen (RDFS/OWL). In anderen Fällen wird aus Mangel an Werkzeugen und Kenntnissen auf spezielle Datensprachen verzichtet und stattdessen auf allgemeine Programmiersprachen zurückgegriffen.\n\n\n\n\n\n\nInfo\n\n\n\nReguläre Ausdrücke sind das gängigste Mittel zur Beschreibung der Syntax von Daten. Gleichzeitig können mit ihnen Zeichenketten nach Mustern durchsucht werden. Ein regulärer Ausdruck für die Syntax einer ISBN-13 mit optionalen Trennstrichen ist beispielsweise:\n(97[89])-?([0-9]{1,5})-?([0-9]+)-?([0-9]+)-?[0-9]\nÜblicherweise decken Schemasprachen nicht alle Aspekte eines Datenformats ab. So lässt sich die Korrektheit der abschließenden Prüfziffer ([0-9]) nicht mit einem regulären Ausdruck überprüfen.\n\n\nEine ausführlichere Beschreibung von Datenformaten mit bibliothekarischem Schwerpunkt bietet die Datenbank format.gbv.de. Grundlagen von Metadaten und Ontologien vermitteln Assfalg (2023) und Rölke und Weichselbraun (2023).\nIn der Praxis werden Daten in einem Datenformat zusätzlich durch anwendungsspezifische Auslegungen und Einschränkungen geprägt, darunter Format-Varianten, Metadatenprofile bzw. Anwendungsprofile, Erfassungsregeln und die jeweilige Erfassungspraxis.\n\n\nIdentifikatoren\nEin wesentlicher Teil von Daten besteht aus Identifikatoren (IDs wie Nummern, Codes…) zum Verweis auf externe Objekte oder an anderer Stelle verwaltete Informationen. Identifikatoren ermöglichen die eindeutige Referenzierung gleicher Dinge in unterschiedlichen Kontexten, so dass Daten aus verschiedenen Quellen miteinander abgeglichen und kombiniert werden können.\nNeben eher intern genutzten Datensatz-Identifikatoren (z.B. die PPN des Bibliothekssystems PICA oder die ZDB-ID der Zeitschriftendatenbank) sind vor allem international standardisierte Identifikatoren von Bedeutung. Beispiele für solche Identifier-Systeme mit Relevanz für bibliothekarischer Daten sind die nachfolgenden:\n\nDie International Standard Book Number (ISBN) wird von Verlagen für Bücher vergeben. Seit 2007 ist die 13-stellige ISBN Teil des EAN-Barcode-Systems.\nDie International Standard Serial Number (ISSN) identifiziert Zeitschriften und Schriftenreihen.\nDer Digital Object Identifier (DOI) identifiziert digitale Publikationen in elektronischen Zeitschriften und Repositorien.\nDer International Standard Identifier for Libraries and Related Organisations (ISIL) referenziert Bibliotheken, Archive, Museen und verwandte Einrichtungen.\nDie Open Researcher and Contributor ID (ORCID) identifiziert Autor*innen von wissenschaftlichen Publikationen.\nDer Uniform Resource Locator (URL) dient als Adresse einer digitalen Ressource im Web und wird teilweise gleichzeitig als deren Identifikator eingesetzt.\nDas System der Uniform Resource Identifier (URI) ermöglicht die Vereinigung verschiedener Identifier-Systeme und bildet die Grundlage von RDF und Linked Open Data (LOD).\n\nGemeinsam ist den Identifikatoren, dass sie jeweils eine definierte Syntax haben (z.B. XXXX-XXXY im Falle der ISSN, wobei X für eine Ziffer und Y für eine Prüfziffer steht), deren Bestandteile hierarchisch von einer zentralen Instanz festgelegt werden. Nach dem Prinzip des Namensraums kann dabei die Vergabe von Teilen an untergeordnete Organisationen delegiert werden. Beispielsweise werden ISIL für Bibliotheken in Deutschland beginnend mit dem Präfix „DE-“ durch die ISIL-Agentur an der Staatsbibliothek zu Berlin verwaltet.\nVöllig dezentrale Identifikatoren gibt es zur Identifizierung von digitalen Objekten nur in Form von Prüfsummen, die sich automatisch aus vorhandenen Daten berechnen lassen (SHA-Summe, IPFS-Adresse, Prüfziffer…).\n\n\nNormdaten\nEinfache kontrollierte Vokabulare bestehen aus normierten Listen von eindeutigen Benennungen – beispielsweise könnte in einem Gemüse-Vokabular festgelegt sein, dass immer „Karotte“ statt „Möhre“ verwendet werden muss. Wird jeder Eintrag mit einem künstlichen Identifikator versehen, muss die Benennung selbst nicht eindeutig sein. Existiert eine Datenbank zum Nachschlagen dieser IDs, so wird diese auch als Normdatei bezeichnet. Ihre Datensätze dienen als Normdaten der eindeutigen Identifizierung von Personen, Organisationen, geographischen oder administrativen Einheiten, Themen oder anderen Entitäten an verschiedenen Stellen. Ein Normdatensatz besteht mindestens aus einem Identifikator und einer Vorzugsbenennung als primärer Name. Oft gibt es weitere identifizierende Merkmale wie alternative Benennungen, Lebensdaten von Personen, Ortsangaben u.Ä. sowie Verknüpfungen zwischen verschiedenen Entitäten.\nUmfang und Komplexität von Normdateien reichen von einfachen Listen bis zu komplexen Wissensgraphen. Ein prominentes bibliothekarisches Beispiel ist die Gemeinsame Normdatei (GND), in der neben Personen auch Körperschaften, Veranstaltungen, Geografika, Werke und Sachschlagwörter miteinander vernetzt sind.\nZur Anreicherung von Daten mit Normdaten mittels Entity Recognition (Erkennung von Entitäten in Daten) und Entity Linking (Abgleich von Entitäten mit IDs anderer Normdateien) sollte unterschieden werden zwischen:\n\nNormdateien mit Entitäten wie Personen (ORCID), Publikationen (DOI, ISBN), Sprachen (ISO 639) etc., die sich grundsätzlich eindeutig unterscheiden lassen sowie\nNormdateien, deren abstrakte Entitäten von Kontext und Modellierung abhängen (Klassifikationen, Thesauri, …).\n\nZur Verwaltung von Normdaten gibt es einige Datenformate wie MARC 21 for Authority Data und ISAAR (CPF). Als gemeinsamer Nenner auch außerhalb des Bibliotheksbereichs gilt das RDF-basierte Simple Knowledge Organization System (SKOS), für das mit JSKOS auch eine JSON-Variante existiert. Vor allem kleinere oder speziellere Normdateien (z.B. Codelisten im Rahmen der Katalogisierung) liegen allerdings selten in maschinenlesbarer Form vor.\nDas Basic Register of Thesauri, Ontologies & Classifications (BARTOC) erfasst Informationen zu Normdateien aller Art, darunter auch Verfahren zum technischen Zugriff."
  },
  {
    "objectID": "metadaten.html#metadatenstandards",
    "href": "metadaten.html#metadatenstandards",
    "title": "Daten & Metadaten",
    "section": "Metadatenstandards",
    "text": "Metadatenstandards\nNeben allgemeinen Datenformaten sind für die Bibliotheks-IT vor allem Metadatenformate zur Beschreibung von Dokumenten relevant. Die meisten der im Folgenden beschriebenen Metadatenformate spielen außerhalb von Kultureinrichtungen keine wesentliche Rolle. Für digitale Objekte (METS/MODS, LIDO, CDWA, EN 15907, EAD, …, siehe Kapitel Digitalisierung) und für Forschungsdaten (DataCite, siehe Kapitel Forschungsnahe Dienste) gibt es darüber hinaus spezielle Formate.\n\nArten von Metadaten\nFolgende Arten von Metadaten können nach ihrer Funktion unterschieden werden:\n\nDeskriptive (=beschreibende) Metadaten zur Identifizierung und inhaltlichen Beschreibung wie Titel, Verfasser*in, Schlagwörter etc.\nAdministrative (=Verwaltungs-) Metadaten wie Angaben zu Herkunft, Speicherung, Zugriffsrechten, Verwaltung etc.\nStrukturelle Metadaten über den Aufbau von Dokumenten wie die Einteilung in einzelne Kapitel, Abschnitte, eingebundene Medien etc. Die Grenze zwischen digitalen Inhalten und ihrer Struktur ist allerdings mitunter fließend.\nTechnische Metadaten zu Merkmalen wie Umfang, verwendeten Datenformaten etc.\n\nJe nach Anwendung gibt es spezielle Metadatenformate oder es werden verschiedene Arten von Beschreibungen in einem Format zusammengefasst.\n\n\nFeldbasierte bibliothekarische Metadatenformate\nMachine-Readable Cataloging (MARC) ist das älteste und noch immer wichtigste Format für den Austausch von Daten zwischen Bibliotheken. Die aktuell relevante Variante ist MARC 21, insbesondere das Format MARC 21 für bibliographische Daten. Neben der binären Kodierung kann MARC 21 auch in XML und JSON kodiert werden. Viele Eigenheiten und Probleme des Formats sind historisch bedingt, eine Alternative konnte sich bislang nicht durchsetzen.\nPICA ist das von MARC inspirierte Datenformat der Katalogisierungssysteme CBS und LBS (Voß 2022). Das wichtigste Anwendungsprofil ist das K10plus-Format des BSZ/GBV.\nMAB und allegro sind ebenfalls an MARC angelehnte, feldbasierte Formate aus dem deutschsprachigen Raum, die allerdings nur noch sporadisch verwendet werden.\n\n\nXML-basierte Datenformate\n\nMETS und MODS sind zwei zusammen im Bereich Digitalisierung eingesetzte Formate für strukturelle und administrative (METS) sowie bibliografische Metadaten (MODS). Strukturdaten in METS ermöglichen granulare Gliederung und Verlinkung von Objekten wobei mögliche Typen und Beziehungen in Regelsätzen definiert sind.\nEncoded Archival Description (EAD) ist der zentrale dokumentarische XML-Standard zur Beschreibung von archivischen Findmitteln.\nLIDO ist ein etabliertes Austauschformat für den Museumsbereich.\nDataCite ist ein bibliographisches Datenformat insbesondere zur Beschreibung von Forschungsdaten (siehe Kapitel Forschungsnahe Dienste).\n\n\n\nDatenmodelle und RDF-Formate\n\n\n\n\n\n\nDefinition\n\n\n\nEine Ontologie ist ein Datenmodell, das verschiedene Klassen und Eigenschaften in RDF definiert und so die einheitliche Kodierung und Verknüpfung verschiedener Datenquellen als Linked Data bis zu umfangreichen Wissensgraphen ermöglicht.\n\n\nDublin Core bzw. das Dublin Core Metadata Element Set (DCMES) hat als kleinster gemeinsamer Nenner der meisten Metadatenstandards die größte Verbreitung. Es besteht aus 15 Basiselementen wie „creator“, „title“, „date“ und „description“ und Erweiterungen mit den DCMI Metadata Terms wie „Alternative Title“, „Date Created“ und „Date Available“.\nDie Functional Requirements for Bibliographic Records (FRBR) sind ein sehr abstraktes Metadatenmodell. Sie beinhalten insbesondere eine Einteilung von bibliographischen Entitäten in die Beschreibungsebenen „work“, „expression“, „manifestation“ und „item“.\nDie BIBFRAME-Ontologie wurde entwickelt, um MARC auf Grundlage von RDF zu ersetzen. Die wesentlichen Elemente sind „work“, „instance“ und „item“ sowie damit verbundene Eigenschaften und Entitätstypen (siehe Abbildung 5.1).\nSchema.org ist eine allgemeine Ontologie für strukturierte Daten in Webseiten.\n\n\n\nAbbildung 5.1: Hauptbestandteile des Datenmodell BIBFRAME\n\n\n\n\nVerlagsdaten und Literaturangaben\nDie Formate ONIX, JATS, BITS und CrossRef XML stammen aus dem Verlagsbereich zur Beschreibung von Zeitschriftenartikeln und Büchern. Sie basieren alle auf XML und sind für Bibliotheken für den Datenimport relevant. Datenformate für Literaturangaben (BibTeX, RIS, Endnote, CSL-JSON…) werden dagegen zum Export von Katalogdaten bereitgestellt. Zitationsregeln für Literaturangaben und Ansetzungsregeln von ISBD sind dagegen für den Datenaustausch eher unbrauchbar. Learning Object Metadata (LOM) dient in verschiedenen lokalen Anpassungen der Beschreibung von Lerneinheiten."
  },
  {
    "objectID": "metadaten.html#datenverarbeitungsprozess-in-bibliotheken",
    "href": "metadaten.html#datenverarbeitungsprozess-in-bibliotheken",
    "title": "Daten & Metadaten",
    "section": "Datenverarbeitungsprozess in Bibliotheken",
    "text": "Datenverarbeitungsprozess in Bibliotheken\n\nDatenerfassung\nTraditionell werden bibliothekarische Metadaten durch Katalogisierung erstellt. Die Verwaltung der Katalogdaten erfolgt entweder lokal oder gemeinsam in einer Verbunddatenbank. Der Vorteil der Verbundkatalogisierung liegt darin, dass jedes Dokument nur einmal zentral beschrieben werden muss, während bei lokaler Katalogisierung durch Fremddatenübernahme nur zum Teil auf vorhandene Kataloge zurückgegriffen werden kann.\nIm Idealfall sollte die Erfassung nach Autopsie, also auf Grundlage des vorliegenden Werkes, durch geschultes Personal und nach etablierten Regelwerken (Katalogisierungsrichtlinien) erfolgen. Um möglichst viele Publikationen zu erfassen, wird jedoch zunehmend auch auf anderweitig erfasste Metadaten von Verlagen, Repositorien und aus anderen Quellen zurückgegriffen. Dazu müssen Daten unterschiedlicher Erschließungstiefe und -qualität im Rahmen von ETL-Prozessen gesammelt, analysiert und mit vorhandenen Daten vereinheitlicht werden. In jedem Fall muss beachtet werden, dass sich Regeln und Umstände, nach denen Daten erfasst werden, mit der Zeit ändern können (beispielsweise der Umstieg der Erfassungsregeln von RAK auf RDA) und dass das Ergebnis auch davon abhängt, wie gut überprüft werden kann, was die Anforderungen an die Daten sind.\nDarüber hinaus gibt es Verfahren zur automatischen Erstellung von Metadaten aus vorhandenen Dokumenten, beispielsweise zur Erkennung und Auswertung von Literaturangaben und zur thematischen Einordnung von Dokumenten. Mit diesen Verfahren lassen sich zwar größere Mengen von Daten erfassen, es muss aber immer mit einer gewissen Fehlerrate gerechnet werden.\nWelche Art und welcher Umfang von Fehlern und Uneinheitlichkeiten bei der Datenerfassung tolerierbar sind, hängt letztlich davon ab, wozu die Daten erfasst werden. So gelten beispielsweise für eine historische Bibliographie andere Maßstäbe als für einen Suchindex.\nNicht zuletzt sollte bedacht werden, dass Geschwindigkeit und Qualität von Datenerfassung auch von der Usability der Werkzeuge abhängen, mit denen Daten erstellt, bearbeitet und analysiert werden können.\n\n\n\n\n\n\nInfo\n\n\n\nMehr zur bibliothekarischen Datenerfassung in den Grundlagen der Informationswissenschaft (2023), Teil B.\n\n\n\n\nETL-Prozess\nDa sich die IT in- und außerhalb von Bibliotheken über verschiedene Organisationen und Systeme erstreckt, müssen an vielen Stellen Daten von einer oder mehreren Quellen in ein anderes Informationssystem übertragen werden. Der grundsätzliche Prozess der Datenintegration, der Quell- und Zielsysteme verbindet, wird als ETL-Prozess bezeichnet. Der Prozess aus drei zentralen Schritten „Extract“, „Transform“ und „Load“ stammt ursprünglich aus dem Bereich des Data Warehousing und findet sich auch in anderen Anwendungsfällen. Im Folgenden wird er am Beispiel der Integration von Metadaten in ein Discovery-System beschrieben. Abbildung 5.2 illustriert den generellen ETL-Prozess mit einigen exemplarischen Arbeitsschritten.\n\n\n\nAbbildung 5.2: Beispiel eines ETL-Prozess\n\n\n\nExtraktion\nZiel der Extraktion (Extract) ist die Auswahl und der Abzug relevanter Daten aus verschiedenen Datenquellen. Hierbei handelt es sich primär um einen technischen Vorgang, das sogenannte Harvesting, welcher automatisiert oder manuell gestartet werden kann. Der Aufwand und die Qualität des Harvesting können je nach Datenquelle sehr unterschiedlich ausfallen. Denkbare Datenquellen sind Dateien, Datenbanken bzw. Datenbankabzüge, Schnittstellen oder eher unstrukturierte Quellen wie Websites, die zunächst mittels Screenscraping erschlossen werden müssen.\nDer Extraktionsvorgang erfolgt bei Bedarf regelmäßig, um die Daten im Zielsystem aktuell zu halten. Mögliche Aktualisierungsintervalle sind:\n\nperiodisch, das heißt in zeitlich regelmäßigen Abständen unabhängig von der jeweiligen Aktualisierung der Daten in den Quellsystemen\nereignisgesteuert, immer wenn bestimmte Bedingungen wie zum Beispiel die Änderung von Daten in den Quellsystemen eintreten\nmanuell, beispielsweise wenn Daten aus Quellsystemen ad hoc importiert werden sollen. Manuelle Aktualisierungen bieten sich vor allem an, wenn der Inhalt der Datenquellen weitestgehend statisch ist, da die dauerhaft verlässliche Aktualisierung im Zielsystem ohne Automatismus nicht garantiert ist.\n\nDer Extraktionsvorgang ist technisch relativ einfach handhabbar, wenn strukturierte Datenformate und/oder Schnittstellen existieren — die wesentlichen Aufwände finden sich dann im nachfolgenden Transformationsschritt. Anders sieht es aus, wenn beispielsweise Daten manuell eingesammelt werden müssen oder Screenscraping notwendig ist. Beim Screenscraping müssen aufwändig Extraktionsskripte erstellt werden, um Daten aus Webseiten in ein strukturiertes Format zu überführen. Diese Skripte sind zudem sehr fehleranfällig und müssen jedes Mal angepasst werden, wenn die Betreiber*innen der Datenquelle Veränderungen vornehmen.\nDie extrahierten Daten werden in einem sogenannten Arbeitsbereich abgelegt und dort im nächsten Prozessschritt aufbereitet.\n\n\nTransformation\nDaten aus verschiedenen Quellsystemen liegen zumeist in unterschiedlichen Formaten mit unterschiedlichen Datenmodellen vor. Neben Unterschieden in der Syntax können gleiche Sachverhalte auch auf semantischer Ebene unterschiedlich beschrieben sein, da die Daten mitunter für abweichende Anwendungsfälle erfasst wurden. So müssen beispielsweise in einem Discovery-System Metadaten zur einfachen Beschreibung so aufbereitet werden, dass sie auch erweiterte Suchstrategien unterstützen.\nZiel der Transformation ist es, alle Daten in ein einheitliches Format mit gemeinsamen Datenmodell zu überführen. Dieses Zielformat wird beim ETL-Prozess auch als Schema bezeichnet. Die Vereinheitlichung des Schemas (Mapping) ist ein wesentlicher Schritt jeder Datenkonvertierung. Zur Minimierung des Transformationsaufwands dienen gemeinsame Standards wie MARC21 als Austauschformat oder die einheitliche Verwendung von RDF-Ontologien.\nÜber die einfache Konvertierung hinaus sind im Rahmen der Transformation oft weitere Aufbereitungen zur Vereinheitlichung und Verbesserung der Datenqualität notwendig. Beispiele hierfür sind:\n\nPrüfung und Vereinheitlichung der Zeichencodierung auf normalisierten Unicode\nformale Anpassungen von Daten wie die Vereinheitlichung von Datumsformaten, Ländercodierungen etc.\nErkennung und Eliminierung von Duplikaten\nAbgleich, Vereinheitlichung und Konsistenzprüfung von Aussagen über dieselben Objekte aus verschiedenen Datenquellen\nAnreicherung oder Korrektur von Datensätzen mittels Zusatzinformationen aus Normdaten oder anderer zusätzlicher Datenquellen\n\nDer Aufwand der Transformation sollte nicht unterschätzt werden, da die Datenqualität verschiedener Datenquellen stark variieren kann und Qualitätsprobleme oft erst spät entdeckt werden. Zudem können sich Datenquellen und ihre Qualität zwischen Aktualisierungen ändern. Sofern die Datenübernahme nicht nur einmalig stattfinden soll (Konversion), ist die Betreuung des Transformationsschrittes eine Daueraufgabe.\nDa im Transformationsschritt regelmäßig Massendaten analysiert und modifiziert werden müssen, ist der Einsatz von IT-gestützten Werkzeugen und Verfahren der Datenanalyse unerlässlich. Die aus der Analyse gewonnenen Erkenntnisse müssen wiederum kontinuierlich in die Anpassung des Schema-Mappings einfließen, damit der Transformationsprozess nicht ins Stocken gerät.\n\n\nLaden\nAuf die Transformation folgt beim Laden (load) die Überführung der vereinheitlichten Daten in das Zielsystem – beispielsweise in den Suchindex eines Discovery-Systems. Dabei dürfen nur Datensätze in Produktivsysteme übernommen werden, die den Transformationsschritt erfolgreich durchlaufen haben, während für Test- und Entwicklungssysteme andere Regeln möglich sind.\nDas Laden selbst ist ein technisch beherrschbarer Schritt, welcher optimalerweise darauf abzielt, das Zielsystem ohne Ausfallzeiten aktuell zu halten. Bei Änderungen des Schemas muss deshalb besonders darauf geachtet werden, gleichzeitig entsprechende Anpassungen im Zielsystem vorzunehmen. Daneben ist es bei absehbaren Änderungen ratsam, das Schema und die Verarbeitung von Daten im Zielsystem von Vornherein flexibel zu gestalten.\n\n\nUmsetzung des ETL-Prozess\nDie Umsetzung von Datenkonvertierung und ETL-Prozessen erfolgt im bibliothekarischen Umfeld oft über selbst entwickelte Skripte für das Harvesting und die Transformation. Das entsprechende Know-How ist in der Regel auf wenige Köpfe verteilt und kann auch nicht leicht durch das Hinzuziehen externer Expertise verfügbar gemacht werden.\nEs gibt einige kommerzielle ETL-Komplettlösungen mit Data-Warehouse- oder Business-Intelligence-Hintergrund. Angesichts der teils erheblichen Einstiegskosten und zur Vermeidung von vendor-lock-in sind für Bibliotheken möglichst einfache und allgemeine Werkzeuge zur Datenverarbeitung jedoch meist die bessere Wahl. Die Vorteile etablierter ETL-Werkzeuge liegen in Schulungsmöglichkeiten und der Verfügbarkeit externer Expertise. Mit Catmandu, Metafacture und OpenRefine gibt es mehrere Open Source- ETL-Frameworks, deren eingeschränkter Funktionsumfang und verbesserungswürdige Usability durch Anpassungen für bibliothekarische Datenformate und Schnittstellen möglicherweise aufgewogen werden.\nGrundsätzlich lassen sich die kontinuierlich anfallenden Aufwände der Transformation und Qualitätssicherung durch ein ETL-Werkzeug nicht vermeiden, sondern nur besser handhabbar machen. Dazu sollten die einzelnen Arbeitsschritte zentral verwaltet und dokumentiert werden, beispielsweise durch ein Versionskontrollsystem. Durch den Fokus auf Usability kann mittels ETL-Werkzeugen bibliothekarisches Personal stärker eingebunden werden. Da hier insbesondere im Bereich der Programmierung die Einstiegshürden niedriger sind, ist es Fachpersonal leichter möglich, direkt Änderungen und Optimierungen am ETL-Prozess vorzunehmen. Bei einer reinen Verankerung von ETL im IT-Bereich sind solche Eingriffe dagegen nur in Zusammenarbeit von IT und Metadaten-Expert*innen umsetzbar.\nIn jedem Fall gehen mit der Einführung von ETL-Werkzeugen in die bibliothekarische Arbeit immer auch individuelle Anpassungen im Prozess von Extraktion, Transformation und Laden einher. Dieser Aufwand kann sowohl gegen die Einführung solcher Werkzeuge sprechen als auch dafür, vorhandene „Bastellösungen“ zu evaluieren und zu konsolidieren.\n\n\n\nWerkzeuge\nFür die Verarbeitung von Daten im Rahmen bibliothekarischer IT-Systeme werden grundsätzlich die gleichen Werkzeuge verwendet wie außerhalb des Bibliothekswesens, daher wird an dieser Stelle auf eine allgemeine Einführung in die Datenverarbeitung verzichtet. Ganz allgemein sind hier als Werkzeuge\n\nMittel zur Dateiverwaltung und ein Texteditor unabdingbar,\nallgemeine Kommandozeilenprogramme (curl, sort, grep…) sehr zu empfehlen\nund Programmiersprachen vor allem für komplexere Aufgaben hilfreich.\n\nMaterial und Kurse für die praktischen Grundkenntnisse mit Bibliotheksbezug finden sich insbesondere in den Bereichen Data Librarianship und Data Science.\nWerkzeuge für konkrete Datenformate orientieren sich an den zugrunde liegenden Strukturierungssprachen. So gibt es beispielsweise eigene Editoren oder Editor-Plugins für XML-Daten und JSON-Daten und entsprechende Kommandozeilentools wie xmlstarlet für XML und jq für JSON. Für tabellarische Daten eignet sich etwa eine Tabellenkalkulation oder das tabellenbasierte Werkzeug OpenRefine (openrefine.org).\nFür bibliothekarische Datenformate und Schnittstellen gibt es darüber hinaus einige speziellere Werkzeuge:\n\nProgrammierbibliotheken wie MARC4J und YAZ erleichtern die Datenverarbeitung im Rahmen eigener Programme.\nAnwendungsprogramme wie WinIBW und BibControl erfordern zwar weniger IT-Kenntnisse, sind dafür aber nur eingeschränkt und/oder nur für sehr spezielle Aufgaben verfügbar.\nFreie Werkzeuge zum Metadatenmanagement wie die Frameworks Catmandu (librecat.org/Catmandu) und Metafacture (metafacture.org).\n\nFür einzelne Anwendungen und Formate gibt es einige weitere Werkzeuge und es kann sich lohnen, solche Werkzeuge selbst zu entwickeln und als Open Source zur Verfügung zu stellen. Für das PICA-Format sind solche Programme in der Einführung in die Verarbeitung von PICA-Daten (Voß 2022) aufgeführt.\n\n\nSchnittstellen\nEine API (Application Programming Interface, auch Programmierschnittstelle) ist eine definierte Methode zur Abfrage und/oder Änderung von Daten in einem Informationssystem. Wie die Daten innerhalb des Systems verwaltet werden, ist dabei nebensächlich. Dieses Prinzip ermöglicht die Kombination unterschiedlicher Softwarekomponenten. Wenn möglich, sollten produktunabhängige, offen dokumentierte APIs verwendet werden. Im Bibliotheksbereich sind insbesondere folgende APIs relevant:\n\nZ39.50 wurde vor Erfindung des Web zur Suche in Bibliotheksdatenbanken entwickelt. Nachfolger ist das XML-basierte Search/Retrieve via URL (SRU) mit der zugehörigen Abfragesprache Contextual Query Language (CQL).\nDas Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) dient dem Abruf von Metadaten aus Repositorien. Die Daten können nach Datum und Teilmengen gefiltert und so in Suchmaschinen und Portalen wie BASE und der Deutschen Digitale Bibliothek (DDB) zusammengeführt werden.\nDas NISO Circulation Interchange Protocol (NCIP), das Simple Library Network Protocol (SLNP) und das Standard Interchange Protocol (SIP2) sind interne APIs für Ausleihe und Fernleihe. Sie werden zwischen Bibliotheken, Fernleihservern und zur Anbindung von Verbuchungsautomaten eingesetzt (Michaelis 2014).\nDie Patrons Account Information API (PAIA) ist eine offene Schnittstelle zum Zugriff auf Ausleihkonten.\nDie Document Availability Information API (DAIA) ist eine offene Schnittstelle zur Abfrage der Verfügbarkeit von Medien.\nMit unAPI können einzelne Datensätze in verschiedenen Formaten abgerufen werden.\nDie Reconciliation Service API ermöglicht den Abgleich mit Normdaten zur eindeutigen Referenzierung (siehe Abschnitt Identifikatoren und Normdaten).\nDie APIs des International Image Interoperability Framework (IIIF) ermöglicht die Referenzierung und Nutzung digitalisierter Werke in externen Werkzeugen durch gezielte Verlinkung auf einzelne Bestandteile.\nÜber SPARQL-Schnittstellen können RDF-Daten aus Wissensgraphen wie zum Beispiel Wikidata abgerufen werden.\nVerschiedene Schnittstellen zur Authentifizierung und Autorisierung wie LDAP, Shibboleth und OAuth.\n\nDarüber hinaus bieten die meisten Anwendungen eigene, meist interne Schnittstellen, zum Beispiel die Solr-API der Suchplattform Apache Solr. Besonders im Bereich Forschungsnaher Dienste gibt es weitere, spezialisierte Schnittstellen.\n\n\nDatenanalyse\nIm Gegensatz zu physischen Objekten ist Daten ihre Beschaffenheit nicht direkt anzusehen. Lediglich der Umfang von Daten in Bytes und ggf. die Anzahl von Dateien und Datensätzen kann einen ersten Anhaltspunkt liefern. Weitere Einschätzungen, insbesondere darüber, ob Daten vollständig oder fehlerhaft sind, setzen eine konkrete Analyse der Daten voraus. Dies beinhaltet auch die Visualisierung von Daten zur Exploration, Kommunikation und Diskussion (Jetter 2023).\nDie Auswertung von Daten ist nicht nur für das Qualitätsmanagement relevant (Voß 2021), beispielsweise um im Rahmen des ETL-Prozesses Verteilungen und Ausreißer zu erkennen, sondern auch um aus Daten weitere Erkenntnisse zu gewinnen. So können beispielsweise Ausleihzahlen nach Medien gruppiert für die Bestandsplanung eingesetzt werden. Voraussetzung dafür ist, dass Daten überhaupt vorliegen, ebenso wie Mittel und Kenntnisse zu ihrer Auswertung. Bei fehlenden oder zu umfangreichen Daten können Stichproben erhoben werden, wobei auf die Zufälligkeit der Stichprobe und das Konfidenzintervall des Ergebnisses geachtet werden muss.\nNeben rudimentären Statistik-Kenntnissen helfen bei der Datenanalyse Werkzeuge wie die im vorigen Abschnitt beschriebenen Mittel zur Datenverarbeitung. Für allgemeine Analysen eignet sich vor allem eine Tabellenkalkulation. Für komplexere Analysen gibt es spezielle Statistik-Programme und Programmiersprachen wie SAS und R. Für explorative Analysen und um bei geänderter Datenlage automatisch aktuelle Ergebnisse zu bekommen, bieten sich interaktive Umgebungen wie Jupyter Notebooks oder Observable an. Für spezielle, wiederkehrende Analysen und Aufbereitungen kann es auch sinnvoll sein, eigene Anwendungen zu entwickeln bzw. entwickeln zu lassen. Beispiele hierfür sind BibControl, das Metadata Quality Assessment Framework (MQA), die Deutsche Bibliotheksstatistik sowie Statistikfunktionen als Teil anderer Programme (zum Beispiel Statistik und Reporting als Teil des BMS)."
  },
  {
    "objectID": "metadaten.html#zusammenfassung-ausblick",
    "href": "metadaten.html#zusammenfassung-ausblick",
    "title": "Daten & Metadaten",
    "section": "Zusammenfassung & Ausblick",
    "text": "Zusammenfassung & Ausblick\nStrukturierte Metadaten sind unverzichtbar für die Verwaltung und den Zugriff auf Ressourcen in Bibliotheken. Daher bilden sie und ihre Verarbeitung die Grundlage für praktisch alle von Bibliotheken angebotene IT-Dienste. Während Aufwand und Bedeutung von Datenverarbeitung auch in Zukunft hoch bleiben wird, ist davon auszugehen, dass der Einsatz semantischer Technologien (RDF) zur Zusammenführung heterogener Daten und von Verfahren der künstlichen Intelligenz zunehmen wird.\n\n\n\n\nAssfalg, Rolf. 2023. „Metadaten“. In Grundlagen der Informationswissenschaft, herausgegeben von Rainer Kuhlen, Dirk Lewandowski, Wolfgang Semar, und Christa Womser-Hacker, 7. Ausgabe, 245–56. Berlin, Boston: De Gruyter Saur. https://doi.org/10.1515/9783110769043-021.\n\n\nJetter, Hans-Christian. 2023. „Informationsvisualisierung und Visual Analytics“. In Grundlagen der Informationswissenschaft, herausgegeben von Rainer Kuhlen, Dirk Lewandowski, Wolfgang Semar, und Christa Womser-Hacker, 7. Ausgabe, 295–306. Berlin, Boston: De Gruyter Saur. https://www.degruyter.com/document/doi/10.1515/9783110769043-025/pdf.\n\n\nKuhlen, Rainer, Dirk Lewandowski, Wolfgang Semar, und Christa Womser-Hacker, Hrsg. 2023. Grundlagen der Informationswissenschaft. 7. Ausgabe. Berlin, Boston: De Gruyter Saur. https://doi.org/doi:10.1515/9783110769043.\n\n\nMichaelis, Barbara. 2014. In RFID für Bibliothekare: ein Vademecum, herausgegeben von Frank Seeliger, 3. Auflage, 145–50. Verlag News & Media. https://doi.org/10.15771/RFID_2014_13.\n\n\nRölke, Heiko, und Albert Weichselbraun. 2023. „Ontologien und Linked Open Data“. In Grundlagen der Informationswissenschaft, herausgegeben von Rainer Kuhlen, Dirk Lewandowski, Wolfgang Semar, und Christa Womser-Hacker, 7. Ausgabe, 257–70. Berlin, Boston: De Gruyter Saur. https://www.degruyter.com/document/doi/10.1515/9783110769043-022/pdf.\n\n\nVoß, Jakob. 2021. „Datenqualität als Grundlage qualitativer Inhaltserschließung“. In Qualität in der Inhaltserschließung, 167–76. De Gruyter Saur. https://doi.org/10.1515/9783110691597-010.\n\n\n———. 2022. „Einführung in die Verarbeitung von PICA-Daten“. 2022. https://pro4bib.github.io/pica/."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#einleitung",
    "href": "bibliotheksmanagementsysteme.html#einleitung",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Einleitung",
    "text": "Einleitung\nDas BMS spielt eine zentrale Rolle für die meisten klassischen Geschäftsprozesse in Bibliotheken.\n\n\n\n\n\n\nDefinition\n\n\n\nEin Bibliotheksmanagementsystem ist ein Softwareprodukt, mit dem die Arbeitsprozesse rund um die Erwerbung, Erschließung, Ausleihe, den Zugriff und die Auffindbarmachung von Bibliotheksbeständen über Kataloge abgebildet und automatisiert werden können.\n\n\nDurch die Ausweitung der Aufgaben in den Bereichen Publikationsdienste, Open Science oder auch Lernort sind in neuerer Zeit jedoch noch weitere Aufgaben hinzugekommen, die durch die klassischen BMS nicht abgebildet werden. Darüber hinaus haben die frühen Systeme nur sehr unzureichende Möglichkeiten, die nötigen Informationen zu elektronischen Ressourcen und ihrer Zugänglichkeit abzubilden. Auch zur Unterstützung von neueren Aufgaben wie der Publikationsunterstützung oder der Verwaltung räumlicher Ressourcen werden separate Systeme genutzt. Daraus ergibt sich der Bedarf, das BMS an diese separaten Systeme anzubinden, was die Bedeutung von Schnittstellen und offenen Architekturen erhöht hat.\nIn diesem Text wird der Begriff Bibliotheksmanagementsystem verwendet. Teilweise wird im Deutschen auch der allgemeinere Begriff Bibliothekssystem verwendet. In der angloamerikanischen Literatur finden sich die Begriffe Integrated Library System (ILS) und Library Management System (LMS), zuletzt aber auch Library Services Platforms."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#geschichte-der-bibliotheksmanagementsysteme",
    "href": "bibliotheksmanagementsysteme.html#geschichte-der-bibliotheksmanagementsysteme",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Geschichte der Bibliotheksmanagementsysteme",
    "text": "Geschichte der Bibliotheksmanagementsysteme\nIhren Ursprung haben Bibliotheksmanagementsysteme in den 1960er Jahren, als Bibliotheken damit begannen, Katalogdaten untereinander auszutauschen und auf diese Weise Prozesse zu optimieren. In dieser Zeit entwickelten sich auch die heute noch gebräuchlichen Austauschformate für Katalogdaten, z.B. MARC.\nIn den 1970er Jahren erlaubte die fortschreitende technische Entwicklung die Automatisierung weiterer Prozesse über den Datenaustausch hinaus. Zunächst war dies vor allem die Ausleihe mit der Verbuchung von Medien und der Erzeugung von Mahnschreiben. Auch die Verwaltung von Bestellungen im Rahmen der Erwerbung wurde möglich, so dass man in der Folge von Integrated Library Systems zu sprechen begann. Davon, dass Katalog-, Erwerbungs- und Nutzer*innen-Daten an einem Ort gehalten und bearbeitet wurden, versprach man sich eine größere Effizienz der Arbeitsprozesse. Diese erste Generation von BMS beinhaltete teilweise auch schon digitale Funktionen für Bibliotheksnutzer*innen wie über Telnet erreichbare Kataloge, die von Anfang an als integraler Bestandteil der BMS gesehen wurden (Borgman 1997).\nDie Entstehung des World Wide Web in den 1990er Jahren hatte zunächst vor allem Einfluss auf die Benutzbarkeit der Kataloge, die Web-Oberflächen erhielten. Aber auch die anderen Komponenten der BMS wurden überarbeitet, und zwar zunehmend auch von kommerziellen Anbietern, während die ersten Systeme als Eigenentwicklungen von Bibliotheken entstanden. Die Landschaft an Systemen der 2. Generation war von den späten 1990er bis in die Nullerjahre sehr divers, ist zuletzt aber von vielen Übernahmen geprägt worden, so dass man von einem konsolidierten Markt sprechen kann (Breeding o. J.).\n\n\n\n\n\n\nInfo\n\n\n\nDie erste Generation der Bibliotheksmanagementsysteme umfasste Grundfunktionen für die Ausleihe wie Verbuchung und Mahnung, für die Erwerbung die Verwaltung von Bestellungen und teilweise auch über Telnet erreichbare Kataloge für die Bibliotheksnutzer*innen. Die zweite BMS-Generation verfügte über erweiterte Funktionalitäten zur Unterstützung der Kernprozesse sowie durch Weboberflächen der Kataloge aus. Die dritte Generation zeichnete sich durch stärkere Modularisierung und mehr Schnittstellen zur Anbindung weiterer Systeme aus.\n\n\nSeit den 2010er-Jahren vermarkten Anbieter eine neue Generation von BMS, die Next-Generation Library Management Systems, die auch Library Services Platforms genannt werden. Diese zeichnen sich durch verschiedene technische und funktionale Neuerungen aus. Die Datenhaltung erfolgt in der Regel cloudbasiert (auch wenn dies bei bei älteren Systemen im Grunde auch schon der Fall war), außerdem werden in der Regel mehr Schnittstellen zur Integration des Systems mit anderen Lösungen angeboten. Funktional wurden die Systeme vor allem um die Möglichkeit der Verwaltung von elektronischen Ressourcen erweitert sowie Statistik- und Reporting-Funktionalitäten verbessert.\nSeit dem Ende der 1990er Jahre spielen auch wieder Lösungen eine Rolle, die nicht kommerziell sind. Diese Open Source-Lösungen haben in der Regel eine große Anwender-Community und lassen einen vielfältigen Markt für Support- und Wartungsdienstleistungen zu.\n\n\n\nAbbildung 6.1: Evolution der Bibliotheksmanagementsysteme (nach Matthews und Block (2020), S. 7)\n\n\n\n\n\n\n\n\nInfo\n\n\n\nNach Matthews und Block (2020) lässt sich die Geschichte der BMS in sechs überlappende Epochen einteilen (siehe Abbildung 6.1):\n\nSystem-Epoche: Erste Schritte in den 1950er bis in die 1970er-Jahre hin zur Entwicklung von Software, z. T sehr experimentell, die die klassischen Geschäftsgänge von Bibliotheken in einem digitalen System abbilden sollen – dadurch prägt sich der Begriff „Bibliothekssystem“. Das Augenmerk bei der Entwicklung liegt besonders auf Nachbildungen des Leihverkehrs unter besonderer Beachtung der Identifikation überfälliger Medien.\nEpoche der Funktionalität: Kommerzielle Bibliothekssoftware-Anbieter beginnen sich zu formieren, die erstmals eine integrierte Lösung der verschiedenen Automationsbereiche (Erwerbung, Katalogisierung, Zeitschriftenakzession, Verbuchung, Leihverkehr usw.) anbieten. Hierdurch entsteht die Bezeichnung „Integriertes Bibliothekssystem“ (IBS), der auf den aus dem US-amerikanischen Raum übernommenen Begriff „Integrated Library System“ (ILS) zurückgeht. In den 1980ern entstehen die ersten Online-Kataloge (OPAC), die die in Bibliotheken traditionellen Zettelkataloge nachbilden.\nNutzer*innen-Fokus-Epoche: Durch die Erkenntnis, dass sich die Gewohnheiten von Bibliotheksnutzer*innen im Zugang zu und Umgang mit Medien u.a. mit dem Aufkommen des WWW in ihrem Alltag zunehmend ändern (z.B. durch die Nutzung von Online-Shopping und Suchmaschinen), rücken die Bedürfnisse der Nutzer*innen immer mehr in den Fokus bei der Entwicklung von Bibliothekssystemen.\nEpoche der Verbreiterung der Informationsressourcen: Der Übergang in eine Phase, bei der Medien nicht mehr erworben, sondern digital lizenziert werden. Entsprechend entwickelt sich das Bedürfnis nach einem Electronic Resource Management (ERM) und neuartige BMS unterfüttern zum Ende der Epoche diesen Wandel mit einer von Medientypen unabhängigen Ressourcenverwaltung.\nDiscovery-System-Epoche: Systeme, die über den lokalen Medienbestand hinaus auch extern lizenzierte Inhalte über eine alleinige Suchplattform zugänglich machen, erfreuen sich zunehmender Beliebtheit bei den BMS-Betreiber*innen. Sie sollen den Nutzer*innen einen deutlichen Mehrwert bieten. Seit den 2010er Jahren sind es überwiegend kommerzielle Verlage, die umfangreiche e-Medien-Pakete oder Indizes von Volltext- und Bibliografie-Datenbank als lizenzierbare Resource Discovery Services anbieten.\nWissensinnovation: Bibliotheken realisieren überwiegend, dass Discovery-Systeme nicht ihre gewünschte Wirkung entfalten und sie sich deutlicher von Plattformen großer Tech-Unternehmen abgrenzen müssen. Wissen soll neu erschlossen werden mit innovativen Technologien wie 3D-Druck, Virtual Reality (VR), Open-Access-Repositorien etc.\n\n\n\n\n\nTabelle 6.1: relevante Software-Produkte (Stand Mitte 2022)\n\n\n\n\n\n\n\n\n\n\nOrganisation\nMarktstatus\nOpen Source\nIndividuelle Entwicklung\n\n\n\n\naDIS/BMS\naStec\nÖBs und WBs vor allem im BSZ\nnein\ndurch aStec\n\n\nAlma\nExLibris\nWBs in Berlin, NRW, Bayerische Staatsbibliothek, Schweiz\nnein\ndurch ExLibris, integrierte Apps in Eigenregie\n\n\nFOLIO\nOpen Library Foundation\nEinführung in WBs\nja\nin Eigenregie oder durch Dienstleister\n\n\nKoha\nKoha Community\nÖBs und Spezialbibliotheken, in Planung im KOBV\nja\nin Eigenregie oder durch Dienstleister\n\n\nLBS\nOCLC\nWBs im GBV und Spezialbibliotheken\nnein\ndurch VZG\n\n\nLIBERO\nLIBERO/Knosys\nÖBs und WBs\nnein\ndurch LIBERO\n\n\n\n\n\nIn Tabelle 6.1 sind die aktuellen BMS mit der derzeit größten Marktreife und -durchdringung im deutschsprachigen Raum (Stand Mitte 2022, Sortierung nach Namen) angegeben. Weitere BMS wie ExLibris Aleph, SISIS Sunrise und allegro werden zwar auch noch an vielen Bibliotheken eingesetzt, aber nicht mehr wesentlich weiterentwickelt. Das Cloud-basierte System WMS von OCLC ist in Deutschland bislang nur vereinzelt im Einsatz. Für BibliothecaPlus ist von OCLC ein Nachfolger angekündigt.\nDarüber hinaus gibt es mehrere kommerzielle Systeme, deren Funktionsumfang auf bestimmte Arten von Bibliotheken zugeschnitten ist, beispielsweise:\n\nPerpustakaan ist in Schulbibliotheken verbreitet und wendet sich auch an nicht-bibliothekarisch vorgebildetes Personal,\nNOS ist in internen Forschungs- und Behörden-Bibliotheken verbreitet,\nQuria von Axiell ist in skandinavischen ÖBs verbreitet und löst im deutschsprachigen Raum das BMS BIBDIA ab.\n\nEine umfangreiche internationale Übersicht von BMS enthält der von Marshall Breeding gepflegte Library Technology Guide. Für den Deutschsprachigen Raum gibt es Übersichten von Verbundzentralen oder Büchereifachstellen, z.B. Kluge (2022) für öffentliche Bibliotheken. Darüber hinaus sind Daten zu BMS systematisch in Wikidata erfasst und können beispielsweise unter https://w.wiki/574K abgefragt werden.\n\n\n\n\n\n\nInfo\n\n\n\nDer IT-Lebenszyklus von BMS ist mit mehr als 20 Jahren im Vergleich zu anderen IT-Systemen eher lang. So wurde beispielsweise FOLIO im Rahmen des Open Library Environment Project bereits 2009 initiiert und wird wahrscheinlich erst im nächsten Jahrzehnt in die Wartungsphase übergehen."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#funktionalitäten-von-bibliotheksmanagementsystemen",
    "href": "bibliotheksmanagementsysteme.html#funktionalitäten-von-bibliotheksmanagementsystemen",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Funktionalitäten von Bibliotheksmanagementsystemen",
    "text": "Funktionalitäten von Bibliotheksmanagementsystemen\nBMS sind in der Regel modular aufgebaut und verfügen mindestens über Module für folgende Funktionen:\n\nErwerbung\nKatalogisierung / Erschließung\nAusleihe\nein Recherche-Modul, das sich vorwiegend an die Bibliotheksnutzer*innen richtet\n\n\nGrundlegende Komponenten\nDie Systeme der 1. und 2. Generation können als sehr ausgereift bezeichnet werden und lassen vielfältige Möglichkeiten zu, bibliothekarische Geschäftsgänge in einem hohen Detaillierungsgrad abzubilden. Nachfolgend werden diese entsprechenden Aufgabenbereiche skizziert.\nErwerbung meint die Beschaffung benötigter Bestände bei Verlagen. Darunter fallen z.B. folgende Aufgabengebiete:\n\nBestellungen\nBudgetverwaltung\nRechnungsverwaltung\nLieferantenverwaltung\nZeitschriften- und Fortsetzungsabonnements\nUnterstützung EDIFACT-Standards\nBuchbinder\n\n\\(\\Rightarrow\\) Siehe auch Prozessabbildung: Erwerbung\nKatalogisierung meint die Erschließung der verwalteten Medien und digitalen Quellen, z.B. anhand\n\nÜbernahme von Fremddaten\nAnbindung an Verbünde\nIntegration digitalisierter Medien\n\n\\(\\Rightarrow\\) Siehe auch Prozessabbildung: Katalogisierung\nAusleihe meint vorwiegend die Verwaltung physischer Medien bzw. Objekte und regelt die Interaktionen mit Nutzer*innen wie z.B.:\n\nAbbildung komplexer Reglements nach Benutzer- und Medientypen, Standorten usw (siehe auch Benutzungsbedingungen)\nAusleihfristen\nVerwaltung von Standorten\nVersand von Benachrichtigungen\nAnbindung an Selbstverbuchungslösungen\nMahngebühren\n\n\\(\\Rightarrow\\) Siehe auch Prozessabbildung: Ausleihe\nDas Recherchemodul stellt die Sicht für die Nutzer*innen auf Bestände der Einrichtung zur Recherche und Kontofunktionen dar:\n\nKatalog (auch OPAC genannt)\nBenutzerkonto\n\n\\(\\Rightarrow\\) Siehe auch Prozessabbildung: Katalog\nDie Next Generation-Systeme zeichnen sich gegenüber den Systemen der 1. und 2. Generation in der Regel durch andere Systemarchitekturen aus. Das heißt, sie verfügen über aktuellere technische Einzelkomponenten und Schnittstellen, auf deren Grundlage auch zahlreiche zusätzliche Funktionalitäten angeboten werden können. Im Einzelnen gibt es folgende Merkmale, die ein Next Generation-System kennzeichnen (Schweitzer 2016):\n\nAngebot als Software as a Service (SaaS)\nMandantenfähigkeit\nInteroperabilität durch offene, standardisierte und dokumentierte Schnittstellen\nVerfügbarkeit von Datenbanken bzw. Knowledge Bases für bibliografische Daten und Lizenzinformationen\noftmals kein fest integrierter Katalog, sondern Schnittstellen zu Discovery-Systemen\nStatistik-Werkzeuge\nErzeugung von Semesterapparaten\nAnlegen von Favoriten-Listen\nAnzeige von Buchcovern\n\n\n\nVergleich mit anderen Managementsystemen\nAufgrund der hohen Kosten für die Einführung oder die Migration eines BMS dürfte sich für viele Entscheider*innen die Frage stellen, ob sich die Investition lohnt bzw. ob sich die Aufgaben auch mit anderen Lösungen erledigen lassen (siehe hierzu Beschaffung und Marktanalyse).\nSysteme zur Automatisierung von Geschäftsprozessen gibt es in verschiedenen Branchen. Eine genauere Betrachtung der Aufgaben, die durch Automatisierung unterstützt werden sollen, kann aufzeigen, ob dafür ein Bibliotheksmanagementsystem oder eine andere Lösung besser geeignet ist.\nDie folgenden Alternativen sind möglicherweise für kleine Einrichtungen relevant, die über sehr überschaubare Bestände verfügen und kaum oder wenig ausleihen:\nErfassung von Medien:\n\nListen in einer Tabellenkalkulation (Excel, LibreOffice, …)\n\nErfassung und Web-Präsentation von Medien:\n\nLibrary Thing for Libraries\nZotero Groups\nStand-Alone-Lösungen für Electronic Resource Management wie Coral\n\nAusleihe\n\nPlugins für Wordpress wie WebLibrarian\n\nErwerbung\n\nFinanzbuchhaltungssysteme wie SAP, HIS-Hochschul-ERP\n\nNutzerdatenverwaltung\n\nIDM-Systeme\n\nBibliotheken mit einem jährlichen Zuwachs von über 500 Medien und verschiedenen Benutzertypen und Ausleihbedingungen ist die Nutzung eines BMS zu empfehlen, da hier eine gewisse Prozesseffizienz einerseits und eine Erschließungs- und Dienstleistungsqualität andererseits erreicht werden kann.\n\n\n\n\n\n\nInfo\n\n\n\nAls gedankliches Experiment ist die Überlegung, auf ein BMS zu verzichten, jedoch gut geeignet, um sich über die Anforderungen klar zu werden. Insbesondere die Rolle des Bibliothekskataloges als Schnittstelle zu den Bibliotheksnutzer*innen kann und sollte kritisch hinterfragt werden. Beispielsweise gab es Überlegungen der Universitätsbibliothek in Utrecht, auf dieses klassische Instrument gänzlich zu verzichten.\n\n\n\n\nIntegration des BMS mit anderen IT-Systemen\nInnerhalb der Bibliothek werden BMS meist zusammen mit anderen Softwaresystemen eingesetzt. Insbesondere sind dies:\n\nSelbstbedienungsautomaten (Ausleihe, Rücknahme, Sortierung von Medien, Bezahlung von Gebühren)\nDokumentenserver, Content Management Systeme und andere Repositorien\nWorkflowsysteme (Digitalisierung von Altbestand; Publikationsunterstützung, …)\n\nWeitere Systeme müssen für eine effektive Arbeit sinnvoll mit dem BMS verbunden werden:\n\nHaushaltssysteme wie SAP, HIS Haushalt-ERP\nIdentitätsmanagementsysteme (Account-Verwaltung)\nLieferantensysteme (bibliographische Daten, Bestell- und Rechnungsdaten)\n\nIm bibliothekarischen Umfeld sind folgende Systeme relevant:\n\nder Verbundkatalog\ndie Zeitschriftendatenbank\ndie elektronische Zeitschriftendatenbank\n\nFür die regionale und überregionale Literaturversorgung (physische, Print-Medien, E-Medien) spielt die Anbindung an folgende Systeme eine wesentliche Rolle\n\nFernleihe\nDokumentenlieferdienste (wie Subito und Fachinformations-Lieferdienste)\n\nDie Anbindung an die entsprechenden Dienste (Zentraler Fernleih-Server, Fernleihdienst, Subito-Server etc.) ist für viele, aber durchaus nicht alle Bibliotheken relevant.\nIm Zusammenhang mit dem Aufbau der Fachinformationsdienste für die spezialisierte Informationsversorgung in Deutschland werden in zunehmendem Maße Fachportale entwickelt. Relevante Katalog-Informationen werden aus möglichst vielen Bibliotheken regelmäßig abgerufen (Harvesting), in ein einheitliches Datenformat übertragen und anschließend als gemeinsamer Index für die übergreifende Recherche in Discovery-Systemen angeboten. Die BMS müssen entsprechend über Standardschnittstellen die relevanten Katalogdaten in einem vereinbarten Datenformat bereitstellen.\n\n\nVerbundkataloge\nIn Deutschland haben sich Katalogverbünde in den 1970er und 1980er Jahren entwickelt. Zunächst haben sich die wissenschaftlichen Bibliotheken meistens auf Bundesland-Ebene für die Rationalisierung der Katalogisierung zu Verbünden zusammengeschlossen. Inzwischen sind in diesen Verbünden auch öffentliche Bibliotheken vertreten. Darüber hinaus gibt es mit WorldCat einen internationalen Verbundkatalog. Die Anbindung an WorldCat geschieht jedoch in der Regel nicht direkt über das lokale BMS sondern über den Bibliotheksverbund.\nTabelle 6.2 gibt eine Übersicht über die deutschsprachigen Bibliotheksverbünde.\n\n\nTabelle 6.2: Bibliotheksverbünde und -kataloge\n\n\n\n\n\n\n\nVerbund\nVerbundkatalog\nSystem\n\n\n\n\nBVB\nB3Kat\nALEPH (Ex Libris)\n\n\nBSZ\nK10plus\nCBS (OCLC)\n\n\nGBV\nK10plus\nCBS (OCLC)\n\n\nhebis\nhebis\nCBS (OCLC)\n\n\nhbz\nhbz\nAleph (Ex Libris)\nAlma-Netzwerkzone (Ex Libris)\n\n\nKOBV\nB3Kat\nAleph (Ex Libris)\n\n\nVÖBB (öffentliche Bibliotheken)\nVÖBB\naDIS/BMS (aStec)\n\n\nÖsterreichischer Bibliothekenverbund\nOBV\nAlma-Netzwerkzone (Ex Libris)\n\n\nSwiss Library Service Platform (SLSP)\nswisscovery\nAlma\n\n\n\n\n\n\nAnbindung an Verbundkataloge/Verbundkatalogisierung\nDie Übernahme von bibliografische Daten oder - bei elektronischen Medien - Paket -bzw. Lizenzinformationen aus anderen Systemen ist für eine Bibliothek unabhängig davon, ob sie in einem Verbund organisiert ist, von Interesse. Eine Anbindung von bibliografischen Datenquellen, z.B. per Z39.50, für die Übernahme der entsprechenden Daten gilt daher als Mindeststandard. In Verbünden organisierte Bibliotheken katalogisieren in der Regel bereits in Verbunddatenbanken und wollen die Katalogisate dann verzögerungsfrei in die lokalen Systeme übernehmen.\nFür Informationen zu elektronischen Medien gibt es neben den Verbunddatenbanken weitere Datenbanken bzw. Knowledge Bases, aus denen Paket- und Lizenzinformationen hervorgehen. Diese sind zum Beispiel\n\ndie Zeitschriftendatenbank (ZDB) als zentrales Nachweissystem für Zeitschriften und Fortsetzungen in deutschen und österreichischen Bibliotheken\ndie GoKB als kooperativ gepflegte Knowledge Base für elektronische Ressourcen\n\n\n\nStatistik und Reporting\nMitunter verfügen BMS über eigene Module für die Erstellung von Statistiken. Folgende Statistiken sind typischerweise erforderlich:\n\nArbeitsstatistiken - Für die tägliche Arbeitsorganisation und die Abrechnung der Arbeitsleistungen gegenüber den Stakeholdern müssen in regel- und unregelmäßigen Abständen Statistiken und Bericht aus dem BMS erstellt werden. Die Inhalte werden von den Stakeholdern bestimmt.\nDeutsche Bibliotheksstatistik - Bibliotheken können sich entscheiden, Daten für die Deutsche Bibliotheksstatistik zu erfassen. Die notwendigen Daten sollten über das BMS ermittelt werden können. Durch die einheitliche Definition der statistischen Kennzahlen ist eine umfassende, vergleichende Auswertung aller Bibliothekssparten (wissenschaftliche, öffentliche, Spezialbibliotheken) möglich.\nSonderstatistiken wie Statistiken der Fachinformationsdienste (FID)\n\nBei den Systemen der 1. und 2. Generation ist es bisweilen nötig zusätzliche Werkzeuge zum Einsatz zu bringen, um alle gewünschten Berichte zu erstellen (z.B. BibControl oder Crystal Reports). Während die integrierten Module vor allem auf die Daten des eigenen Systems fokussiert sind, können externe Werkzeuge auch Fremddaten aufnehmen, zum Beispiel Daten aus Besucherzählern.\n\n\nBibliotheksorganisation\nBei der Implementierung oder Anpassung eines BMS ist die Organisation der Bibliothek, die Gestaltung der Prozesse sowie die räumliche Situation zu berücksichtigen. Handelt es sich zum Beispiel um einen öffentliche oder wissenschaftliche Bibliothek? Ist die Organisation als ein einschichtiges oder zweischichtiges System angelegt? Ist es eine einzelne Bibliothek oder eine Zentralbibliothek mit Zweigstellen?\nAuch die Aufstellung der Medien innerhalb der Gebäude nimmt Einfluss auf die Ablauforganisation und damit die Konfiguration des Systems. Dies lässt sich anhand der folgenden Beispiele darstellen:\n\nBücher können in einer anderen Zweigstellen ausgeliehen werden.\nDie Bibliothek verfügt über einen Magazinbestand, also physische Medien, die für die Nutzer*innen nicht unmittelbar zur Verfügung stehen.\n\nIn beiden Fällen muss auch der Bestellprozess über das System abgebildet werden. Im Magazin bzw. der Zweigstelle sind der Anschluss und die Aufstellung von Druckern für die Erzeugung von Bestellzetteln zu berücksichten. Sind die Medien für die Bibliotheksnutzer*innen direkt zugänglich, entfällt der Bestellschritt und der abzubildende Prozess beginnt mit der Ausleihverbuchung.\nAuch das Rechtemanagement eines BMS ist abhängig von der Größe der Organisation. So sind ggf. verschiedene Berechtigungsstufen für die Bearbeitung von Daten im BMS für die Bibliotheksbeschäftigen einzuführen. Die Berechtigungen bilden die Arbeitsorganisation ab und berechtigen z.B. zum Lesen, Anlegen, Editieren oder Löschen von Ausleihbestellungen, Nutzer*innen- oder Katalogdaten, Erwerbungsunterlagen, Gebühreninformationen u.ä.\n\n\nBenutzungsbedingungen\nDie Benutzungsbedingungen werden durch die Ausleihpolitik der Bibliothek bestimmt. Die Gestaltung der Bedingungen erfolgt sowohl bezogen auf die Medien und die Bibliotheksnutzer*innen. Dabei geht es um die Frage, was von wem ausgeliehen werden darf und, wenn eine Ausleihe möglich ist, wie und für welchen Zeitraum diese erfolgen kann.\nEine Grundlage zur Abbildung der Benutzungsbedingungen ist die Definition von Benutzungsgruppen. Die Benutzungsgruppen werden durch verschiedene Kriterien charakterisiert. Zur Illustration zwei Beispiele:\n\nGruppenbildung Universitätsbibliothek:\n\nintern: Studierende, Lehrende, weitere Universitätsangehörige\nextern: externe Wissenschaftler*innen, interessierte Öffentlichkeit\n\nGruppenbildung öffentlichen Bibliothek: Kinder, Jugendliche, Erwachsene\n\nDie Einteilung von Bibliotheksnutzer*innen in Gruppen dient der einfacheren Zuweisung von Rechten und Ausleihbedingungen, wird aber auch für statistische Zwecke genutzt. Die Ausleihpolitik bestimmt, welche Rechte den verschiedenen Benutzungsgruppen zugewiesen werden. So erfolgt z.B. die Gruppeneinteilung in öffentlichen Bibliotheken i.d.R. nach dem Alter. Einerseits wird damit die Zugänglichkeit der Medien für Kinder und Jugendliche gesteuert. Andererseits dient diese Gruppierung der Einstufung der Gebühren (Kinder und Jugendliche zahlen oft weniger oder keine Gebühren).\nNeben den Gruppen werden Ausleihbedingungen auch auf die Medien bezogen. Zur Illustration:\n\nPräsenzbestände vs. ausleihbare Medien,\nbesonders wertvolle Medien oder\nelektronische Publikationen, die nur unter bestimmten Bedingungen und von bestimmten Benutzergruppen genutzt werden können.\n\nBenutzungsbedingungen werden also sowohl durch die Zugehörigkeit zu einer Benutzungsgruppe als auch durch das Medium selbst bestimmt. Die Beschreibung der Benutzungsbedingungen ist somit eine wesentliche Voraussetzung für die Einrichtung des Ausleihmoduls eines BMS."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#datenverwaltung-in-bms",
    "href": "bibliotheksmanagementsysteme.html#datenverwaltung-in-bms",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Datenverwaltung in BMS",
    "text": "Datenverwaltung in BMS\nEin BMS verwaltet zum einen Daten über die von der Bibliothek bereitgestellten oder vermittelten Ressourcen (vor allem physische und digitale Medien) und zum andern Daten über wesentlichen Arbeitsprozesse (beispielsweise Erwerbung und Ausleihe). Dabei lassen sich grob drei Arten von Daten unterscheiden:\n\nBibliographische Metadaten zur Beschreibung von Ressourcen\nDigitale Inhalte wie Volltexte, Digitalisate und andere digitale Publikationen\nVerwaltungsdaten zur Unterstützung von Workflows\n\nDie Datenhaltung erfolgt in der Regel in relationalen Datenbanken (MySQL, Oracle).\nZur sinnvollen Verarbeitung von Daten im BMS und in Integration mit anderen System müssen Daten bestimmten Datenformaten entsprechen, über Schnittstellen abruf- und ggf. änderbar sein und Mindestanforderungen an die Datenqualität genügen.\n\nBibliographische Metadaten\nBibliographische Metadaten in Form von Titel-, Exemplar- und Normdaten bilden den Kern den klassischen Katalogs. An anderer Stelle tauchen diese Daten beispielsweise als Suchindizes für Discovery-Systeme auf. Das BMS verwaltet diese Daten um Ressourcen Auffindbar und Zugreifbar zu machen. Diese Daten können von verschiedenen Bibliotheken gemeinsam genutzt und in der Regel frei zur Verfügung gestellt werden (siehe Kapitel zu Open Data).\n\n\nDigitale Inhalte\nDies sind letztendlich die Daten die für die Nutzer*innen der Bibliothek vor allem von Interesse sind. Im Falle von Open Access Publikationen bietet das BMS nur einen möglichen Weg zum Zugriff, für erworbene oder lizenzierte Inhalte muss das BMS dagegen unterschiedliche Zugriffsrechte unterstützen.\nDigitale Inhalte werden in der Regel nicht direkt im BMS sondern in eigenen Content Management Systemen (CMS) und Repositorien verwaltet. Ein BMS muss mit diesen Systemen durch Verwendung gemeinsamer Datenformate, Import, Export und Verlinkung zusammenarbeiten können. Der Unterschied zwischen Metadaten und Inhalten ist dabei mitunter fließend und hängt vom Anwendungsfall ab. Reicht es oft Publikationen grob mit Metadaten zu beschreiben, so umfasst in anderen Fällen die Erschließung von Publikationen auch Dokumentstrukturen und inhaltliche Bestandteile wie z.B. einzelne Abbildungen.\n\\(\\Rightarrow\\) Das Kapitel Digitalisierung geht ausführlicher auf digitale Inhalte ein.\n\n\nVerwaltungsdaten\nVerwaltungsdaten dienen der Unterstützung von Arbeitsabläufen innerhalb der Bibliothek (siehe Prozessabbildung). Diese Daten sind zum größten Teil nicht öffentlich und müssen insbesondere im Falle von Daten von Nutzer*innen im Rahmen des Datenschutz vertraulich behandelt werden.\nZur Interoperabilität mit anderen Informationssystemen innerhalb der eigenen oder übergeordneten Einrichtung gibt es in der Regel nur wenig übergreifend etablierte Standards und Schnittstellen, so dass hier oft zusätzliche Anpassungen an das BMS notwendig sind.\n\n\nDatenformate und Schnittstellen\nDa Computer nicht selbständig mitdenken und interpretieren können, müssen Daten nach klar definierten Regeln aufgebaut sein. Diese Regeln sollten möglichst genau dokumentiert sein. Damit verschiedene Systeme Daten austauschen können, sollten möglichst etablierte Standardformate verwendet werden.\nTrotz gemeinsamer Standards ist ein genaues Hinschauen immer erforderlich, da sich die Handhabung gleicher Formate in der Praxis zwischen verschiedenen Systemen und Einrichtungen unterscheidet.\nNeben Standardformaten gibt es speziellere Anwendungsformate. Diese basieren allerdings in der Regel auf allgemeinen Strukturierungssprachen (CSV, XML, JSON oder RDF) die je nach BMS besser oder schlechter unterstützt werden.\n\nBeispiele für bibliographische Standardformate sind MARC21, BIBFRAME und als kleinster gemeinsamer Nenner Dublin Core. Das PICA-Format bzw. darauf aufbauende Formate ist vor allem als Internformat in den Bibliotheksverbünden GBV, BSZ und an der DNB verbeitet.\nVerbreitete Metadaten-Schnittstellen sind Z39.50, SRU und OAI-PMH.\nBeispiele für relevante Formate und Schnittstellen für digitale Inhalte sind PDF, METS/MODS und IIIF.\nBeispiele für relevante Schnittstellen für BMS-Verwaltungsdaten sind LDAP und PAIA.\n\nEine umfassende Übersicht von Datenformaten mit Schwerpunkt auf Formate, die für Bibliotheken relevant sind, bietet die Seite https://format.gbv.de.\n\n\nDatenqualität\nIm Gegensatz zu physischen Dingen ist Daten von außen nicht anzusehen, ob sie unvollständig, veraltet oder aus anderen Gründen fehlerhaft sind. Ohne kontrolliertes Qualitätsmanagement muss davon ausgegangen werden, dass die Qualität von Daten kontinuierlich abnimmt. Zur Ermittlung und Verbesserung der Datenqualität tragen bei:\n\nRichtlinien legen einheitliche Regeln für Daten fest, beispielsweise durch Katalogisierungsregeln wie RDA (Soll-Stand)\nValidierung ermittelt die Übereinstimmung von Daten mit formal definierten Vorgaben (Ist-Stand)\nStatistiken geben quantitative Auskunft, zum Beispiel über die Anzahl erfolgreich importierter oder exportierter Datensätze\n\nNicht zuletzt beeinflussen auch die Möglichkeiten der Ein- und Ausgabe von Daten ihre Qualität, beispielsweise über die Usability der Katalogisierung."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#marktanalyse-und-beschaffung",
    "href": "bibliotheksmanagementsysteme.html#marktanalyse-und-beschaffung",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Marktanalyse und Beschaffung",
    "text": "Marktanalyse und Beschaffung\n\n\n\n\n\n\nInfo\n\n\n\nDer deutschsprachige BMS-Markt 2022 ist überschaubar. Für den Entscheidungsprozess sind daher vor allem auch der Umfang der gewünschten und gewichteten Funktionalitäten, Varianten des Betriebs (gehostet oder lokal) oder auch die Mitgliedschaft in einem Verbund als Kriterien heranzuzuziehen.\n\n\nDie Beschaffung eines BMS ist für eine Bibliothek eine große Herausforderung, nicht nur wegen der zu kalkulierenden Kosten sondern auch wegen des erheblichen Einflusses auf alle bibliothekarischen Arbeitsschritte. Der Aufwand für die Migration von Altdaten, die Revision von Geschäftsgängen und die Schulung von Personal muss bei der Beschaffung berücksichtigt werden. Nicht zuletzt ist die Wahl eines BMS auch eine strategische Entscheidung, da die Möglichkeiten auf zukünftige Anforderungen einzugehen je nach System und eigenen Ressourcen unterschiedlich ausfällt.\nEs kann auch eine ethisch-moralische Entscheidung oder ein Commitment zu einer ökologisch-nachhaltigen Betriebsführung (öffentliche Einrichtungen als Vorzeigecharakter für einen ökologischen Wandel) sein, die Aspekte der nachhaltigen Beschaffung zu berücksichtigen, wie sie sich bei BMS als auch anderen IT-Anwendungen stellen, etwa die Konsequenzen des ökologischen Fußabdrucks der genutzten Infrastruktur (z. B. CO2-Ausstoß des Rechenzentrums).\nAuch aus datenschutzrechtlicher Perspektive gibt es Voraussetzungen zu berücksichtigen, die gegen die Anschaffung bestimmter BMS-Lösungen sprechen (siehe Abschnitt Datenschutz).\nVor diesem Hintergrund ist die Auswahlentscheidung für einzelne Bibliotheken oft ein langwieriger Prozess. Bei Teilnahme an einem Verbund können sich Bibliotheken durch diesen über die BMS, die vom Verbund unterstützt werden, informieren und beraten lassen (siehe Übersicht deutscher Verbundsysteme). Die Beschaffung und Einführung von BMS liegt immer in der Verantwortung der jeweiligen Bibliothek oder der Einrichtung, zu der die Bibliothek gehört.\nDie Gründe für einen Systemwechsel sind primär technischer oder finanzieller Natur. Beispielhaft werden folgend einige Gründe aufgezählt:\n\nDas Altsysteme ist technisch überholt oder wird nicht mehr gewartet.\nEs fehlen Schnittstellen für die Integration des BMS in die lokale Informationsinfrastruktur.\nDie Kosten für den laufenden Betrieb sind zu hoch und sollen mit einem anderen System gesenkt werden.\nEine Funktionserweiterung, z.B. für die Verwaltung von elektronischen Ressourcen, kann an dem bestehenden System nicht mehr vorgenommen werden.\n\n\nEntscheidungsprozess\nEin Entscheidungsprozess umfasst typischerweise folgende Schritte:\n\nWorkflowanalyse: Dokumentation bestehender und zukünftig gewünschter Prozesse, die mit dem BMS abgebildet werden sollen\nAnforderungsanalyse: Zusammenstellung und Priorisierung der gewünschten Funktionalitäten und strategischen Zielen unter Einbeziehung aller Stakeholder\nMarktanalyse: Auswahl der in Frage kommenden Lösungen und Betriebsmodelle\nEvaluation: Vertiefte Beschäftigung mit einer Auswahl von Lösungen durch Ausprobieren von Test-Installationen und Kontakt mit Anwendungsbibliotheken\nAufwandsabschätzung von Migration, Einrichtung und Schulung\nAusschreibung, falls erforderlich\nAuswahlentscheidung\n\n\n\nAuswahlkriterien eines BMS\nEs kann davon ausgegangen werden, dass die aktuell am Markt verfügbaren Systeme die klassischen Geschäftsgänge (siehe Kapitel Prozessabbildung) einer Bibliothek gut abbilden können. Die Anforderungen aus dem Kapitel Nutzer*innenzentrierte Gestaltung gelten grundsätzlich natürlich auch hier.\nDie Betrachtung einzelner Systeme einschließlich der Nutzungsszenarien und Use Cases kann sehr aufwändig werden. Daher empfiehlt es sich, die gewünschten Funktionalitäten zu bestimmen und durch die Stakeholder bewerten zu lassen. Die Bewertung kann beispielsweise in Form einer Matrix geschehen, in der die Funktionalitäten nach ihrer Bedeutung/Wichtigkeit einerseits und den zu erwarteten Aufwänden andererseits eingeordnet werden.\n\n\n\nAbbildung 6.2: Beispiel für eine Matrix zur Einordnung von Funktionalitäten\n\n\nZur Evaluierung der BMS können bestehende Anforderungskataloge für die Evaluierung von BMS herangezogen werden, zum Beispiel der gemeinsam von HBZ und VZG entwickelte Kriterienkatalog. Dieses umfangreiche Dokument zeigt die Anforderungen an alle Komponenten auf Grundlage der Analyse von sehr ausgereiften Prozessen in Altsystemen auf. Es empfiehlt sich, insbesondere diejenigen Funktionalitäten genau zu überprüfen, die strategisch von besonderer Bedeutung sind.\n\n\nMarktanalyse\nDa es sich bei BMS um relativ spezialisierte Software handelt und in den letzten Jahren einige Produkte aufgekauft oder eingestellt wurden, ist der Markt sehr überschaubar (siehe Kapitel aktuell relevanten BMS).\nNeben der Wahl konkreter Produkte gibt es grundsätzlich drei Möglichkeiten:\n\nBeitritt zu einem Bibliotheksverbund und Nutzung eines BMS, das von diesem Verbund unterstützt wird, zu den jeweils gültigen Konditionen\nLizenzierung eines kommerziellen BMS und Einkauf einschlägiger Dienstleistungen für Hosting, Wartung und Support sowie Migration und individuelle Konfiguration\nImplementierung und individuelle Konfiguration eines Open Source-BMS, entweder in Eigenregie oder durch vollständige oder punktuelle Unterstützung von einschlägigen Dienstleistern für Hosting, Wartung und Support sowie Migration und individuelle Konfiguration\n\nDie Vor- und Nachteile im Überblick:\n\n\n\n\n\n\n\n\n\n\nVerbund\nkommerzielles BMS\nOpen Source BMS\n\n\n\n\nVorteile\nregelmäßige Produktentwicklung\ngewisser State-of-the-Art garantiert\nklare Kosten- und Leistungsstruktur\ngroße Anwendungscommunity\nregelmäßige Produktentwicklung\neinheitlicher Leistungsumfang\nklare Verantwortlichkeiten\nniedrige Anschaffungskosten\ngroße Anwendungscommunities\noftmals regelmäßige Produktenwicklung\nviele Dienstleister, die Services rund um Migration, Betrieb und individuelle Anpassung anbieten\noffene Schnittstellen und Formate\n\n\nNachteile\nbegrenzte individuelle Anpassung\nWartezeiten bei individueller Anpassung\neher geringe individuelle Anpassbarkeit\nrelativ hohe und intransparente Preise\nAbhängigkeit bei der Weiterentwicklung\nevtl. Verlust der Datenhoheit\nz.T. proprietäre (herstellerspezifische) Systeme und Schnittstellen\nerfordert eigene IT-Kapazitäten oder Outsourcing\nRisiko der Sicherung von Nachhaltigkeit und Kompatibilität\n\n\n\nVerbünde bieten in der Regel ein oder zwei Lösungen an, die entweder kommerziell oder Open Source sind. Die Mitgliedschaft in Verbünden kann ein kostengünstiger Weg sein, um mit einem BMS und dazugehörigen Dienstleistungen versorgt zu werden. Allerdings steht möglicherweise nicht allen Bibliotheken die Mitgliedschaft in einem Verbund offen oder bedingt andere Nachteile (z.B. den Zwang, an der Fernleihe teilzunehmen und begrenzte Möglichkeiten zur individuellen Anpassung der Software).\nBei kommerzieller Software fallen typischerweise Lizenzkosten an, die sich nach der Größe der Bibliothek oder der übergeordneten Einrichtung richten (z.B. an der Anzahl von Mitarbeitenden, Studierenden oder Einwohner). Dabei werden einmalige Beschaffungs- und jährlichen Wartungskosten unterschieden. Es muß klar vereinbart werden, welche Dienste mit den Wartungskosten (Support, Update auf neue Versionen, …) abgegolten sind.\nDer Betrieb der Lösungen kann von den Anbietern oder anderen Dienstleistern (Verbund, andere kommerzielle Anbieter) übernommen werden (Cloud/Software as a Service), d.h. die Bibliotheken brauchen keine eigenen Server zur Verfügung stellen und administrieren. Eine Installation auf eigenen Servern (On-Premise-Lösung) erfordert hingegen eigenes, ausgebildetes Personal.\nBei Open Source-Lösungen gibt es keine initialen Anschaffungskosten. Bei Verfügbarkeit entsprechender Server-Infrastruktur und erfahrenem Personal kann eine Bibliothek die Software selbst installieren und in Betrieb nehmen oder diese Leistungen von Dienstleistern einkaufen.\nDie initiale Konfiguration sowie die Migration von Daten aus einem Alt-System können ebenso von den Bibliotheken selbst durchgeführt werden oder sind Teil des Kauf-/Wartungsvertrages.\nDie laufende Betreuung des Betriebs von BMS erfordert speziell geschultes und berechtigtes Personal - sogenannte System-Bibliothekar*innen. In wenigen Fällen wird die Systembetreuung an Dienstleister (beim Hoster) übergeben."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#prozessabbildung",
    "href": "bibliotheksmanagementsysteme.html#prozessabbildung",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Prozessabbildung",
    "text": "Prozessabbildung\nFür den Einsatz eines BMS bilden Prozessbeschreibungen bzw. Workflows eine wesentliche Grundlage. Auf der Basis der Abbildung der Kernprozesse wie Erwerbung, Katalogisierung, Ausleihe sowie der Rolle des Systems und anderer Akteure können Anpassungen (leichter) vorgenommen werden.\nZur Modellierung, Dokumentation und Visualisierung von Workflows bietet sich klassischerweise eine Modellierungssprache wie BPMN (Business Process Model and Notation) an. Für diese und verwandte Sprachen existieren umfangreiche Werkzeuge und Toolchains, mit denen einerseits Prozesse erstellt werden können, gleichzeitig aber auch – sollte das nötig sein – die modellierten Prozesse automatisiert werden können. Im Endeffekt bedeutet dies, dass aus dem Prozessmodell Programmcode erzeugt wird.\n\n\n\nBeispiel einer BPMN-Prozessabbildung\n\n\nLässt man die Aspekte der Prozessautomatisierung oder Codegenerierung außer acht, so lässt sich auch eine abgespeckte BPMN-ähnliche Semantik nutzen, um Prozesse zu dokumentieren und zu visualisieren. Andere Alternativen zur Modellierung finden sich in den verschiedenen Diagrammformen der UML (Unified Modelling Language).\nAus heutiger Sicht sollten für die im Folgenden genannten Bereich Prozessbeschreibungen erstellt werden, damit potentielle BMS an Hand dieser geprüft werden können. Hierbei könnten sich Notwendigkeiten für Änderungen in den Prozessabläufen der Bibliothek ergeben, die auf Basis der Beschreibungen genauer adressiert werden können.\n\nNutzer*innen\nAls Nutzer*innen werden in diesem Kapitel diejenigen Menschen bezeichnet, die mit einem BMS interagieren. Man unterscheidet zwischen den Bibliotheksbeschäftigten, die mit dem Modulen Ausleihe, Erwerbung, Katalogisierung, ERM etc. interagieren, und den Bibliotheksnutzer*innen (oft auch als Leser*innen bezeichnet), die mit dem BMS über das Modul OPAC oder nur indirekt über ein Discovery-System oder ein anderes Drittsystem mit dem BMS in Kontakt kommen.\n\n\nUser-Interfaces für verschiedene BMS-Anwender*innen\nDie Bibliotheksbeschäftigten und die Bibliotheksnuter*innen haben verschiedene Sichtweisen auf ein BMS. Bibliotheksbeschäftigte müssen über das User-Interface bei ihrer Arbeit spezifisch durch die Workflows geführt werden. Dabei ist auf eine einheitliche Benutzungsführung und Gestaltung der Oberfläche zu achten.\nFür die Bibliotheksnutzer*innen steht die Information über die Dienste der Bibliothek, deren Bestand und die Nutzung des Bestandes im Vordergrund. Bibliotheksnutzer*innen kommen dabei häufig mit mehreren IT-Systemen in Kontakt (BMS- OPAC-Modul, Web-Server, Discovery-System, …). Daher sollte auch hier auf eine einheitliche Oberfläche der eingesetzten IT-Systeme geachtet werden, auch bezüglich Accounts und Login, zumindest aber auf ein einheitliches Design und eine einheitliche Benutzerführung.\nEs ergeben sich daraus die folgenden Anforderungen\n\nIntuitive Benutzbarkeit\nBarrierearme Gestaltung\nResponsivität\n\nDiese Themen werden auch in den Abschnitten zu rechtlichen Rahmenbedingungen und im Kapitel zu den Anforderungen an Bibliotheks-IT angesprochen.\n\n\nErwerbung\nEin BMS sollte das Bibliothekspersonal bei den folgenden Aufgaben unterstützen:\n\nÜberprüfen von vorhandenen Beständen (Vorakzession)\nAufgabe von Bestellungen bei definierten Lieferanten auf verschiedenen Wegen\nVerwaltung von Lieferantendaten\nAnlegen und Verwalten von Bestellungen von Zeitschriften und Fortsetzungswerken\nÜberwachung von Bestellungen\nAnlegen und Verwalten von Budgets\nAkzessionierung von Medien\nRechnungsverwaltung inkl. Schnittstellen für haushalterische Systeme\nVerwaltung von Bindeaufträgen\nVerwaltung von Nicht-Kauf-Bestellungen\n\nDiese Aufgaben lassen sich mit den am Markt befindlichen Systemen in der Regel gut abbilden. Allerdings werden die meisten Bibliotheken für die Verwaltung von notwendigen Bestellungen von Materialien jenseits des Bibliotheksbestandes (Büromaterial, IT-Ausstattung etc.) zusätzliche haushalterische Systeme einsetzen. Das Erwerbungsmodul ist insofern meist nur eine Komponente im Haushaltswesen.\n\n\nVerwaltung von elektronischen Ressourcen\nFür die Verwaltung elektronischer Ressourcen sollten folgende Aufgaben unterstützt werden:\n\nErfassung von Lizenzinformationen nach unterschiedlichen Erwerbungsmodellen wie Pakete, Allianz- oder Nationallizenzen\nZuordnung von digitalen Inhalten zu Paketen\nVerwaltung von Paketen\nBezug von bibliografischen Daten von Aggregatoren und Verlagen\nUnterstützung der direkten Verlinkung auf Volltexte aus Katalogen und Discovery-Systemen\nAuslieferung von aussagekräftigen Zugangsinformationen in Kataloge und Discovery-Systeme\nUnterstützung bei der Bereitstellung von digitalen Inhalten jenseits von proprietären Apps\n\nDie BMS der 1. und 2. Generation haben erhebliche Defizite bei der Verwaltung von elektronischen Ressourcen. Die Bereitstellung von entsprechenden Funktionalitäten ist daher ein Alleinstellungsmerkmal von BMS der neuen Generation.\nAlternativ können aber auch separate, sogenannte Electronic Resource Management-Tools eingesetzt werden (Coral, GoKB und LAS:eR).\n\n\nKatalogisierung\nBei der Katalogisierung müssen folgende Tätigkeiten unterstützt werden:\nErfassung von unterschiedlichen Medientypen gemäß aktueller Metadaten-Standards\n\nÜbernahme von Katalogdaten aus Bibliotheksverbünden\nMöglichkeit der Integration von Normdaten\nErfassung von lokalen Daten\nKonfigurierbarkeit von Erfassungsmasken\n\n\n\nKatalog\nDer Katalog ist die Sicht für die Bibliotheksnutzer*innen auf die Bestände der Bibliothek. An das Katalogmodul werden folgende Anforderungen gestellt:\n\nWeb-Interface nach aktuellen Standards bezüglich Barrierefreiheit, Responsivität etc.\nAngebot von Möglichkeiten der Suche nach bekannten Titeln\nAngebot von Möglichkeiten der Suche nach Themen\nFilterung von Trefferlisten nach formalen oder inhaltlichen Kriterien bzw. Standorten\nAnzeige von Verfügbarkeitsinformationen\nAnzeige von Neuerwerbungslisten\nKontobezogene Funktionalitäten (Einsicht, Verlängerung, Vormerkung, Bestellungen)\nAnzeige von Neuigkeiten und wichtigen Links auf der Startseite des Katalogs\nAnpassbarkeit der Katalogoberfläche an das Corporate Design (wenigstens Logo und Farbschema)\n\nIn der Geschichte der BMS war das Katalogmodul eher ein Nebenprodukt der Katalogisierungsarbeit. Durch die Veränderungen im Informationsverhalten seit Entwicklung des WWW ist insbesondere auf das Katalogmodul ein besonderer Innovationsdruck entstanden. Auf diesen Druck haben Bibliotheken mit dem Angebot von Discovery-Systemen reagiert, die als alternative Benutzungsschnittstelle zu den klassischen OPACs aufgebaut wurden und neben einem modernen Design auch Suchmaschinen-typische Funktionen wie Facettierung oder Unterstützung bei der Formulierung von Suchbegriffen bieten. Diese Funktionen sind in den BMS der neuen Generation standardmäßig enthalten.\nEs entstanden durch den erwähnten Innovationsdruck verschiedene Konstrukte, die Daten der Bibliothek den Nutzer*innen zur Verfügung zu stellen:\n\nKlassischer Katalog (OPAC) als Bestandteil des BMS\nKatalog als separates Modul (nicht Bestandteil des BMS), selbst entwickelt, zugekauft oder als Open Source\nDiscoverysystem als Bestandteil des BMS: Daten aus dem eigenen Bestand sowie Fremddaten, die als Metadaten zur Verfügung stehen.\nDiscoverysystem als zugekauftes Modul eines anderen Herstellers oder als Eigenbau mit zugekauften Metadaten oder als Open Source mit offenen Daten oder zugekauften Metadaten.\n\nBei Punkt 4 entsteht die Herausforderung, die im BMS gehosteten Informationen, zum Beispiel über den Ausleihstatus/Verfügbarkeit, auch in der Oberfläche des Discovery-Systems aktuell darzustellen.\n\n\nAusleihe\nEin BMS sollte die folgenden Aufgaben der Ausleihe unterstützen:\n\nAnlegen von Benutzergruppen, Standorten, Medienarten\nAbbildung der in den Benutzungsordnungen festgelegten Ausleihbedingungen, z.B. Leihfristen nach Benutzergruppen, Standorten, Medienarten\nVerbuchung von Medien (Ausleihe, Rücknahme)\nKonfiguration von Ausdrucken für Bestellzettel und Vormerkungen\nErmöglichen von Bestellungen und Vormerkungen\nMahnwesen (Fristen, Mahnstufen)\nBenachrichtigungen für Bestellungen, Vormerkungen, Mahnungen, Leihfristerinnerungen\nGebührenverwaltung\nErzeugung von Listen (überfällige Medien, nicht abgeholte Vormerkungen)\nAnbindung an Bezahlsysteme (Kassenautomaten, Online-Bezahlsysteme)\nAnbindung von Verfügbarkeits- und Kontoinformationen an Discovery-Systeme\nAnbindung an Automatisierungslösungen und externe Verbuchungssysteme (etwa mittels RFID)\n\nDie Parametrisierung der Ausleihe ist ein besonders komplexer Bereich der BMS-Installation aufgrund der Vielzahl von zu beachtenden Benutzungsregeln, der Sensibilität der Daten und der besonderen Relevanz eines reibungslosen Betriebs beim Versand von Benachrichtigungen. Ein Beispiel für eine solche Komplexität ist die das Verhalten bei Feiertagen: Hier muss ein Schließtagekalender regelmäßig gepflegt werden, um zu vermeiden, dass Leihfristenden auf Feiertage oder Wochenenden fallen.\n\n\nAutomatisierung und Selbstbedienung\nAls Automatisierung wird die Möglichkeit bezeichnet, die Geschäftsgänge einer Bibliothek mit digitalen Werkzeugen abzubilden und durchführen zu können. Dazu sind Maschinen notwendig, die die entsprechenden Funktionen anbieten. Das schon recht betagte Standardprotokoll für die Kommunikation zwischen BMS und Automat ist SIP2. Dieses Protokoll hat den Nachteil, dass es ohne Verschlüsselung entwickelt wurde und daher - sofern es sich um ein BMS in der Cloud handelt zumindest - über stunnel verschlüsselt getunnelt wird. Moderne BMS unterstützen mittlerweile zusätzlich auch allgemeine Kommunikationsprotokolle, etwa über REST, sodass das Tunneln von Verbindungen nicht mehr nötig ist. Außerdem ist man nicht mehr daran gebunden, dass anzubindende Geräte SIP2 unterstützen, was deutlich mehr Marktalternativen öffnet.\nNachfolgend werden Automaten für die Selbstbedienung im Bereich der Ausleihe dargestellt.\n\nSelbstverbucher / Ausleihautomaten\nSelbstverbucher / Ausleihautomaten bestehen meist aus einer Auflagefläche für die auszuleihenden Medien, einer Schnittstelle für Bibliotheksausweise sowie einem PC, der die Endgeräte verwaltet und mit dem BMS kommuniziert. Bei einer funkgestützten Medienerkennung (RFID) gibt es die Möglichkeit der Stapelverbuchung, es werden also vom Automaten mehrere gestapelte Bücher erkannt und zur Verbuchung angeboten. Bei einer Barcodegestützten Medienerkennung wird jedes Medium einzeln verbucht.\nBibliotheksausweise gibt es in verschiedensten Ausprägungen: Barcode (1D-Code), Funkchip (u.U. proprietär, Bsp.: Intercard), QR-Code (2D-Code). Die 1D- oder 2D-Codes können entweder auf Papier oder in einer App auf dem Smartphone beigebracht werden. Die Schnittstelle im Automaten muss auf die vorhandenen Ausweistypen vorbereitet sein.\nBei Nichtvorhandensein einer separaten Rückgabeanlage kann der Selbstverbucher / Ausleihautomat auch eine Rückgabefunktion anbieten. Zumeist werden die zurückgegebenen Medien unsortiert gesammelt; im Anschluss erfolgt die Sortierung durch das Bibliothekspersonal.\nNach der Rückgabe- oder Ausleihverbuchung muss der Selbstverbucher / Ausleihautomat auch die Buchsicherung (sofern vorhanden) bedienen. Bei der in vielen Bibliotheken auslaufenden EM-Sicherung (elektromagnetisch über einen im Medium eingeklebten magnetisierbaren Metallstreifen) geschieht dies über die Ansteuerung eines Elektromagneten mit hörbarem Feedback an die Nutzer*innen („klack“). Bei RFID-Sicherung wird bei erfolgter Verbuchung ein Sicherungsbit auf dem RFID-Chip verändert. Aufgrund der größeren Geschwindigkeit dieses Vorganges geschieht dies ohne Feedback an die Nutzer*innen.\n\n\nRückgabeautomat / -sortierung\nEin separater Rückgabeautomat hat zum einen den Vorteil, dass die Prozesse Ausleihe und Rückgabe bei starker Nutzung entzerrt werden und zum anderen, dass eine Sortierung der zurückgegebenen Medien möglich ist. Die Medien werden von den Nutzer*innen auf ein Förderband gelegt und eingezogen (außer Reichweite des Nutzer*innen. In dieser Position wird der Barcode auf dem Medium oder der RFID-Chip gelesen. Wird keines der beiden erkannt, wird das Medium wieder zurückgegeben. Bei erfolgreicher Erkennung und Verbuchung im BMS (und anschließender Aktivierung der Buchsicherung) wird im BMS mithilfe der Signatur oder Mediennummer erfragt, wie das Medium sortiert werden soll. In den meisten BMS gibt es dazu Tabellen, die z.B. über die Anfänge von Signaturen oder anderen Kriterien (Bsp: „SN …“ in Wagen 3, „ist vorgemerkt“ in den Wagen x) arbeiten. Steht das Sortierziel fest, wird das Medium über Förderbänder zu dieser Stelle transportiert und abgeworfen. Das Ziel kann ein sog. Tray sein, ein oben offener Korb oder Wagen, oft mit einem gewichtgesteuerten Boden, damit die Medien nicht allzu tief fallen. Alternativ bieten immer mehr Hersteller sog. Ergocarts an, auf die die Medien so geschichtet werden, dass sie am Regal Rückenschonend aus einem Stapel entnommen und einsortiert werden können.\nÜblicherweise gibt es am Rückgabeautomaten keine Authentifizierung.\nEs gibt auch Rückgabeautomaten, die eine erneute Ausleihe des gerade zurückgegebenen Werkes an den/ie gleiche Bibliotheksnutzer/in ermöglichen. Dies ist in den Fällen sinnvoll, wenn die maximale Leihfrist / maximal mögliche Verlängerungen der Leihfrist erreicht ist und den/die Bibliotheksnutzer/in das Buch weiter nutzen möchte und das Medium nicht anderweitig bestellt ist.\n\n\nKassenautomat\nEin Kassenautomat ermöglicht die personalfreie Bezahlung der offenen Gebühren. Auch hier wird erst der Nutzungsausweis eingelesen und nach einer optionalen Passworteingabe die offenen Gebühren angezeigt. Die Gebühren können dann mit Bargeld oder Bargeldlos gezahlt werden. Auf eine Bargeldzahlung wird zunehmend verzichtet, da das Handling von Bargeld aufwändig und teuer ist.\n\n\nFernleihautomat\nAus einem Fernleihautomat können Fernleihen personalfrei an Nutzer*innen ausgegeben werden. Da diese Bücher weder mit dem eigenen System der Bibliothek gesichert noch verbuchbar sind, muss eine separate Verbuchung durchgeführt werden. Die Nutzer*innen bekommen eine Nachricht, dass ihr bestelltes Medium in einem Fach mit der Nummer xy bereit liegt sowie eine PIN zur Öffnung dieses Faches. Sobald das Fach geöffnet wird, wird das Medium auf das Konto des Nutzers/der Nutzerin verbucht. Auch eine Öffnung des Faches mit einem funkgesteuerten Nutzungsausweis statt der PIN ist möglich.\n\n\nSicherungsgates\nSicherungsgates erkennen unverbuchte Medien, die die Bibliothek verlassen. Die dafür übliche Technik war in den letzten Jahrzehnten die EM-Sicherung, also die Erkennung der Magnetisierung von metallischen Streifen, die in die Medien geklebt waren. Mit der Umstellung auf RFID geschieht die Buchsicherung über Funk, ein Sicherungsbit im Speicher der RFID-Chips wird untersucht. Bei EM-Sicherung ist der maximale Abstand zwischen zwei Gates zur halbwegs zuverlässigen Erkennung ca 90 cm und stellen somit eine Einschränkung des Zugangs, z.B. bei der Nutzung mit Rollstühlen, dar. Etwa der gleiche Abstand ist notwendig bei RFID-HF, bei RFID-UHF (Reichweite bis zu 10m) ist ein sehr großer Abstand möglich und somit der Verzicht auf eine Einengung des Ausgangs.\nBei Erkennung eines gesicherten (und nicht entliehenen) Mediums ertönt ein Warnton. Bei manchen Systemen wird das entsprechende Medium mit Titel und Cover auf einem Monitor angezeigt.\nSicherungsgates verhindern nicht Diebstahl, Diebe wählen andere Wege. Sicherungsgates verhindern das versehentliche Verlassen der Bibliothek mit unverbuchten Medien.\n\n\n\nAnbindung von Systemen über Schnittstellen\nEin BMS muss in der Lage sein, mit anderen Systemen automatisiert Daten auszutauschen. Diese Austauschprozesse betreffen folgende Szenarien\n\nBereitstellung von Konto- und Verfügbarkeitsinformationen, z.B. über PAIA und DAIA\nAnbindung an Buchhaltungssysteme wie SAP oder HIS Haushalt-ERO\nAnbindung an Tools für statistische Auswertungen (s.a. Kapitel Statistik)\nBereitstellung von bibliografischen Daten\nRecherche in Fremddatenbeständen, z.B. über Z39.50\nSchnittstellen zu Kataloganreicherungsdiensten (Buchcover)\nSchnittstellen zu IDM-Systemen (s.a. Kapitel IDM)\nSchnittstellen zu einschlägigen Plattformen der jeweiligen Zielgruppen, zum Beispiel Lernmanagementsysteme\n\nDie Systeme der neuen Generation verfügen in der Regel über Schnittstellen, über die sie in die bestehenden Informationsinfrastrukturen, d.h. die umgebenden Systeme, eingebunden werden können.\nEine Schnittstelle (engl. Interface oder manchmal auch API - application programming interface) bildet einen definierten Kommunikationsweg zwischen Verschiedenen Systemen als „Gesprächspartner“. Im bibliothekarischen Universum gibt es für diese Fälle auch schon viele etablierte Austauschformate, etwa SIP2. Ein BMS „von der Stange“ kann im Regelfall die üblichen Austauschformate unterstützen, sodass ein Austausch zwischen den gängigen Systemen einfach möglich ist. Hierzu zählen insbesondere der jeweilige Bibliotheksverbund, etwa zum Austausch von Metadaten oder für das verteilte Lizenzmanagement, aber auch nutzer*innen-nahe Dienstleistungen, wie die Fernleihe.\n\n\nNicht-bibliothekarische Schnittstellen\nEin BMS existiert im Regelfall nicht nur für sich oder nur im Kosmos der eigenen und anderer Bibliotheken, sondern ist auch in die lokalen IT-Strukturen eingebunden.\nEin gutes Beispiel ist der Einsatz eines BMS an einer Hochschule: Im Regelfall sind alle Mitglieder einer Hochschule auch gleichzeitig (potenzielle) Nutzer*innen der Bibliothek. Die Daten der Mitglieder dieser Einrichtung werden an einer zentralen Stelle verwaltet und sollen durch andere Systeme, z.B. im Bibliothekssystem, durch Verknüpfung nachgenutzt werden. Dies ist die Rolle des Identity Managements (IDM).\n\nIdentity Management\nEin IDM (Identity Management System) ist ein System, mit dem die Basisdaten von Personen und Gruppen an zentraler Stelle verwaltet werden könne. Dies sind etwa persönlich Daten, Kontaktdaten und Organisationsstrukturen. Der Gedanke daher ist, dass alle relevanten Informationen nur an einer zentralen Stelle vorgehalten werden, und in anderen Systemen keine Dubletten erzeugt werden, die dann auch noch irgendwie synchronisiert werden müssten. Damit Personen in einem System eindeutig identifiziert werden können, existiert zumeist eine oder mehrere eindeutige IDs, etwa die Matrikelnummer eines Studierenden.\nDas IDM hält im Regelfall mehr Daten über eine/n Nutzer/in bereit, als von den jeweiligen verbundenen Systemen benötigt werden. Beispielsweise könnte in einem IDM vorgehalten werden, dass eine Person Mitarbeiterin einer Hochschule ist, dass sie zu einer gewissen Fakultät der Hochschule gehört und dass sie zu einer bestimmten Arbeitsgruppe gehört. In der Kommunikation des BMS mit dem IDM ist jedoch nur die erste der Informationen relevant, etwa um die Ausleihkonditionen der Person festlegen zu können. Daher wird in der Kommunikation mit einem IDM im Regelfall auch auch gewisser Scope mitgegeben, damit nur die wirklich für das konsumierende System relevanten Informationen mitgegeben werden; Prinzip „Datensparsamkeit“.\nEin IDM kann als Identity Provider zu einem Authentifizierungsdienst werden. Über diesen Dienst kann man dann unter Umständen ein Single Sign On realisieren, bei dem die Daten der Nutzer*innen nicht mehr an den Service oder Content Provider weitergegeben werden sondern nur noch eine Art Ticket, dass eine Erlaubnis regelt. Im Idealfall gilt diese einmalige Anmeldung dann für einige/viele Service-/Contentprovider, so dass der/die Nutzer/in sich nur einmal anmelden muss um viele Dienste zu nutzen.\nAuthentifizierungsprotokolle sind bspw.: Shibboleth / SAML2, OpenID\nSoftwareprodukte für IDM sind: SAP (mit Plugins), Microsoft Active Directory, uvm\n\nSpeicherung von Nutzer*innendenaccounts\nEin Account besteht aus den Kontaktdaten des Menschen sowie Authentifizierungsinformationen. Hier ist Datensparsamkeit nach DSGVO geboten. Für die Speicherung aller personenbezogenen Daten müssen die Notwendigkeiten oder rechtlichen Gründe nachgewiesen werden. Als Beispiel kann die Speicherung des Geburtsdatums angesehen werden. Wird für die Begründung für die Speicherung des Geburtsdatums die Prüfung der Volljährigkeit oder die Befähigung eines Seniorentarifes herangezogen, ist davon auzugehen, dass die Speicherung des Geburtsdatums nicht notwendig ist. Wird zur Begründung eine als notwendig erachtete Adressermittlung bei Behörden angegeben, ist die Speicherung der Geburtsdatum möglich, das eine Adressermittlung (zur Wiederbeschaffung vermisster Exemplare) möglich. Die Speicherung nutzungsbezogener Daten wie Verweise auf die ausgeliehenen Medien, angefallene Gebühren, offene Bestellungen und bestellte Digitalisate muss in der Regel nicht explizit begründet werden.\nSofern die übergreifende Institution über eine Datenbank zur Speicherung der Accounts verfügt (IDM, Identity Management) ist eine Anbindung an diese sinnvoll. Dieses IDM enthält dann allerdings nicht notwendigerweise die externen Nutzer*innen.\nDie technisch einfachste Lösung für Accounts der externen Bibliotheksnutzer*innen ist die Speicherung im IDM der übergeordneten Einrichtung, sofern vorhanden. Komplexer ist die Speicherung in einem separaten System, da dann bei Autorisierung u.U. mehrere Systeme abgefragt werden müssen.\nDatenschutzbezogene Vorgehensweisen auch in Bezug auf personenbezogene und personenbeziehbare Daten von Nutzer*innen finden sich in Abschnitt Datenschutz im Kapitel zum technischen Betrieb eines BMS.\n\n\n\nBezahlsysteme\nOnline-Payment, Kassensysteme/-automaten (siehe auch Kapitel Kassenautomat)\n\n\nE-Rechnung\nE-Rechnungen müssen seit 2020 von Einrichtungen des Bundes, der Länder und Kommunen verarbeitet werden können. Der Umgang mit E-Rechnungen ist sehr unterschiedlich geregelt. Zum Teil nehmen Einrichtungen nur noch an einer zentralen Stelle E-Rechnungen entgegen. In anderen Einrichtungen werden E-Rechnungen dort entgegen genommen, wo die Bestellungen ausgelöst wurden. Es gibt verschiedene Formate in der eine E-Rechnung übermittelt werden kann (PDF, XML oder direkt per EDIFACT).\nElektronische Rechnungen kommen immer dann ins Spiel, wenn Bestellvorgänge von neuen Medien über das BMS abgewickelt werden. In diesem Zusammenhang entstehen Rechnungen von Lieferanten, die von der Bibliothek oder ihrer Organisation zu begleichen sind.\nOhne eine „E-Rechnungs-Workflow“ würde dies bedeuten, dass Rechnungen der Lieferanten bei der Bibliothek eingehen, einem Bestellvorgang zugeordnet werden müssen, von der jeweiligen Rechnungsstelle beglichen und schließlich wieder im BMS „abgehakt“ werden müssen. Diese repetitiven Workflows lassen sich mittlerweile weitgehend automatisieren. Das BMS ist in der Lage elektronisch übermittelte Rechnungsdaten automatisiert den jeweiligen Bestellprozessen zuzuordnen Bei einer gleichzeitigen Anbindung eines elektronischen Rechnungswesens z.B. über SAP können auch die Zahlungsinformationen automatisiert zugeordnet werden und somit ein Bestellvorgang komplett automatisiert abgeschlossen werden.\n\n\nStatistik\nMit dem Begriff „Statistik“ können verschiedene Dinge im Rahmen eines BMS gemeint sein, etwa Betriebsstatistiken, wie die Rechnerauslastung eines Servers, auf dem das BMS betrieben wird. In diesem konkreten Fall ist jedoch mit „Statistik“ gemeint, dass die Nutzungsdaten des BMS in eine Form gebracht werden können, in der Mitarbeiter*innen der Bibliothek Informationen ziehen können, die zur Dokumentation, zum Reporting oder zur weiteren Arbeit benutzt werden können.\nBeispiele für Statistiken sind ganz klassische die Ausleihzahlen einer Bibliothek, ggf. aufgeteilt nach verschiedenen Themen oder Fächern, die den Bedarf der an bestimmten Medien preisgeben. Dies könnte für die Leitung einer Bibliothek relevant sein, oder für das Budgetmanagement der Einrichtung. Ein anderes Beispiel wären detaillierte Ausleih- und Benutzungsstatistiken, sowie konkrete Informationen zum Bestand. Mit einer solchen Datenlage können Fachbibliothekar*innen etwa gezielt Bestandsmanagement betreiben.\nManche LMS haben Statistikfunktionen schon mit dabei. Andere halten ihre Daten in einer Datenbank und diese müssen aktiv exportiert werden. Wieder andere bieten entsprechende Schnittstellen, über die statistische Daten exportiert werden können.\nJe nach Anforderung an den Umfang und an die Arbeit, die mit statistischen Auswertungen erfolgen soll, kann die Entscheidung fallen, die aus dem BMS kommenden Daten einfach nur in eine Tabellenkalkulation zu exportieren, oder eine speziell auf die statistische Datenanalyse zugeschnittene Statistik-Software einzuspielen. Ergo kommen hier Software wie Excel, BibControl oder gar komplexe Statistik-Plattformen wie SPSS in Frage. BMS wie ExLibris Alma bringen hierbei schon eigene Statistik-Module mit, die eine externe Lösung überflüssig machen.\nAlma (und andere BMS) können automatisiert oder manuell COUNTER-Reports für statistische Daten der Nutzung digitaler Medien importieren."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#technischer-betrieb",
    "href": "bibliotheksmanagementsysteme.html#technischer-betrieb",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Technischer Betrieb",
    "text": "Technischer Betrieb\nDer technische Betrieb eines BMS variiert je nach Betriebsmodell (lokale Installation, gehostete Variante oder Cloud-Dienst). Kosten entstehen dabei für Lizenz- und Wartungsverträge sowie für Betriebsressourcen. Für den Betrieb sind weiter das Monitoring sowie die Aspekte der IT-Sicherheit, Backup und Datenschutz zu berücksichtigen.\n\nKosten\nDie Anschaffungskosten eines BMS machen nur einen kleinen Teil aus. Wichtiger ist, sich über folgende Kosten klar zu werden:\n\nPersonalkosten für den laufenden Betrieb\nLizenzkosten und Wartungsverträge der Software\nBetriebsressourcen, wie z.B. Serverraum, Energieverbrauch, Wartung, Backuplösungen\n\nPersonalkosten und Ressourcen richten sich hauptsächlich nach Art der Installation (Lokal, Hosting oder Cloud). Lizenzkosten sind teilweise nach Größe der Einrichtung gestaffelt, d.h. sie richten sich nach Anzahl der verwalteten Medien und/oder Endnutzer*innen.\nInsbesondere der Punkt Personalkosten kann zu einem Engpass bzw. Risiko werden, denn in vielen Fällen zeigt sich, dass einige wenige Personen durch ein BMS gebunden werden und gleichzeitig auch die einzigen sind, die das System in der Tiefe bedienen können. Wirklich kritisch wird es, wenn nur eine einzige Person diese Rolle erfüllt. Je mehr Verantwortung beim Betrieb auf das Personal vor Ort fällt (lokaler Betrieb), desto wichtiger wird dieser Aspekt. Selbst bei der Nutzung eines Cloud-BMS ist davon auszugehen, dass für die fachliche Administration der Software Personal dauerhaft gebunden ist. Bei dieser Betriebsmethode gibt der Anbieter meistens den Updatezeitpunkt vor, insofern müssen unter Umständen Workflows in der Bibliothek aufgrund von Änderungen in der Software durchgeführt werden, ohne dass man die zeitliche Planung dafür in der Hand hat.\nUm Personalengpässe zu vermeiden, ist es sinnvoll, Einführungsprozesse nur in einer Expertengruppe durchzuführen und Verantwortlichkeiten auf mehrere Schultern zu verteilen (Ausfallsicherheit, Urlaubsvertretung usw). Auch die gute Dokumentation teils komplexer Zusammenhänge sollte bedacht werden, damit Fachwissen nicht nur in den Köpfen einiger weniger Mitarbeiter*innen schlummert.\n\n\nInstallation & Updates\nZur Einrichtung eines BMS gehört:\n\nInstallation auf einem Server: erfordert i.d.R. Kenntnisse in Systemtechnik (Hardware, Server, Kommandozeile...). Wenn Hosting durch Drittanbieter geleistet wird (Cloud, Dienstleister wie Verbundzentrale o.A.), verändert sich diese Aufgabe. Sie entfällt, wenn der Hoster spezialisiert auf das Hosting von BMS ist (bspw. Verbundzentrale), sie wird geringer, wenn der Hoster eher allgemein aufgestellt ist.\nKonfiguration/Parametrisierung: Teilweise über Administrator-Oberfläche möglich, teilweise nur über Konfigurationsdateien. Erfordert vor allem Kenntnisse der eigenen IT-Infrastruktur und der verwendeten Schnittstellen und Formate. Die Grenzen zwischen Konfiguration und Programmierung eigener Erweiterungen sind fließend. Zu beachten ist auch die Migration bestehender Daten in das neue System.\n\nNach Einrichtung werden BMS laufend erweitert. Fehler werden behoben und neue Funktionen kommen hinzu. Die Aktualisierung kann je nach Produkt agil in kleinen, häufigen Schritten erfolgen (monatlich, wöchentlich oder häufigere Updates) oder in längeren Zeitabschnitten (oft quartals- oder halbjahres-weise).\n\n\nOpen Source\nWird ein System auf Open-Source-Basis eingesetzt, sollte eine Verständigung darüber erfolgen, ob und unter welchen Bedingungen lokale Anpassungen am System auch der Community zur Verfügung gestellt werden. Hierzu müssen die Lizenzbedingungen des Systems geprüft werden.\n\n\nLaufender Betrieb\nWährend des laufenden Betriebs ist es wichtig, sich über den aktuellen Betriebszustand des Systems ein klares Bild machen zu können. Dieser „Statusbericht“ kann sich über alle Ebenen des Systems ziehen: Wie viel Speicherplatz ist noch frei? Ist das System für alle Nutzer*innen erreichbar? Sind verbundene Systeme verfügbar und betriebsbereit? Je nach Betriebsmodell werden diese Fragestellungen durch klassisches IT-Monitoring abgedeckt, benötigen teilweise aber auch bibliotheksspezifische Lösungen.\n\nMonitoring\nMonitoring-Lösungen für den Betrieb von IT-Infrastrukturen sind beispielsweise Check_MK oder Prometheus. Diese Anwendungen bieten eine kontinuierliche Überwachung von Systemen anhand definierter Metriken und warnen die Administratoren aktiv, wenn definierte Werte bestimmte Grenzen überschreiben.\nDie Nutzung einer Monitoring-Lösung wird umso relevanter, je mehr Betriebsverantwortung für das BMS bei der Einrichtung liegt. Beim Cloud-BMS liegen zwar viele der Verantwortungen beim Betreiber der Software, trotzdem sollte zumindest die reine Verfügbarkeit des Systems auch von der nutzenden Einrichtung überwacht werden.\n\n\nNotfallbetrieb\nBzgl. der Themen Support, Wartung & IT-Sicherheit, als auch Fehlersuche und -vorbeugung, unterscheiden sich die Aufwände für die Einrichtung je nach gewähltem Betriebsmodell erheblich. Jedoch weichen die zu nutzenden Prinzipien bei diesen Themen nicht grundlegend ab zu anderen zu wartenden Systemen in der IT-Welt.\nDazu gehören Maßnahmen zur Aufrechterhaltung des Bibliotheksbetriebs im Notfallbetrieb. Dies kann ein temporärer Offlinebetrieb des Systems sein. In diesem Fall werden die Prozesse mit den Daten abgewickelt, die zum Zeitpunkt des Offline-Gangs im System vorhanden waren. Wenn das System wieder online geht, muss gewährleistet werden, dass Änderungen an den Daten aus der Offlinezeit nachvollzogen werden (Beispiele: Ausleihen, Erwerbungen, Rechnungsbearbeitung, Benutzerdatenänderungen). Im Idealfall erledigt das die genutzte Komponente oder das BMS selbst.\nBei lokalen Installationen sollte man je nach Größe der Einrichtung ebenfalls über ein Spiegelsystem des BMS nachdenken. Dieses wird parallel auf dem aktuellen Stand gehalten und kann einspringen, wenn das laufende BMS ausfällt.\nEs empfiehlt sich in jedem Fall neben dem Einsatz eines Produktivsystems mindestens eine Test-Instanz und ggf. eine oder mehrere Entwicklungs-Instanzen des BMS zu betreiben. So können neue Funktionen schneller umgesetzt werden ohne den laufenden Betrieb durch unerwartete Fehler zu gefährden.\nZu beachten ist weiterhin, die Nutzer*innen des BMS (intern als auch extern) bei Problemen zu informieren. Dabei sind vor allem von Bedeutung, welche Interaktionen nicht mehr möglich sind, ob es alternative Möglichkeiten für die Nutzer*innen gibt und wann das System voraussichtlich wieder zur Verfügung steht.\n\n\n\nIT-Sicherheit\nUm ein BMS vor den zunehmenden Angriffen durch böswillige Akteure (Hacking, Malware, Ransomware) abzusichern, können die folgenden Empfehlungen als Grundlage dienen (Breeding, Marshall 2022):\n\nDie Infrastruktur um das BMS herum sollte durch starke Sicherheitsvorkehrungen getragen werden.\nDie Gefahr kurzfristig entstehender Sicherheitslücken sollte nicht unterschätzt werden.\nCloud-basierte Systeme sollten aktiv überwacht und der Überblick behalten werden.\nAnbieter sollten aufgefordert werden, die Konzepte ihrer Sicherheitsvorkehrungen offenzulegen.\nGerade Administrator*innen sollten ihre Zugänge gesondert absichern.\nEs sollte sichergestellt werden, dass jede Software stets auf dem aktuellen Stand ist, sowohl auf den Arbeitsplatz-PCs als auch den Servern.\n\nAllgemein gilt auch immer der Grundsatz: „Bleiben Sie wachsam, in Bezug auf ungewöhnliche Ereignisse auf Ihren IT-Systemen“.\n\n\nBackup und Rollback\nFür den Fall, dass der Betrieb eines BMS lokal erfolgt, ist es wichtig, dass sich die Einrichtung über Backup und Rollback der Software Gedanken macht. Da dies ein generelles Thema des Betriebs von IT-Systemen ist, wird im Folgenden auf die Spezifika für BMS eingegangen, und Themen wie das Backup von Servern lediglich angerissen.\nFolgende Aspekte sollten im Rahmen von BMS besondere Beachtung finden:\n\nDefinition von Backup-Zyklen: wie oft werden welche Daten in welchem Umfang auf welche Art gesichert? Es können hier durchaus verschiedene „Sicherungsaspekte“ mit unterschiedlichen Zyklen definiert werden.\nDefinition des Umfangs der Sicherung. Sollen die Daten komplett gesichert werden, sollen nur Veränderungen gesichert werden? Wichtig für diese Entscheidung ist die Frage, wie schnell ein System wiederhergestellt werden kann/soll.\nEin off-site-Backup sollte in die Überlegungen einbezogen werden, also ein kompletter Satz einer Sicherung, der außerhalb der Institution gelagert wird. Dabei ist der Datenschutz zu berücksichtigen, u.U. müssen die Sicherungsdaten daher verschlüsselt werden.\nSicherung von Daten, die bei rechtlichen Fragen von Relevanz sein können: Bsp. Rechnungen, Ausleihen, Mahnungen.\n\nGanz allgemein ist die Frage zu klären, wer Verantwortung für die Einrichtung, Durchführung und die regelmäßige Kontrolle der Sicherungen hat. Der letzte Punkt meint hierbei einerseits das Monitoring der erfolgreichen regelmäßigen Ausführung von Sicherungen, aber auch der Test der erstellten Sicherungen, etwa durch periodisches Einspielen auf einer Testinstanz des BMS.\n\n\nZusammenspiel Hard- und Software\nDas BMS steht in der IT-Landschaft einer Bibliothek im Regelfall nicht alleine, sondern kommuniziert mit anderen Hard- und Softwaresystemen. Hierzu gehören beispielhaft (s.a. Kapitel Automatisierung):\n\nLesegeräte: (Barcode-)Scanner und Chip-Lesegeräte für Benutzungsausweise und/oder Medien\nSelbstverbucher für die Ausleihe und/oder Rückgabe\nRückgabeautomaten, die ggf. auch eine automatische Vorsortierung von Medien übernehmen\nSicherungsgates zur Detektion nicht entliehener Medien an Ein- und Ausgängen\nDrucker zur Erstellung von Quittungen, Ausweisen, Labeln, usw.\n\nFür den Fall, dass die externen Systeme nicht lokal an einem Computer angeschlossen sind, sondern über das Netzwerk der Einrichtung angebunden sind, gibt es vielfach etablierte bibliothekarische Schnittstellen (APIs), etwa SIP, oder man setzt auf moderne, allgemeine API-Standards wie REST.\n\n\nDatenschutz, User-Tracking, Analytics\nInnerhalb der EU gilt seit 2018 die Datenschutz-Grundverordnung (DSGVO), nach der personenbezogene Daten grundsätzlich zu schützen sind.\nIm Kontext eines BMS sind die anfallenden personenbezogenen Daten etwa:\n\ndurch Nutzer*innen bei der Anmeldung angegebenen Daten für den Bibliothekszugang\nmit dem Benutzerkonto verbundene Ausleihvorgänge und Mahnhistorien\ndie Protokolle (Logs) über Online-Zugriffe auf das BMS (z.B. IP-Adresse, Seitenaufrufe)\n\nUm den Schutz personenbezogener Daten gewährleisten zu können, gibt es verschiedene Ansätze:\n\nVerschlüsselung: Daten werden auf verschlüsselten Servern gespeichert, ebenso ist die Übertragung Ende-zu-Ende verschlüsselt\nSeparierung: Personendaten werden getrennt von nicht-sensiblen Daten gehalten (siehe IDM)\nPseudonymisierung: Nutzer*innen-Daten werden mit Pseudonymen präpariert, sodass sie nicht mehr oder nur unter großem Aufwand den einzelnen Personen zuzuordnen sind\nAnonymisierung: Daten werden derart verändert, dass sie nicht rückverfolgbar sind (z.B. Maskierung IP-Adressen)\n\nDie Entscheidung zur Verschlüsselung und Separierung von Daten sollte bereits im Vorfeld des Betriebs eines BMS getroffen werden.\nDie Pseudonymisierung und Anonymisierung kann auch im Laufe der Erhebung der personenbezogenen Daten zur Anwendung kommen, sofern bestimmte Daten nicht mehr für einen konkreten Zweck erforderlich sind.\nLeider sind personenbezogene Daten für Bibliotheks-Statistiken oft notwendig (siehe Kosten). In diesem Fall sollten ebenfalls pseudonymisierte oder anonymisierte Datensätze zur Grundlage genommen werden.\nWenn ein BMS durch einen externen Anbieter gehostet wird (siehe Betriebsmodelle für serverbasierte Software), muss Folgendes sichergestellt sein:\n\nDie Verschlüsselung der Datenübertragung (Ende-zu-Ende-Verschlüsselung)\nBetrieb und Steuerung der Server innerhalb der EU (DSGVO)\nDer Ausschluss von User-Tracking durch Ad-Tech (Werbe-Netzwerke)\nDer Abschluss eines Datenverarbeitungsvertrags im Auftrag\n\nIn der Kombination eines IDM mit einem cloudbasierten BMS außerhalb der EU wäre denkbar, die personenbezogene Daten dort in pseudonymisierter Form speichern zu lassen oder Personendaten von nicht sensiblen Daten zu trennen.\nFür alle personenbezogenen und personenbeziehbaren Daten sind Lösch- oder Anonymisierungsfristen festzulegen. Die Anonymisierungsfristen ergeben sich aus den Vorgaben der DSGVO und müssen betrieblichen und rechtlichen Aspekten genügen. So ergeben sich Fristen für die Speicherung von Daten über Gebühren (Entstehung, Bezahlung, ...) aus den Landeshaushaltsordnungen oder anderen für die Einrichtung maßgeblichen Regelungen. Betriebliche Gründe für die Länge von Speicherfristen von personenbezogenen und personenbeziehbaren Daten können sich aus Fristen für Einsprüche ergeben.\nDie über die vergangenen Jahrzehnte geschehenen sukzessiven Aufkäufe kleinerer BMS-Service-Provider durch einige wenige große kommerziellen Bibliotheksdienstleister hat ganze Firmenkonglomerate entstehen lassen, die inzwischen den Bibliotheksmarkt dominieren. Einige von ihnen, die Dienste für wissenschaftliche Bibliotheken anbieten, wandeln sich in den letzten Jahren zu Data-Analytics-Konzernen. In diesem Zuge präparieren sie ihre cloud-basierten BMS-Lösungen mit Trackern, die Verhaltensprofile über die Nutzer*innen erstellen. Durch die ebenfalls seitens der Anbieter gestellten Zugangsauthentifizierungssysteme wird versucht, zusätzlich eine möglichst hohe Personalisierung bei der Erstellung einzelner Profile zu erreichen. Die dabei entstehenden Datenflüsse werden für gewöhnlich nicht transparent gemacht (Siems 2022). Der Einsatz solcher Analytics-Technologien unterminiert die Integrität konventioneller IDM-Systeme und tangiert somit nicht nur datenschutzrechtliche Belange, sondern auch die IT-Sicherheit. Idealerweise sollte bereits vor der Anschaffung einer BMS-Lösung abgeklärt werden, ob solche Analytics-Technologien eingesetzt werden. Im Zweifelsfall sollte immer der*die lokale Datenschutzbeauftragte oder IT-Sicherheitsbeauftragte hinzugezogen werden."
  },
  {
    "objectID": "bibliotheksmanagementsysteme.html#zusammenfassung-und-ausblick",
    "href": "bibliotheksmanagementsysteme.html#zusammenfassung-und-ausblick",
    "title": "Bibliotheksmanagementsysteme",
    "section": "Zusammenfassung und Ausblick",
    "text": "Zusammenfassung und Ausblick\nEin BMS ist im Normalfall kein statisches System - vielmehr muss es aufgrund der sich verändernden Bedürfnisse einer Bibliothek und deren Nutzer*innen stetig angepasst werden.\nDer Import, Export oder auch die Zusammenführung von Daten erfordert klar definierte Metadaten und Schnittstellen für den freien Austausch aus gut nachnutzbaren Quellsystemen. Dies ist vor allem erforderlich bei der aktuell stärkeren Entwicklung hin zu Open Data und öffentlicher Datennutzung. Die Integration und Interaktion mit anderen Informationssystemen nimmt also zu. Vor allem herkömmliche BMS der zweiten Generation kommen hier schnell an ihre Grenzen.\n\n\n\n\nBorgman, Christine L. 1997. „From Acting Locally to Thinking Globally: A Brief History of Library Automation“. The Library Quarterly: Information, Community, Policy 67 (3): 215–49. https://www.jstor.org/stable/40039721.\n\n\nBreeding, Marshall. 2022. „How to Secure Library Systems From Malware, Ransomware, and Other Cyberthreats“. 2022. https://www.infotoday.com/cilmag/jan22/Breeding--How-to-Secure-Library-Systems-From-Malware-Ransomware-and-Other-Cyberthreats.shtml.\n\n\nBreeding, Marshall. o. J. „Library Technology Industry Mergers and Acquisitions. Library Technology Guides“. Zugegriffen 28. April 2022. http://librarytechnology.org/mergers/.\n\n\nKluge, Matthias. 2022. Anbieter von Bibliothekssoftware. Landesfachstelle für das öffentliche Bibliothekswesen. https://www.oebib.de/bau-einrichtung-it/it-und-internet/bibliothekssoftware.\n\n\nMatthews, Joseph R., und Carson Block. 2020. Library information systems. Second edition. Library and information science text series. Santa Barbara, California: Libraries Unlimited.\n\n\nSchweitzer, Roswitha. 2016. „Anforderungen an ein Bibliothekssystem der neuen Generation - der Kriterienkatalog von hbz und VZG“. Köln. https://docplayer.org/61296444-Anforderungen-an-ein-bibliothekssystem-der-neuen-generation.html.\n\n\nSiems, Renke. 2022. „Das Lesen der Anderen: Die Auswirkungen von User Tracking auf Bibliotheken“. o-bib. Das offene Bibliotheksjournal / Herausgeber VDB 9 (1): 1–25. https://doi.org/10.5282/o-bib/5797."
  },
  {
    "objectID": "discovery.html#einleitung",
    "href": "discovery.html#einleitung",
    "title": "Discovery & Retrieval",
    "section": "Einleitung",
    "text": "Einleitung\nAls Discovery-Systeme werden Rechercheplattformen bezeichnet, die möglichst alle Dienste einer Bibliothek über einen einheitlichen Zugang nutzbar machen. Insbesondere beschränken sich die recherchierbaren Medien nicht nur auf den lokalen Bestand. Die Benutzung und der Funktionsumfang orientieren sich dabei an gängigen Suchmaschinen und Verzeichnissen im Web."
  },
  {
    "objectID": "discovery.html#ursprung-und-motivation-von-discovery-systemen",
    "href": "discovery.html#ursprung-und-motivation-von-discovery-systemen",
    "title": "Discovery & Retrieval",
    "section": "Ursprung und Motivation von Discovery-Systemen",
    "text": "Ursprung und Motivation von Discovery-Systemen\nDie Entstehung von Discovery-Systemen zu Beginn der 2000er Jahre hatte mehrere Gründe: Bibliothekarische Recherchesysteme spielten im Informationsverhalten insbesondere von studentischen Nutzer*innen nur noch eine untergeordnete Rolle. Parallel zeichnete sich ab, dass die dritte Generation der Bibliotheksmanagementsysteme bezüglich ihrer OPAC-Module stagnierte, vornehmlich in Bezug auf das Design, aber auch hinsichtlich ihrer Funktionalitäten. Außerdem wurde Suchmaschinen-Technologie als Open Source-Software verfügbar, so dass technisch aufgeschlossene Einrichtungen eigene Experimente mit der Indexierung bibliographischer Daten begannen.\nZum gegenwärtigen Zeitpunkt sind Discovery-Systeme in wissenschaftlichen und zunehmend auch in öffentlichen Bibliotheken verbreitet. Es gibt eine Reihe von Produkten kommerzieller Anbieter*innen und einige Open Source-Projekte. Discovery-Systeme können von Bibliotheken selbst oder durch Hosting-Anbieter wie Verbundzentralen, Hersteller*innen und kommerzielle Dienstleister*innen betrieben werden. Die Hersteller kommerzieller Bibliotheksmanagementsysteme der neueren Generation bieten Discovery-Systeme an, die besonders gut mit dem BMS der gleichen Hersteller*innen zusammenarbeiten.\nWenn Bibliotheken neben dem Bestandskatalog andere Repositorien betreiben (Dokumenten-Server, Digitalisate-Server, Forschungsdaten-Server, …) ist die Einführung eines Discovery-Systems eine Möglichkeit, diese Datenbestände gemeinsam zugänglich zu machen."
  },
  {
    "objectID": "discovery.html#bestandteile-von-discovery-systemen",
    "href": "discovery.html#bestandteile-von-discovery-systemen",
    "title": "Discovery & Retrieval",
    "section": "Bestandteile von Discovery-Systemen",
    "text": "Bestandteile von Discovery-Systemen\n\nKomponenten\nEin Discovery-System umfasst verschiedene Komponenten. Dazu gehören\n\neine Benutzungs- oder Rechercheoberfläche (Frontend),\nder Suchindex (ein oder mehrere Quell-Indizes) sowie die operativen Aspekte\nETL-Prozesse und\ndie Konfiguration der Rechercheoberfläche.\n\nAngebunden ist häufig auch eine Komponente zur Authentifizierung und Autorisierung.\n\nFrontend\nDie Rechercheoberfläche (User Interface) umfasst typischerweise eine Startseite, eine einfache und eine erweiterte Suche, eine Trefferliste mit Facetten sowie eine Detailseite. Mitunter sind auf der Startseite auch thematische Sucheinstiege verfügbar, z.B. ein Browsing über eine Klassifikation oder Sammlungen. Außerdem gibt es meistens einen persönlichen Bereich, in dem auf das eigene Bibliothekskonto im BMS zugegriffen und gespeicherte Suchanfragen und Literaturlisten verwaltet werden können.\nDie Gestaltungsmöglichkeiten für Design und Layout des User Interface reichen von einer einfachen optischen Anpassung bei Schriften, Farben und Logos bis hin zu größeren Veränderungen im Seitenaufbau, je nachdem, welcher Art das eingesetzte System ist (Eigenentwicklung auf Open Source-Basis, gehostetes kommerzielles System o.Ä.).\n\n\nSuchindex\nZentraler Bestandteil eines Discovery-Systems sind auf Grundlage etablierter Suchmaschinentechnologie wie Apache Solr und Elasticsearch entwickelte Suchindizes.\nDer Index eines Discovery-Systems enthält Metadaten und ggf. damit verknüpfte Daten wie Volltexte, Inhaltsverzeichnisse und Übersetzungen. Im Suchindex kommen also Daten unterschiedlicher Art und Herkunft zusammen. Die Daten können in einzelnen Kollektionen aufbereitet sein, z.B. nach Bestandsdaten von (Teil-)Bibliotheken oder Verbünden, Daten einzelner Verlage, Metadaten aus Repositorien etc. Es besteht die Möglichkeit, den Suchraum des Discovery-Systems individuell zu konfigurieren. Der Aufbau eines Index in Eigenregie ist bei entsprechenden Prozesskenntnissen und personellen Kapazitäten möglich und schafft Freiheiten zur Berücksichtigung eigener Datenkollektionen.\nEinige Discovery-Systeme können Suchanfragen gleichzeitig an mehrere Suchindizes senden und die Treffer aus den unterschiedlichen Suchindizes in einer Gesamtliste zusammenführen. Dies setzt allerdings eine Koordination der genutzten Suchindizes voraus. Dieser Aufbau ermöglicht es den Bibliotheken auch, verschiedene Datenquellen in ihrem Discovery-System gemeinsam zugänglich zu machen. Teils werden die Quellen selbst ausgewertet (z.B. Harvesting der Daten des eigenen Katalogs, relevanter Repositorien, …), teils werden dafür andere freie oder kommerzielle Suchindizes (K10plus-Zentral, Gemeinsamer Verbünde Index, EBSCO-Discovery-Index, ExLibris Central Discovery Index,…) genutzt.\nDie Daten, die in Suchindizes aufgenommen werden sollen, werden im Rahmen eines ETL-Prozess aus verschiedenen Datenquellen (Kataloge/BMS, Repositorien, bibliographische Fachdatenbanken, …) gesammelt, konvertiert und dann in den Suchindex geladen. Für jede Quelle muss dieser Prozess entsprechend eingerichtet und für Aktualisierungen regelmäßig ausgeführt werden.\nBei den ETL-Prozessen werden die Daten aus den verschiedenen Datenquellen transformiert. Dabei werden z.B. die MARC-Struktur mit Feldern, Indikatoren und Unterfeldern in eine einfachere Feldstruktur überführt. Die Daten werden entsprechend den verschiedenen Such- und Navigationsbedürfnissen in unterschiedliche Indexfelder überführt. Ein Datum (z.B. Name des*der Autor*in) kann für verschiedene Suchtypen unterschiedlich aufbereitet und mehrfach im Index gespeichert werden. Bei der Aufbereitung werden die Daten analysiert und etablierte Verfahren zur Relevanzberechnung für die Sortierung innerhalb der Trefferliste eingesetzt.\nFür die Bildung von Facetten aus den Einträgen der Trefferliste werden spezielle Daten ermittelt. Diese Facetten-Daten sind technisch gesehen Suchbegriffe und dienen der nachträglichen Verfeinerung der Trefferliste. Beispiele für Facetten, die zur Einschränkung genutzt werden, sind Namen von Autor*innen, Schlagwörter, Medienarten, Standorte physischer Medien oder auch Kennzeichnung von Open Access-Material und Vieles mehr).\n\n\n\nFunktionen\nEin Discovery-System ist mehr als ein reines Nachweissystem. Der Funktionsumfang umfasst daher auch mehr als die reine Recherche. Der Anspruch an ein Discovery-System, alle Informationen zu Medien an einer Stelle zu bündeln, sollte prinzipiell auch alle Dienstleistungen zu diesen Medien umfassen. Daher sollten auch Informationen zur Bereitstellung von Literatur enthalten, weitere Dienste integriert und eine Personalisierung möglich sein.\n\nRecherche\nHauptfunktionen des Discovery-Systems sind die Recherche, die Anzeige von Metadaten und die Hinführung zur Nutzung der Medien. Im Einzelnen geht es um folgende Punkte:\n\neinfache Suche ohne Spezifizierung eines Suchfeldes\nSuche in Feldern der Metadaten (Titel, ISBN, Schlagworte)\nerweiterte Suche mit Möglichkeiten der Verknüpfung von Suchen in verschiedenen Feldern\nNavigation in Trefferlisten über Facetten und Sortierung\nDetailanzeige einzelner Treffer\nExport von Literaturangaben\n\nDie Suche in Discovery-Systemen nutzt in der Regel verschiedene Funktionen der Suchmaschinentechnologie, um einen eingegebenen Suchbegriff gegen den Index abzuprüfen. Daher liefern Discovery-Systeme mit dem Suchparadigma „beste Treffer“ statt „exakte Treffer“ mehr Treffer als Bibliothekskataloge (Steilen 2012). Sie nutzen außerdem Algorithmen für die Relevanzsortierung (Ranking), um die Trefferlisten möglichst nutzungsorientiert aufzubereiten. Die Sortierungsalgorithmen sorgen bei Übereinstimmungen von Suchbegriff und Indexeintrag in definierten Feldern (Titel, Schlagwort, …) für eine Bevorzugung. Anders als bei Web-Suchmaschinen gehen Popularitätsdaten wie die Anzahl von Ausleihen, Aufrufen und Zitationen bislang nicht in das Ranking ein.\nZu den Funktionalitäten für die Suchunterstützung gehören auch die Autovervollständigung sowie die Vorschlagsfunktion von Suchbegriffen. In beiden Fällen wird der Suchindex in Echtzeit geprüft. Es gehört zu den zentralen Zielen von Discovery-Systemen, Null-Treffer-Meldungen zu vermeiden.\nFacetten sind ebenfalls eine für Suchmaschinen typische Funktion und dienen der Eingrenzung von Treffermengen. Hierfür werden einzelne Metadatenfelder wie Schlagwörter, Namen von Verfasser*innen oder Dokumenttypen in Bezug auf eine Suchanfrage ausgewertet und nach Vorkommenshäufigkeit sortiert. Den Facetten wird eine wichtige Rolle beim entdeckenden Suchen zugesprochen. Zur Präsentation der Facetten in der Rechercheoberfläche gibt es verschiedene Möglichkeiten (siehe Abbildung 7.1). Die Auswahl der angebotenen Facetten muss jedoch gut vorbereitet werden. Fehlen die entsprechenden Metadaten bei bestimmten Titeln, können durch Facettierung auch Treffer verloren gehen.\nDie Weiterverwendung von Literaturangaben wird durch verschiedene Exportmöglichkeiten unterstützt. In der Regel lassen sich Angaben per Mail verschicken, ausdrucken oder in unterschiedlichen Formaten und Zitierstilen herunterladen.\n\n\n\nAbbildung 7.1: Beispiel eines Rechercheergebnis in einem Discovery-Interface (Quelle)\n\n\n\n\nBereitstellungsdienste\nDie Evaluationen früher Discovery-Systeme haben bereits gezeigt, dass Informationen darüber, ob und wie ein gefundenes Medium zugänglich ist, von zentraler Bedeutung sind. Diese Bereitstellungsdienste, auch Delivery-Funktionen genannt, umfassen für physische und digitale Medien jeweils unterschiedliche Aspekte.\nBereitstellungsdienste für physische Medien:\n\nNachweise von Standorten, Ausleihbarkeit und aktuellem Ausleihstatus\nVerlinkung zu Verbundkatalogen mit Fernleihmöglichkeiten\nVerlinkung zu Fernleihe und Dokumentlieferdiensten\nMöglichkeit zur Anfrage nach einer Digitalisierung oder Bereitstellung in einem Semesterapparat\nMöglichkeit zur Abgabe eines Anschaffungsvorschlags\n\nBereitstellungsdienste für digitale Medien:\n\nidealerweise eine auf das jeweilige Nutzungsszenario angepasste Zugangs-URL\nweitere Zugangs-URLs\nHinweise zur Nutzung elektronischer Medien, z.B. zur Zugänglichkeit über VPN, notwendigen Readern, DRM etc.\n\nDie Verfügbarkeit und Entleihbarkeit von physischen Medien, die der Bibliothek gehören, werden über eine sogenannte Verfügbarkeitsrecherche, die das Discovery-System im Hintergrund ausführt, ermittelt und angezeigt. Diese Abfragen werden mittels Schnittstellen zu den Ausleihmodulen der Bibliotheksmanagementsysteme durchgeführt. Diese Schnittstellen können proprietär oder offen sein. Beispiele für Hersteller-unabhängige Schnittstellen sind die Patrons Account Information API (PAIA) als offene Schnittstelle und das Session Initiation Protocol (SIP2) als intern genutzter Standard oder das NISO Circulation Interchange Protocol (NCIP). Verschiedene Discovery-Systeme unterstützen diese oder andere Schnittstellen zum Ausleihsystem in Form von sogenannten Treibern – beispielsweise unterstützt VuFind die Anbindung an FOLIO durch einen eigenen FOLIO-Treiber.\nBei den digitalen Medien ist die größte Herausforderung, den jeweils besten von in der Regel mehreren Zugangslinks für ein Medium zu identifizieren und zur Anzeige zu bringen. Zur Ermittlung des besten Zugangslinks sind in der Regel mehrere Prüfschritte erforderlich. Idealerweise sind solche Prüfschritte konfigurierbar, allerdings ist diese Funktion oftmals kein integraler Bestandteil von Discovery-Systemen, sondern ein eigener Dienst. Ein Beispiel für einen solchen separaten Dienst ist der Webdienst DAIA+ (Keßler 2018). Eine andere Möglichkeit ist der Einsatz sogenannter Link Resolver. Beim Link Resolving wird über die Metadaten ein Hyperlink zu Diensten der Bibliothek ermittelt. Es wird vorrangig bei der Ermittlung von Diensten für Metadaten zu solchen Medien genutzt, die nicht aus dem BMS der Bibliothek und E-Ressourcen stammen. Ein Verfahren für das Link-Resolving ist die Open-URL (NISO-Standard Z39.88).\n\n\n\nAnreicherungsdienste\nDie Ergänzung von bibliotheksseitig erstellten Metadaten mit weiteren Informationen gibt es bereits in den klassischen OPACs. Beispiele sind gescannte Inhaltsverzeichnisse, Links auf Wikipedia-Artikel oder die Integration von Buchcovern.\nZu den am häufigsten genutzten Anreicherungsdiensten gehören:\n\nCover-Anzeigen\nkontextabhängige Infoboxen mit Informationen aus Nachschlagewerken, z.B. Autor*innenenportraits z.B. via Wikidata und GND, Informationen aus Nachschlagewerken wie Munzinger\nEmpfehlungsdienste mit Hinweisen auf Literatur zum selben Thema (z.B. BibTip, bX)\nVisualisierungen von Buchstandorten über Gebäudeinformationssysteme (z.B. Mapongo, V:Scout)\nIntegration mit weiteren Diensten, z.B. der Leseförderungs-App Antolin\n\nGrundsätzlich erlaubt die Systemarchitektur von Discovery-Systemen die Integration von diesen und anderen Diensten über einschlägige Schnittstellen, so dass sich über die gelisteten Dienste noch zahlreiche weitere Möglichkeiten ergeben.\n\nPersonalisierung\nDiscovery-Systeme erlauben in der Regel eine Anmeldung in einem persönlichen Bereich, der folgende Funktionalitäten umfassen kann:\n\nEinsicht in das Bibliothekskonto einschließlich der Möglichkeit zum Vormerken und Verlängern\nSpeicherung von Suchanfragen\nSpeicherung von Literaturlisten\nAlerting-Dienste\n\nLiteraturlisten können alternativ dazu auch sitzungsbasiert gespeichert werden. Dauerhaft gespeicherte Listen lassen sich auch veröffentlichen und damit allgemein zugänglich machen, was auch die Präsentation von Auswahllisten oder Semesterapparaten erlaubt.\nHäufig können auch Suchanfragen gespeichert werden. Die Einrichtung von Alerting-Diensten hilft den Nutzer*innen, sich mit wenig Aufwand über neue Titel informieren zu lassen. Alerting-Dienste beinhalten das regelmäßige (automatisierte) Absetzen einer Suchanfrage und das Versenden von Information, wenn die Suchanfrage veränderte Trefferlisten (in der Regel: neue Titel) liefert.\n\n\nThematische Sucheinstiege\nWie beschrieben bieten Trefferlisten mit Facetten und Empfehlungen zwar durchaus auch die Möglichkeit, sich eine Treffermenge zu erschließen. Allerdings fehlt Discovery-Systemen genau wie OPACs häufig die Möglichkeit, eine systematische Suche durchzuführen. Teilweise wird ein Browsing durch die klassifikatorische Inhaltserschließung angeboten, jedoch fehlen vielen Datensätzen entsprechende Daten und das Browsing bezieht sich jeweils nur auf Teilmenge des Suchraums.\nAus diesem Grund werden derzeit verschiedene Ansätze erprobt, um eine thematische Suche zu ermöglichen. Hierzu zählen u.a. folgende Projekte und Dienste:\n\nein Nachbau der Browsing-Funktion an physischen Bücherregalen, z. B. bei dem kommerziellen Dienst Blended Shelf\ndie Nutzung von Normdaten zur Erstellung von Übersichtsseiten, z. B. im Katalog des Deutschen Literaturarchivs Marbach\ndie Visualisierung von Treffermengen und den darin enthaltenen Zusammenhängen, wie zum Beispiel bei Open Knowledge Maps, in einer prototypischen Installation der SLUB Dresden oder mit dem kommerziellen Dienst Yewno.\n\nDiese Projekte und Dienste sind jedoch entweder noch relativ neu oder wenig verbreitet und nicht oder nur mit Aufwänden nachnutzbar. Im Rahmen einer strategischen Planung für den Einsatz eines Discovery-Systems muss daher abgewogen werden, ob und wie ein thematischer Sucheinstieg umgesetzt werden soll, zumal für eine Darstellung im Sinne einer optimalen User Experience jeweils auch erhebliche Design-Aufwände entstehen."
  },
  {
    "objectID": "discovery.html#aufbau-und-betrieb-eines-discovery-systems",
    "href": "discovery.html#aufbau-und-betrieb-eines-discovery-systems",
    "title": "Discovery & Retrieval",
    "section": "Aufbau und Betrieb eines Discovery-Systems",
    "text": "Aufbau und Betrieb eines Discovery-Systems\n\nBetriebsmodelle\nDer Betrieb eines Discovery-Systems stellt vergleichbare Anforderungen und unterliegt ähnlichen Rahmenbedingungen wie beim Betrieb eines Bibliotheksmanagementsystems.\nIm Inhouse-Betrieb werden alle Komponenten selbst durch die Bibliothek betrieben und damit sind hier die weitestgehenden Anpassungen möglich. Dies wird meist nur bei kleinen oder sehr speziellen Datenbeständen (z. B. durch die Fachinformationsdienste) oder durch sehr große Einrichtungen gemacht. Oft trifft man auch hybride Lösungen, in denen neben einem vergleichsweise kleinen eigenen Index ein kommerzieller oder nicht-kommerzieller Index genutzt wird.\nIn einem Hosting-Betrieb wird die gesamte Infrastruktur durch eine*n Dienstleisterbereitgestellt. Dabei erfolgt die Indexierung in der Regel durch einheitliche Indexierungsverfahren, die von allen teilnehmenden Bibliotheken gemeinsam genutzt werden. Bei diesen Lösungen werden alle Daten in einen einheitlich aufgebauten, in einer Cloud gehosteten Index eingespielt, die Frontends sind nur eingeschränkt individualisierbar und lassen sich ausschließlich durch Konfigurationen parametrisieren. Zusatzfunktionen lassen sich über Schnittstellen anbinden. Wesentlicher Vorteil dieser Systeme ist ein vergleichsweise geringer Wartungsaufwand, ihre gute Skalierbarkeit und durch standardisierte Workflows und ihre hohe Betriebssicherheit. Als Hoster*innen von Discovery-Systemen treten Bibliotheken, Verbünde und kommerzielle Anbieter auf.\nEin Spezialfall des Hostings ist die Nutzung von Cloud-Services externer Anbieter*innen für den Betrieb von BMS und Discovery-Systemen. Mehrere Hersteller*innen von BMS und Discovery-Systemen sind gleichzeitig Betreiber*innen von solchen Cloud-Lösungen. In diesen Fällen wird die Software (BMS, Discovery-System) nicht mehr lizenziert, sondern über eine jährliche Pauschale Nutzung, Update und Betrieb des jeweiligen Software-Systems abgegolten.\nBeim Hosting oder bei der Nutzung von Software, die in der Cloud betrieben wird, spricht man von einer „Datenverarbeitung im Auftrag“. Die Verantwortung für Datenschutz und Datensicherheit bleibt bei der Bibliothek als Auftraggeberin.\n\n\nMarktsituation\nDie ersten Discovery-Systeme haben Bibliotheken selbst entwickelt, im deutschsprachigen Raum z.B. die E-LIB an der Staats- und Universitätsbibliothek Bremen oder das beluga-System an der Staats- und Universitätsbibliothek Hamburg. Seit Ende der 00er Jahre gibt es auch kommerzielle Systeme am Markt, entweder als Teil von Bibliotheksmanagementsystemen der neuesten Generation oder auch als individuell lizenzierbare Systeme. Die Open Source-Lösung VuFind ermöglicht es, verschiedene Suchindizes unter einer Oberfläche nutzbar zu machen, so dass es eine relativ große Vielfalt von Nutzungsszenarien gibt.\n\nKommerzielle Komplettsysteme\nIm Wesentlichen gibt es zwei vergleichbare Anbieter*innen von Komplettsystemen für Discovery-Systeme\n\nExLibris mit Primo und Summon\nEBSCO mit Ebsco Discovery-Service\n\nDiese Systeme bieten eine fertige Lösung, in die lokale Bestandsdaten und weitere lokale Metadaten integriert werden können. Es fallen jährliche Lizenzgebühren sowie einmalige Implementierungskosten an. Beide genannten Systeme sind weit verbreitet. Diese Systeme sind ausschließlich über die Cloud der jeweiligen Hersteller*innen nutzbar. Diese sorgen für eine hohe Verfügbarkeit und regelmäßige Softwarepflege. Individuell zu prüfen sind vor einem Einsatz folgende Fragen:\n\nEinbindung von Verfügbarkeitsinformationen\nDatenschutzrechtliche Fragen (Ort des Hostings, Verfahrensbeschreibungen)\nDatenhoheit\n\nDie Indizes dieser Systeme können separat lizenziert und beispielsweise an VuFind-Systeme angebunden werden.\nEin weiteres kommerzielles Discovery-System ist WorldCat Discovery, das allerdings die Nutzung von WorldCat als Suchindex voraussetzt.\n\n\nOpen Source-Systeme\nUnter den von Bibliotheken selbst entwickelten Discovery-Systemen sind international VuFind und Blacklight am weitesten verbreitet.\nVuFind lässt sich an verschiedene kommerzielle und frei verfügbare Komponenten wie Indizes und Bibliotheksmanagementsysteme anbinden. In den deutschsprachigen Ländern besteht eine lebendige Anwender*innengemeinschaft, die sich regelmäßig trifft. Mit Qcovery und finc gibt es zwei Sub-Communities für wissenschaftliche Bibliotheken, die sich die Aufgaben der Pflege und Weiterentwicklung der Software unter sich aufteilen. Die Software basiert auf PHP.\nBlacklight ist hauptsächlich im angloamerikanischen Raum verbreitet, aber auch bei Europeana Einsatz. Die Software basiert auf Ruby on Rails.\nDas von der VZG entwickelte System Lukida spielt vor allem im Rahmen des Index K10plus-Zentral eine Rolle und wird primär als SaaS angeboten.\n\n\nIndizes\nNeben den kommerziellen Anbieter*innen bieten im Bereich wissenschaftlicher Bibliotheken einige Verbundzentralen auf Suchmaschinen-Technologie basierende Indizes an, teilweise für die teilnehmenden Bibliotheken, teilweise auch darüber hinaus für die nicht-kommerzielle Nutzung. Diese frei verfügbaren Indizes sind für Bibliotheken, die ihre Bestandsdaten an einen Verbund liefern, eine hervorragende Möglichkeit, um relativ kostengünstig an ein Discovery-System zu kommen, da die Erstellung eines eigenen Index mit hohen Investitionen verbunden ist. Metadaten-Kollektionen enthalten der ALBERT-Index des Kooperativen Bibliotheksverbundes Berlin-Brandenburg sowie der Gemeinsame Verbündeindex für Bestandsdaten aus allen wissenschaftlichen sowie vielen Spezial- und öffentlichen Bibliotheken.\n\n\n\nAuswahl- und Entscheidungsprozesse\nSofern ein Discovery-System nicht Teil des BMS ist, ist die Einführung immer mit beträchtlichen Aufwänden verbunden, die aus initialen Kosten für die Implementierung und laufenden Kosten für die Pflege bestehen. Diese Kosten fallen unabhängig davon an, ob es sich um ein kommerzielles oder ein Open Source-System handelt. Sie richten sich nach unterschiedlichen Kriterien und dürften im Bereich der initialen Kosten im höheren vierstelligen Bereich liegen. Grundsätzlich sind die Entscheidungsprozesse bei Auswahlentscheidungen mit denen für ein Bibliotheksmanagement-System vergleichbar (vgl. Abschnitt Marktanalyse und Beschaffung).\nAllerdings müssen die strategischen Vorteile eines Discovery-Systems sehr deutlich und auf den lokalen Bedarf hin herausgearbeitet werden. Es hat sich als hilfreich erwiesen, dass Bibliotheken klar definieren, an welche Zielgruppen sich ein Discovery-System richtet und welche Aufgaben es erfüllen soll. So könnte man beispielsweise argumentieren, dass eine Suche nach Signaturen, die aufgrund der häufigen Komplexität der entsprechenden Systeme in der Regel recht aufwändig zu implementieren ist, in einem Discovery-System nicht nötig ist, weil diese Suche ohnehin hauptsächlich vom Bibliothekspersonal durchgeführt wird. Das Bibliothekspersonal kann diese Suchen im BMS durchführen. Es sollte auch geklärt werden, ob der klassische OPAC nach Einführung eines Discovery-Systems überhaupt weiter angeboten werden soll.\nAuch der Zuschnitt der Suchräume sollte genau bedacht werden, vor allem, wenn über lokale Bestandsdaten hinaus eigene Metadatenkollektionen (z.B. aus institutionellen Repositorien) integriert und durch eigene Suchfilter angesprochen werden sollen. Generell kann davon ausgegangen werden, dass auf die initiale Implementierung eines Discovery-Systems eine längere, oft mehrjährige Phase der Optimierung folgt, die idealerweise konsequent auf die Usability und User Experience der Hauptzielgruppen ausgerichtet ist (vgl. Kapitel Anforderungen an die IT-Entwicklung).\nDie grundsätzliche Entscheidung für ein Discovery-System beinhaltet auch einen Wechsel der Suchparadigmen. Die Einführung eines Discovery-Systems kann nur dann sinnvoll erfolgen, wenn die Abkehr der Dualität von Bestandsverzeichnis und Bibliographie sowie den traditionellen Suchparadigmen strategisch erwünscht ist und von entsprechenden Schulungen für das Bibliothekspersonal begleitet wird.\nWenn ein Discovery-System im Hosting genutzt werden soll, relativieren sich die oben gemachten Aussagen zur Flexibilität, die Open Source-Systeme bieten, da die Hoster*innen in diesem Fall die Möglichkeiten festlegen, die durch die Bibliotheken genutzt werden können. Ebenso verschieben sich die gemachten Aussagen zur Verantwortung für Betriebssicherheit und Verfügbarkeit.\n\n\nMonitoring und Weiterentwicklung\nWie jedes IT-System brauchen auch Discovery-Systeme kontinuierliches technisches Monitoring (vgl. Kapitel Management von IT-Diensten), aber auch konzeptionelle Betreuung. Anders als der klassische Bibliothekskatalog sind Discovery-Systeme angetreten, um sich konsequent nach dem Informationsverhalten der Nutzer*innen zu richten. Daraus ergibt sich, dass sowohl die Implementierung als auch die weitere Entwicklung möglichst kleinschrittig und unter Einbeziehung von Analysen der Nutzung erfolgen sollten. Neben den klassischen Methoden der Usability-Forschung (siehe Kapitel Wie beziehen wir unsere Nutzer*innen ein?) bietet sich als niedrigschwellige Methode vor allem die Analyse von Logfiles an. Mit der Software Matomo kann, auch unter Berücksichtigung von datenschutzrechtlichen Vorschriften, ermittelt werden, welche Anfragen an ein System gestellt werden."
  },
  {
    "objectID": "discovery.html#vergleich-mit-klassischen-bibliothekskatalogen",
    "href": "discovery.html#vergleich-mit-klassischen-bibliothekskatalogen",
    "title": "Discovery & Retrieval",
    "section": "Vergleich mit klassischen Bibliothekskatalogen",
    "text": "Vergleich mit klassischen Bibliothekskatalogen\nDa Discovery-Systeme die Metadaten und Volltexte anders als die klassischen OPACs aufbereiten, sind Suchstrategien und -ergebnisse in beiden Systemen unterschiedlich.\nDiscovery-Systeme richten sich in der Regel an Benutzer*innen, die den Umgang mit bibliographischen Recherchesystemen wie Katalogen und Fachbibliographien nicht gewohnt sind und die mit den Nutzungsmustern bedient werden sollen, die sie auch aus dem Web gewohnt sind.\nNeben der Recherche nach bibliographischen Informationen sollen Discovery-Systeme auch den Zugriff bzw. die Bereitstellung von Medien unterstützen. Dieser auch als Delivery bezeichnete Prozess hat sich bereits in der frühen Phase der Discovery-Systeme als zentrales Element aus Sicht der Nutzer*innen herausgestellt. Die Anbindung an Ausleihsysteme und Link Resolver ist daher ein wichtiges Qualitätskriterium.\nNeuere BMS wie FOLIO und Alma enthalten zum Teil gar keinen klassischen OPAC mehr. Mit diesen Systemen muss daher immer ein zusätzliches Discovery-System eingesetzt werden.\nViele Bibliotheken erschließen E-Ressourcen nicht in vollem Umfang in ihrem BMS. Daher sind im OPAC, der zu diesem BMS gehört, die E-Ressourcen nicht oder nur eingeschränkt auffindbar. Wenn die Bibliothek ein Discovery-System betreibt, können Metadaten zu E-Ressourcen über einen ETL-Prozess in den Index des Discovery-Systems geladen werden. Voraussetzung dafür ist, dass den Metadaten mittels Electronic Ressource Management (ERM) entsprechende Nutzungslizenzen zugeordnet sind.\n\n\nTabelle 7.1: Vergleich typischer Eigenschaften von OPAC/Katalog und Discovery-System\n\n\n\nOPAC/Katalog\nDiscovery-System\n\n\n\n\nSuchraum\nnur lokaler Bestand, nur selbständige Werke\nlokaler Bestand, aber auch Verbunddaten, bibliographische Daten, Volltexte…\n\n\nSuchprinzip\nexakte Suche, feldbasierte Suche mit Boolescher Logik\nbest match/natürlichsprachige Suche\n\n\nSuchunterstützung\neher wenig\nAutovervollständigung, Suchvorschläge, Facetten\n\n\nSortierung\nstandardmäßig nach Aktualität\nstandardmäßig nach Relevanz\n\n\nMehrwertdienste\nBuchcover, Listen, Exportformate\nBuchcover, Listen, Stöbern/Entdecken\n\n\nMetadatenmodell\nbibliothekarisches Schema mit Hierarchien und Verweisen\n„flache Version“ eines bibliothekarischen Schemas\n\n\n\n\n## Grenzen und Alternativen\nDiscovery-Systeme sind in der Regel nur einer von vielen Bausteinen in der Prozesskette der Recherche, Bewertung und Beschaffung von Literatur und spielen an unterschiedlichen Stellen eine Rolle. Sie helfen dabei, Literatur zu entdecken und Zugangswege zu ermitteln und brechen die traditionelle Grenze zwischen Katalog und Bibliografien durch einen zentralen Sucheinstieg auf. Trotz dieser Stärken können die Systeme nachgewiesene Medien nur begrenzt kontextualisieren und bewerten und bleiben in der Praxis oft hinter den Erwartungen zurück (Christensen 2022). Je nach Anwendung spielen daher alternative Systeme weiterhin eine Rolle:\n\nKomplexe bibliographische Angaben, zum Beispiel zum Erscheinungsverlauf von Zeitschriften oder mehrbändigen Werken, oder die Suche nach Signaturen lassen sich möglicherweise schneller über herkömmliche bibliothekarische Instrumente beziehungsweise Spezialdatenbanken wie die des BMS ermitteln.\nZum Entdecken von Literatur eignen sich auch allgemeine Suchmaschinen oder spezielle Academic Search Engines wie Google Scholar sowie gänzlich andere Wege wie bestehende Literaturverzeichnisse, Empfehlungslisten auf Lernplattformen und Webshops.\n\nInsbesondere Webshops haben im Vergleich zu Discovery-Systemen sehr personalisierte Such- und Empfehlungsdienste, die jedoch auf einer intensiven Auswertung des jeweiligen Nutzungsverhaltens basieren. Die Verwendung dieser Daten zur Personalisierung ist auch in Discovery-Systemen denkbar, wird aber aus Datenschutz- und Neutralitätsgründen grundsätzlich eher abgelehnt.\nEine vergleichsweise neue Herangehensweise insbesondere an das entdeckende Suchen bieten Wissensgraphen (knowledge graphs), die die vielfältigen Beziehungen zwischen Dokumenten und damit verknüpften Elementen darstellen und visualisieren. Die Anforderungen an die Qualität der so aufbereiteten Daten sind jedoch ungleich höher. Entsprechende Systeme existieren bereits in ausgewählten Bereichen, zum Beispiel die Plattform SoNAR zur historischen Netzwerkanalyse. Ein ernstzunehmendes Beispiel für einen allgemeinen Wissensgraphen ist die Datenbank Wikidata mit ihren bibliographischen Inhalten WikiCite und dem dazu gehörigen Browsing-Interface Scholia (siehe Abbildung Abbildung 7.2).\n\n\n\nAbbildung 7.2: Thematisches Netzwerk von Publikationen in und über Scholia\n\n\nGrundsätzlich gilt, dass die Grenzen zwischen Discovery-Systemen und Alternativen in der Praxis fließend sind und dass Discovery-Systeme perspektivisch um Funktionen anderer Systeme erweitert werden können und sollten.\n\n\n\n\nChristensen, Anne. 2022. „Wissenschaftliche Literatur entdecken: Was bibliothekarische Discovery-Systeme von der Konkurrenz lernen und was sie ihr zeigen können“. LIBREAS, Nr. 41. https://doi.org/10.18452/24798.\n\n\nSteilen, Gerald. 2012. „Discovery-Systeme - die OPACs der Zukunft?“ Hamburg. https://www.slideshare.net/steilen/discoverysysteme-die-opacs-der-zukunft."
  },
  {
    "objectID": "digitalisierung.html",
    "href": "digitalisierung.html",
    "title": "Digitalisierung",
    "section": "",
    "text": "Dieses Kapitel ist noch nicht umgesetzt (siehe Issue). Bitte melden Sie sich bei Interesse zur Mitarbeit!"
  },
  {
    "objectID": "forschungsnahe-dienste.html",
    "href": "forschungsnahe-dienste.html",
    "title": "Forschungsnahe Dienste",
    "section": "",
    "text": "Dieses Kapitel ist noch nicht umgesetzt (siehe Issue). Bitte melden Sie sich bei Interesse zur Mitarbeit!"
  },
  {
    "objectID": "kommunikation.html",
    "href": "kommunikation.html",
    "title": "Kommunikation",
    "section": "",
    "text": "Dieses Kapitel ist noch nicht umgesetzt (siehe Issue). Bitte melden Sie sich bei Interesse zur Mitarbeit!"
  },
  {
    "objectID": "literatur.html",
    "href": "literatur.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Hier nur die explizit im Handbuch referenzierten Publikationen. Die vollständige Bibliographie wird in einer gemeinsamen Zotero-Gruppe verwaltet.\n\n\nAssfalg, Rolf. 2023. “Metadaten.” In Grundlagen Der\nInformationswissenschaft, edited by Rainer Kuhlen, Dirk\nLewandowski, Wolfgang Semar, and Christa Womser-Hacker, 7. Ausgabe,\n245–56. Berlin, Boston: De Gruyter Saur. https://doi.org/10.1515/9783110769043-021.\n\n\nBach, Nicolas. 2022. “Das Handbuch IT in\nBibliotheken: Einblicke in den ersten bibliothekarischen Book Sprint\nDeutschlands.” Informationspraxis 8 (1). https://doi.org/10.11588/ip.2022.1.94475.\n\n\nBorgman, Christine L. 1997. “From Acting Locally to Thinking\nGlobally: A Brief History of Library Automation.” The Library\nQuarterly: Information, Community, Policy 67 (3): 215–49. https://www.jstor.org/stable/40039721.\n\n\nBreeding, Marshall. 2022. “How to Secure Library Systems from\nMalware, Ransomware, and Other Cyberthreats.” 2022. https://www.infotoday.com/cilmag/jan22/Breeding--How-to-Secure-Library-Systems-From-Malware-Ransomware-and-Other-Cyberthreats.shtml.\n\n\nBreeding, Marshall. n.d. “Library Technology Industry Mergers and\nAcquisitions. Library Technology Guides.” Accessed April 28,\n2022. http://librarytechnology.org/mergers/.\n\n\nChristensen, Anne. 2022. “Wissenschaftliche Literatur entdecken:\nWas bibliothekarische Discovery-Systeme von der Konkurrenz lernen und\nwas sie ihr zeigen können.” LIBREAS, no.\n41. https://doi.org/10.18452/24798.\n\n\nChristensen, Anne, and Frank Seeliger. 2022. “„Wie Schreiben Wir\nGemeinsam Ein Nützliches Buch?”.” B.i.t.online 25 (6):\n509–10. https://www.b-i-t-online.de/heft/2022-06-nachrichtenbeitrag-christensen.pdf.\n\n\nDeutsches Institut für Normung e. V. (DIN). 2020.\n“DIN EN ISO 9241-110\nErgonomie Der Mensch-System-Interaktion - Teil 110:\nInteraktionsprinzipien (ISO 9241-110:2020).” https://www.din.de/de/mitwirken/normenausschuesse/naerg/veroeffentlichungen/wdc-beuth:din21:320862700.\n\n\nFreyberg, Linda, and Sabine Wolf, eds. 2019. Smart Libraries:\nKonzepte, Methoden Und Strategien. B.i.t.online Innovativ 76.\nWiesbaden: b.i.t. Verlag.\n\n\nGesetzliche, Deutsche, and Unfallversicherung e.V. (DGUV). 2019.\n“Bildschirm- Und Büroarbeitsplätze: Leitfaden Für Die\nGestaltung.” https://publikationen.dguv.de/widgets/pdf/download/article/409.\n\n\nGould, J. D., and C. Lewis. 1987. “Designing for Usability: Key\nPrinciples and What Designers Think.” In Human-Computer\nInteraction: A Multidisciplinary Approach, 528–39. San Francisco,\nCA, USA: Morgan Kaufmann Publishers Inc.\n\n\n“Government Design Principles.\nGOV.UK.” 2012. 2012. https://www.gov.uk/guidance/government-design-principles.\n\n\nHanson, Cody. 2015. “Opinion: Libraries Are Software.”\n2015. https://www.codyh.com/writing/software.html.\n\n\nJakob Nielsen. 2000. “Why You Only Need to Test with 5 Users.\nNielsen Norman Group.” 2000. https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/.\n\n\nJetter, Hans-Christian. 2023. “Informationsvisualisierung Und\nVisual Analytics.” In Grundlagen Der\nInformationswissenschaft, edited by Rainer Kuhlen, Dirk\nLewandowski, Wolfgang Semar, and Christa Womser-Hacker, 7. Ausgabe,\n295–306. Berlin, Boston: De Gruyter Saur. https://www.degruyter.com/document/doi/10.1515/9783110769043-025/pdf.\n\n\nKern, Christian. 2011. RFID Für Bibliotheken.\nSpringer.\n\n\nKling, Rob, and Susan Leigh Star. 1998. “Human Centered Systems in\nthe Perspective of Organizational and Social Informatics.”\nACM SIGCAS Computers and Society 28\n(1): 22–29. https://doi.org/10.1145/277351.277356.\n\n\nKluge, Matthias. 2022. Anbieter von Bibliothekssoftware.\nLandesfachstelle für das öffentliche Bibliothekswesen. https://www.oebib.de/bau-einrichtung-it/it-und-internet/bibliothekssoftware.\n\n\nKuhlen, Rainer, Dirk Lewandowski, Wolfgang Semar, and Christa\nWomser-Hacker, eds. 2023. Grundlagen Der\nInformationswissenschaft. 7. Ausgabe. Berlin, Boston: De Gruyter\nSaur. https://doi.org/doi:10.1515/9783110769043.\n\n\nMatthews, Joseph R., and Carson Block. 2020. Library Information\nSystems. Second edition. Library and Information Science Text\nSeries. Santa Barbara, California: Libraries Unlimited.\n\n\nMichaelis, Barbara. 2014. In RFID Für Bibliothekare:\nEin Vademecum, edited by Frank Seeliger, 3. Auflage, 145–50. Verlag\nNews & Media. https://doi.org/10.15771/RFID_2014_13.\n\n\nRölke, Heiko, and Albert Weichselbraun. 2023. “Ontologien Und\nLinked Open Data.” In Grundlagen Der\nInformationswissenschaft, edited by Rainer Kuhlen, Dirk\nLewandowski, Wolfgang Semar, and Christa Womser-Hacker, 7. Ausgabe,\n257–70. Berlin, Boston: De Gruyter Saur. https://www.degruyter.com/document/doi/10.1515/9783110769043-022/pdf.\n\n\nSchweitzer, Roswitha. 2016. “Anforderungen an Ein\nBibliothekssystem Der Neuen Generation - Der Kriterienkatalog von Hbz\nUnd VZG.” Köln. https://docplayer.org/61296444-Anforderungen-an-ein-bibliothekssystem-der-neuen-generation.html.\n\n\nSeeliger, Frank, ed. 2014. RFID Für Bibliothekare: Ein\nVademecum. 3. Auflage. Verlag News & Media. https://doi.org/10.15771/978-3-936527-32-2.\n\n\n———. 2019. “Smart Services Als Marketinginstrument.” In\nPraxishandbuch Informationsmarketing: Konvergente Strategien,\nMethoden Und Konzepte, edited by Frauke Schade and Ursula Georgy,\n343–57. De Gruyter Saur. https://doi.org/10.1515/9783110539011-023.\n\n\nShneiderman, Ben, and Catherine Plaisant. 2005. Designing the User\nInterface. Strategies for Effective Human-Computer Interaction. 4th\ned. Pearson.\n\n\nSiems, Renke. 2022. “Das Lesen der Anderen: Die Auswirkungen von\nUser Tracking auf Bibliotheken.” o-bib. Das offene\nBibliotheksjournal / Herausgeber VDB 9 (1): 1–25. https://doi.org/10.5282/o-bib/5797.\n\n\nSteilen, Gerald. 2012. “Discovery-Systeme - Die OPACs\nDer Zukunft?” Hamburg. https://www.slideshare.net/steilen/discoverysysteme-die-opacs-der-zukunft.\n\n\n“UHF RFID Almanach 2022.” 2022.\nEECC. https://eecc.info/rfidalmanach.html.\n\n\nVoß, Jakob. 2021. “Datenqualität als Grundlage qualitativer\nInhaltserschließung.” In Qualität in der\nInhaltserschließung, 167–76. De Gruyter Saur. https://doi.org/10.1515/9783110691597-010.\n\n\n———. 2022. “Einführung in Die Verarbeitung von\nPICA-Daten.” 2022. https://pro4bib.github.io/pica/."
  },
  {
    "objectID": "glossar.html",
    "href": "glossar.html",
    "title": "Anhang A — Glossar",
    "section": "",
    "text": "API\n\nApplication Programming Interface, Programmierschnittstelle\n\nAvram\n\nSchemasprache für feldbasierte Datenformate, insbesondere MARC und PICA+\n\nBMS\n\nBibliotheksmanagementsystem, gebräuchlich auch als LMS (Library Management System)\n\nCOUNTER\n\nCounting Online Usage of NeTworked Electronic Resources\n\nDiscovery-System\n\nAuf Suchmaschinentechnologie beruhende Systeme zur Suche in großen (auch externen) Datenbeständen\n\nEDIFACT\n\nElectronic Data Interchange for Administration, Commerce and Transport\n\nERM\n\nElectronic Resource Management, Verwaltung von Lizenzinformationen zu E-Ressourcen\n\nERP\n\nEnterprise-Ressource-Planning, Ressourcen wie z.B. Finanzen unternehmerisch überwachen und planen\n\nFID\n\nFachinformationsdienst\n\nFOLIO\n\nOpen-Source Bibliotheksmanagementsystem\n\nGOKb\n\nGlobal Open Knowledgebase, Freie Datenbank zu E-Ressourcen, insbesondere für ERM\n\nID\n\nEindeutige Referenz auf einen Datensatz (Identifikator)\n\nIDM\n\nIdentity Management, das Speichern von Metadaten zu Personen\n\nKBART\n\nKnowledgebases and related tools, Datenformat zum Transfer von Metadaten\n\nLock-In-Effekt\n\nKundenbindung durch hohen Wechselaufwand\n\nMARC\n\nMAchine-Readable Cataloging, ältestes und noch immer wichtigstes bibliothekarisches Austauschformat\n\nNormdaten\n\nDatensätze zur eindeutigen Identifizierung und Referenzierung von Entitäten wie Personen, Organisationen, Themen…\n\nOCR\n\nAutomatische Erkennung von Texten in Bildern (Optical Character Recognition)\n\nOPAC\n\nOnline Public Access Catalogue, Katalog einer Bibliothek\n\nPersona\n\n„Maske“, ein Modell zur Beschreibung eines Anforderungsszenario\n\nSIP2\n\nProtokoll zur Anbindung von Selbstbedienungsautomaten an Bibliothekssysteme\n\nSaaS\n\nSoftware as a Service, Software und Hardware bei externem Dienstleister\n\nUsability\n\nGebrauchstauglichkeit\n\nUser Experience\n\nNutzererfahrung\n\nVR\n\nVirtual Reality, (computer-generierte) virtuelle Umgebung\n\nWCAG\n\nWeb Content Accessibilty Guidelines\n\nZ39.50\n\nProtokoll zur Abfrage von bibliografischen Daten"
  },
  {
    "objectID": "mitarbeit.html#arbeitsablauf",
    "href": "mitarbeit.html#arbeitsablauf",
    "title": "Anhang B — Hinweise zur Mitarbeit",
    "section": "Arbeitsablauf",
    "text": "Arbeitsablauf\nDer aktuelle Workflow beinhaltet folgende Schritte:\n\nSchreiben\n\nNeue Themen werden durch Gruppen im Rahmen von Book Sprints erstellt. Als Werkzeug zum freien Schreiben dient dabei beispielsweise Google Docs.\n\nLektorat\n\nFertige Kapitel werden einmalig nach Markdown konvertiert und im git-Repository des Handbuch abgelegt. Anschließend werden daraus DOCX-Dateien erstellt (Word) und in einem Google Drive Verzeichnis zum Korrekturlesen und Kommentieren bereitgestellt. Änderungen können auch mittels GitHub-Issues oder per Hinweis an die Autor*innen erfolgen.\n\nRedaktion\n\nÄnderungen an bestehenden Kapiteln und an der Gesamtstruktur des Buches können direkt im git-Repository vorgenommen werden. Alternativ muss jemand Änderungsvorschläge aus den Kapitel-Kopien bei Google Drive einarbeiten und die DOCX-Datei aktualisieren.\n\nPublikation\n\nÄnderungen an der Markdown-Dateien im git-Repository führen dazu, dass das Buch mittels quarto in HTML und anderen Formaten aus den Quellen zusammengebaut wird."
  },
  {
    "objectID": "mitarbeit.html#styleguide",
    "href": "mitarbeit.html#styleguide",
    "title": "Anhang B — Hinweise zur Mitarbeit",
    "section": "Styleguide",
    "text": "Styleguide\nDieser Styleguide soll eine einheitliche Form trotz unterschiedlicher Autor*innen gewährleisten. Dazu gibt es Hinweise zu Zielgruppe, Stil und Aktualität, Schreibweise und Struktur sowie Vorgaben zu besonderen Inhalten wie Bildern und anderen Medien, Literaturverzeichnis und Glossar.\n\nZielgruppe\nZur Klärung der Zielgruppe dieses Handbuchs wurden einige sogenannte Personas definiert:\n\nJanine Buchinger: Janine leitet die Stadtbibliothek in einer Stadt mit 250.000 Einwohnern. Die Bibliothek besteht aus einer Zentrale und zwei Zweigstellen. Mit den Schulbüchereien besteht eine Kooperation für fachliche Beratung und gemeinsame Aktivitäten bei der Informationskompetenz-Vermittlung.\nDr. Tillmann Schuppe: Tillmann ist Leiter einer Fachhochschulbibliothek mit 500.000 Medieneinheiten. Die Bibliothek gehört einem Bibliotheksverbund an. Die Bibliothek plant einen Neubau, der gemeinsam mit dem Rechen- und Medienzentrum bezogen werden soll.\nMagda Olsowski: Magda ist studierte Informatikerin und leitet die Gruppe Forschungsdatenmanagement an einer großen Universitätsbibliothek. Sie hat keine bibliothekarische Vorbildung.\nAlicia Meyer: Alicia studiert Bibliotheksmanagement und plant eine Masterarbeit, in der sie die Implementierungsprozesse von Software analysieren möchte.\nRobert Pohlmann: Robert leitet die IT-Abteilung einer mittelgroßen Universitätsbibliothek und ist nebenberuflich Lehrbeauftragter für einen bibliothekarischen Studiengang.\n\n\n\nStil und Aktualität\n\nJournalistische oder enzyklopädische Neutralität sind nicht oberstes Prinzip dieses Buches. Es soll vielmehr fundiert und praxisorientiert informieren und beraten und darf dabei auch parteiisch sein.\nDieses Buch ist keine wissenschaftliche Forschungsveröffentlichung. Nicht jede Aussage muss mit einer Quelle belegt werden. Für die Anwendung in der Hochschullehre reicht es, wenn das Buch zentrale Aussagen belegt bzw. auf die wichtigsten aktuellen Studien verweist und somit auch Tipps zur weiterführenden Lektüre bietet.\nDas Buch sollte in 2-5 Jahren noch aktuell und verständlich sein, aber nicht mehr unbedingt in 10 Jahren.\nDas Buch soll als Nachschlagewerk dienen, das nicht vollständig durchgelesen werden muss. Dabei helfen Redundanz und Querverweise (siehe Hinweise zur Struktur).\n\n\n\nStruktur\n\nStruktur des Texts\n\nWir verwenden kurze, unverschachtelte Sätze.\nWir erzeugen Sinnabschnitte, die möglichst für sich stehend verständlich sind.\nWir schreiben stark strukturiert, also\n\nmit vielen Zwischenüberschriften, bis maximal zur vierten Gliederungsebene,\nwo es inhaltlich passt, in stichpunktartigen Listen und\nmit Hervorhebung wichtiger Begriff durch Fettdruck als Gliederungshilfe.\n\nWir verwenden Infoboxen, die auch unabhängig vom übrigen Text lesbar sind.\nWir liefern wichtige Informationen zusätzlich zum Text in Form von Bildern, Tabellen, Listen, Infoboxen und/oder Zusammenfassungen.\n\n\n\nStruktur der Hauptkapitel\nDas Handbuch behandelt aufgeteilt in Hauptkapitel die wesentlichen Themen rund um IT in Bibliotheken.\n\nKapitel haben normalerweise einen Umfang von 3.000 bis 4.000 Wörtern. Deutlich längere Kapitel sind darauf zu prüfen, ob sie sich in mehrere Kapitel trennen lassen, und wenn das nicht möglich ist, müssen sie sorgfältig in Unterkapitel aufgeteilt werden.\nJedes Kapitel beginnt mit einer Kurzfassung als Infobox gefolgt von einer Einleitung und endet mit einem Abschnitt Zusammenfassung und Ausblick.\nJedes Kapitel beinhaltet ein aussagekräftiges Metadatenfeld description für Suchmaschinen (maximal etwa 158 Zeichen)\n\n\n\n\nSchreibweise, Fachbegriffe und Verweise\n\nWir verwenden im gesamten Buch gendergerechte Schreibweise mit Sternchen (*). In Markdown ist es sicherer dem Sternchen einen Backslash voranzustellen, z.B. Autor\\*innen.\nEine Schreibweise für häufig verwendete Fachbegriffe sollte quer durch das Buch eingehalten werden, so z.B. BMS für Bibliotheksmanagementsysteme\nFachbegriffe (z.B. Bibliotheksverbund) werden dort verwendet, wo sie wiederholt relevant sind, und werden bei ihrer ersten Erwähnung definiert. Die eingeführten Fachbegriffe müssen in einem Glossar für das gesamte Buch gebündelt werden.\nWir vermeiden IT-Jargon.\nQuellen sollten nur dann genannt werden wenn in der jeweiligen Textpassage auch wirklich paraphrasiert oder wörtlich zitiert wird.\n\n\nTypografie\n\nAbkürzungen werden durch geschützte Leerzeichen getrennt (z. B.)\nGerade Anführungszeichen \"...\" werden automatisch durch die Deutschland und Österreich übliche Anführungszeichen („…“) ersetzt.\n\nExterne Links, die nur auf Anbieter oder andere Websites verweisen, werden inline verlinkt.\n\nLinks, die auf später entstehende Kapitel verweisen, werden durch eckige Klammern kenntlich gemacht.\nKursive Hervorhebung sollte nur für Namen und Glossareinträge verwendet werden.\nWir verzichten auf Fußnoten.\n\n\n\n\nBilder und andere Medien\n\nBilder und andere Mediendateien kommen in das Verzeichnis media im git-Repository. Alternativ können sie von externen Quellen per URL eingebunden werden wenn die Quelle voraussichtlich dauerhaft verfügbar ist.\nBilder sollten möglichst als Vektorgrafik (SVG) bereitgestellt werden.\nStandardschriftart ist Source Sans Pro und Standard-Farbe für Hervorhebungen ist Blau mit dem Farbcode #2780e3 und darauf aufbauende Hellblau-Töne.\nBitte nutzt sprechende Dateinamen!\n\n\n\nLiteraturverzeichnis\nDie zitierte und weiterführende Literatur wird in einer Zotero-Gruppe unter https://www.zotero.org/groups/4673379/it_in_bibliotheken verwaltet. Der BibLaTex-Export dieser Bibliographie wird mit Aufruf von make refs von dort heruntergeladen und unter references.bib gespeichert. Diese Datei sollte also nicht direkt bearbeitet werden! Innerhalb des Markdown-Quelltext kann mittels Pandoc-Citation Syntax und dem jeweiligen Citekey aus references.bib auf Literatur verwiesen werden.\n\n\nGlossar\nDas Glossar in der Datei glossar.yml enthält erklärungswürdige Begriffe mit Kurzbeschreibung und optionalem Link auf eine weiterführende Quelle (meist Wikipedia). Es werden _keine_ Firmennamen in das Glossar aufgenommen, auch wenn sie Akronyme sind. Die Glossarbegriffe werden in den Textdateien zur Hervorhebung kursiv gesetzt (in Markdown so ein *Fachbegriff*). Bei Erzeugung der HTML-Version des Handbuchs wird die Hervorhebung in einen Tooltip umgewandelt.\n\n\nAutor*innen-Verzeichnis\nWenn Du etwas beigetragen hast und möchtest, dass Du im Verzeichnis der Autor*innen auftauchst, trage Dich in der YAML-Datei contributors.yml ein. Die Einträge sollten nach Nachname sortiert werden. Die Felder email, position und orcid sind optional."
  },
  {
    "objectID": "mitarbeit.html#technik",
    "href": "mitarbeit.html#technik",
    "title": "Anhang B — Hinweise zur Mitarbeit",
    "section": "Technik",
    "text": "Technik\nDie Master-Version des Handbuch liegt in einem git-Repository unter https://github.com/pro4bib/handbuch-it-in-bibliotheken. Die Ergebnisdateien werden automatisch via GitHub und einen Server der VZG aktualisiert, so dass unter https://it-in-bibliotheken.de/ immer der aktuellste Stand einsehbar sein sollte.\n\nVerzeichnisstruktur\nDie Markdown-Dateien im Wurzelverzeichnis (*.md) sind die Masterdateien.\n\nmetadata.yml bibliographische Metadaten (Titel, Abstract…)\n_quarto.yml zentrale Konfigurationsdatei zur Anpassung der Konvertierung mit Quarto\ncontributors.yml Autor*innen-Verzeichnis\nreferences.bib Literaturverzeichnis (bitte nicht direkt bearbeiten!)\n\nWeitere Unterverzeichnisse:\n\nmedia/ Bilder und andere Medien\n\nDie Dateien in folgenden Verzeichnissen sollen nicht per Hand geändert werden:\n\ndocs/ aus den Masterdateien mit quarto erzeugte Publikation\n_gdrive/ von bzw. nach Google-Drive importierte bzw. exportierte Kapitel (siehe README.md)\n\n\n\nKonvertierung\nZur Anpassung der Konvertierung des Handbuchs mit Quarto muss das Repository lokale geklont und Quarto installiert werden. Für die DOCX-Ausgabe muss außerdem rsvg-convert installiert werden (Paket librsvg2-bin bzw. libsrvg).\nDie Aufrufe sind zur Vereinfachung in Makefile zusammengefasst:\n\nmake preview konvertiert das Handbuch nach HTML und startet einen Webserver mit Vorschau unter http://localhost:15745/ (PLZ von Wildau). Die HTML-Ansicht wird automatisch aktualisiert wenn die Quelldateien lokale geändert werden.\nmake build konvertiert das Handbuch in alle konfigurierten Formate und legt die Ergebnisse im Verzeichnis _book ab. Dieser Schritt wird auch automatisch nach jedem Push auf GitHub ausgeführt.\nmake all ruft make build und docx auf und kopiert die DOCX-Dateien ins Publikationsverzeichnis _book.\nmake html erzeugt nur HTML in _book.\nmake docx erzeugt nur DOCX in _book.\nmake refs aktualisiert das Literaturverzeichnis in references.bib von Zotero."
  },
  {
    "objectID": "mitarbeit.html#lizenz",
    "href": "mitarbeit.html#lizenz",
    "title": "Anhang B — Hinweise zur Mitarbeit",
    "section": "Lizenz",
    "text": "Lizenz\nAlle Beiträge werden unter der Lizenz Creative Commons Namensnennung 3.0 Deutschland (CC BY 3.0 DE) veröffentlicht. Für Abbildungen kann auch eine CC-BY-Lizenz (kein -NC oder -ND) verwendet werden."
  }
]